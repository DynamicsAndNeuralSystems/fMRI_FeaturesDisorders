---
title: "Step 4: Feature-wise catch22 ROI Analysis"
output: 
  github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning=F, message=F)
```

### Source functions
```{r}
github_dir <- "D:/Virtual_Machines/Shared_Folder/github/fMRI_FeaturesDisorders/"
source(paste0(github_dir, "helper_functions/Linear_SVM.R"))
source(paste0(github_dir, "helper_functions/Visualization.R"))
source(paste0(github_dir, "helper_functions/Null_distributions.R"))
source(paste0(github_dir, "helper_functions/t_test_functions.R"))
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"
set.seed(127)
```

## Feature-wise t-tests

### Full panel histogram visualization
Let's start with a very simple t-test for catch22 feature values in control vs schizophrenia subjects by brain region:
```{r, fig.width=16, fig.height=10}
if (!file.exists(paste0(rdata_path, "Feature_wise_T_Test_res_catchaMouse16.Rds"))) {
  t_test_res <- t_test_by_region(rdata_path=rdata_path,
                                 feature_set = "catchaMouse16") %>%
    dplyr::rename("feature"="names") 
  saveRDS(t_test_res, file=paste0(rdata_path, "Feature_wise_T_Test_res_catchaMouse16.Rds"))
} else {
  t_test_res <- readRDS(paste0(rdata_path, "Feature_wise_T_Test_res_catchaMouse16.Rds"))
}
# Just use AROMA+2P for example
noise_proc = "AROMA+2P"
noise_label <- gsub("\\+", "_", noise_proc)
t_stat_histograms(t_test_res=t_test_res,
                  noise_proc = noise_proc)
ggsave("plots/Feature_Wise_In_Sample_T_Test_Res_AROMA_2P.png", width=16, height=10, units="in", dpi=300)
```

## Cross-validated SVM classification

### 10-fold cross-validated linear SVM

We can implement 10-fold cross-validation (CV) with the `caret` package.

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"
  
# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))) {
  feature_wise_SVM_CV <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                 test_package = test_package,
                                                 svm_kernel = kernel,
                                                 grouping_var = "Feature",
                                                 svm_feature_var = "Brain_Region",
                                                 use_inv_prob_weighting = FALSE,
                                                 use_SMOTE = FALSE,
                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_CV, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))
}

```


```{r, fig.width=8, fig.height=4.5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_CV <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_CV,
                       noise_procs = noise_procs,
                       group_var = "Feature",
                       rdata_path = rdata_path,
                       plot_title = "Unweighted Feature-wise Linear SVM Results")

# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV.png",
       width=8,height=4.5, units="in", dpi=300)
```


As with in-sample SVM, the unweighted input samples are virtually all classified as control subjects across all 82 ROIs using the 10-fold cross-validation linear SVM with caret.

### 10-fold cross-validated linear SVM with inverse probability weighting

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))) {
  feature_wise_SVM_CV_inv_prob <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                                 test_package = test_package,
                                                                 svm_kernel = kernel,
                                                                 grouping_var = "Feature",
                                                                 svm_feature_var = "Brain_Region",
                                                                 use_inv_prob_weighting = TRUE,
                                                                 use_SMOTE = FALSE,
                                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_CV_inv_prob, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))
}
```

```{r, fig.width=8, fig.height=4.5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_CV_inv_prob,
                       group_var = "Feature",
                       rdata_path = rdata_path,
                       noise_procs = noise_procs,
                       plot_title = "Inv Prob-Weighted Feature-wise Linear SVM Results")

# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV_inv_prob.png",
       width=8,height=4.5, units="in", dpi=300)
```


Surprisingly, incorporating inverse probability weighting has minimal impact when it comes to the ten-fold cross-validated SVM. Of note, the in-sample and cross-validated SVM were both run with kernlab::ksvm using default parameters.


### 10-fold cross-validated linear SVM with SMOTE

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))) {
  feature_wise_SVM_CV_SMOTE <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                                 test_package = test_package,
                                                                 svm_kernel = kernel,
                                                                 grouping_var = "Feature",
                                                                 svm_feature_var = "Brain_Region",
                                                                 use_inv_prob_weighting = FALSE,
                                                                 use_SMOTE = TRUE,
                                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_CV_SMOTE, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))
}
```

```{r, fig.width=8, fig.height=4.5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_CV_SMOTE,
                       group_var = "Feature",
                       plot_title = "SMOTE-Weighted Feature-wise Linear SVM Results",
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV_SMOTE.png",
       width=8,height=4.5, units="in", dpi=300)
```


Surprisingly, incorporating inverse probability weighting has minimal impact when it comes to the ten-fold cross-validated SVM. Of note, the in-sample and cross-validated SVM were both run with kernlab::ksvm using default parameters.


## Model-free shuffle null distribution

### Generating null distributions from model-free shuffles

This first model-free shuffles method is borrowed from Trent's implementation in theft. With this method, the input class labels (Schz or Control) are randomly shuffled N times, and for each iteration, the classification accuracy and balanced accuracy are calculated. This yields a null distribution of accuracies and balanced accuracies, circumventing the need for running any classification algorithms across iterations.

Here, I've run 1,000,000 iterations of the model-free shuffle, generating 1,000,000 null values for Accuracy and Balanced Accuracy, respectively. Since this method is independent of brain region, the same null distribution can be used to compare with each brain region separately.

```{r}
# Try three different noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# One without minority upsampling
if (!file.exists(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))) {
  set.seed(127) 
  model_free_shuffle_null_res <- run_model_free_n_shuffles(num_shuffles = 1000000,
                                                    rdata_path = rdata_path,
                                                    noise_procs = noise_procs)
  saveRDS(model_free_shuffle_null_res, file = paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
} else {
  model_free_shuffle_null_res <- readRDS(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
}
```

### Unweighted linear SVM
```{r, fig.width=8, fig.height=4.5}
feature_wise_SVM_CV <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_CV,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "Feature-wise Unweighted Feature-wise Linear SVM Results vs. Model-Free Shuffles")

# Save plot
ggsave("plots/Feature_Wise_Unweighted_Null_Model_Free_Shuffle_vs_Real.png",
       width=8, height=4.5, units="in", dpi=300)
```


I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 82 ROIs on the left. Let's zoom in on AROMA+2P and pick the five catch22 features with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
feature_wise_SVM_CV <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))
if (!file.exists(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_pvals.Rds"))) {
  feature_wise_SVM_CV_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_CV,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Feature")
  saveRDS(feature_wise_SVM_CV_pvals, file=paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_pvals.Rds"))
} else {
  feature_wise_SVM_CV_pvals <- readRDS(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_pvals.Rds"))
}

feature_wise_SVM_CV_plabs <- truncate_p_values(feature_wise_SVM_CV_pvals, 3)
```


```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_CV_pvals,
                             null_res = model_free_shuffle_null_res,
                             sample_type = "Out-of-sample",
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main Out-of-Sample and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P catch22 Features",
                             yloc = 8,
                             xloc = 0.6)

ggsave("plots/Feature_Wise_Model_Free_Shuffle_Top5_Features_Out_of_Sample_SVM_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_CV_pvals)
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.



### CV linear SVM -- inv prob
```{r, fig.width=8, fig.height=4.5}
feature_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_CV_inv_prob,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "Feature-wise Inv Prob Linear SVM Results vs.\nModel-Free Shuffles")

# Save plot
ggsave("plots/Feature_Wise_CV_Null_vs_Real_Model_Free_Shuffle_inv_prob.png",
       width=8, height=4.5, units="in", dpi=300)
```


I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 22 catch22 features on the left. Let's zoom in on AROMA+2P and pick the five features with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
feature_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))
if (!file.exists(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))) {
  feature_wise_SVM_CV_inv_prob_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_CV_inv_prob,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Feature")
  saveRDS(feature_wise_SVM_CV_inv_prob_pvals, file=paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))
} else {
  feature_wise_SVM_CV_inv_prob_pvals <- readRDS(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))
}

feature_wise_SVM_CV_inv_prob_plabs <- truncate_p_values(feature_wise_SVM_CV_inv_prob_pvals)
```


```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_CV_inv_prob_pvals,
                             null_res = model_free_shuffle_null_res,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P catch22 Features, CV Inverse Probability",
                             xloc = 0.6, yloc = 8)

ggsave("plots/Feature_Wise_Model_Free_Shuffle_Top5_Features_CV_SVM_Balanced_Accuracy_Inv_Prob.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_CV_inv_prob_pvals)
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.


### CV linear SVM -- SMOTE
```{r, fig.width=8, fig.height=4.5}
feature_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_CV_SMOTE,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "Feature-wise SMOTE Linear SVM Results vs.\nModel-Free Shuffles")

# Save plot
ggsave("plots/Feature_Wise_CV_Null_vs_Real_Model_Free_Shuffle_SMOTE.png",
       width=8, height=4.5, units="in", dpi=300)
```


I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 22 catch22 Features on the left. Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
feature_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))
if (!file.exists(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))) {
  feature_wise_SVM_CV_SMOTE_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_CV_SMOTE,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Feature")
  saveRDS(feature_wise_SVM_CV_SMOTE_pvals, file=paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))
} else {
  feature_wise_SVM_CV_SMOTE_pvals <- readRDS(paste0(rdata_path, "Feature_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))
}

feature_wise_SVM_CV_SMOTE_plabs <- truncate_p_values(feature_wise_SVM_CV_SMOTE_pvals)
```


```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_CV_SMOTE_pvals,
                             null_res = model_free_shuffle_null_res,
                             sample_type = "Out-of-sample",
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main Out-of-Sample and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P Features, CV SMOTE",
                             xloc = 0.6,
                             yloc = 8.5)


ggsave("plots/Feature_Wise_Model_Free_Shuffle_Top5_Features_Out_of_Sample_SVM_Balanced_Accuracy_SMOTE.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_CV_SMOTE_pvals)
```

This table summarises the number of catch22 features for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.

## Empirical model-based pooled null distribution

### Generating null distributions from pooled null model fits


In contrast to the model-free shuffle method, here we are actually shuffling the input class labels right before running the linear SVM over N=40 iterations per feature (N=22) and pooling the resulting accuracy and balanced accuracy values, to generate empirical null distributions of N=880 data points each, respectively.

### Unweighted

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_model_permutation_null_unweighted.Rds"))) {
  model_permutation_null_unweighted <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Feature",
                                                                    svm_feature_var = "Brain_Region",
                                                                    num_permutations = 40,
                                                                    use_inv_prob_weighting = FALSE,
                                                                    use_SMOTE = FALSE)
  
  saveRDS(model_permutation_null_unweighted, file=paste0(rdata_path, "Feature_wise_model_permutation_null_unweighted.Rds"))
} else {
  model_permutation_null_unweighted <- readRDS(paste0(rdata_path, "Feature_wise_model_permutation_null_unweighted.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_unweighted %>% filter(Noise_Proc == "AROMA+2P"))
```

```{r, fig.width=8, fig.height=4.5}
# Plot null accuracy and balanced accuracy compared with real metrics:
feature_wise_SVM_unweighted <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_unweighted,
                       null_res = model_permutation_null_unweighted,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "Unweighted Feature-wise Linear SVM Results vs.\nNull Model Fits")

# Save plot
ggsave("plots/Feature_Wise_Null_Model_Fit_Unweighted_Balanced_Accuracy.png",
       width=8, height=4.5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}

if (!file.exists(paste0(rdata_path, "Feature_wise_In_Sample_Null_Model_Fits_pvals.Rds"))) {
  feature_wise_SVM_unweighted_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_unweighted,
                                                           null_data = model_permutation_null_unweighted,
                                                           grouping_var = "Feature")
  saveRDS(feature_wise_SVM_unweighted_pvals, file=paste0(rdata_path, "Feature_wise_In_Sample_Null_Model_Fits_pvals.Rds"))
} else {
  feature_wise_SVM_unweighted_pvals <- readRDS(paste0(rdata_path, "Feature_wise_In_Sample_Null_Model_Fits_pvals.Rds"))
}

feature_wise_SVM_unweighted_plabs <- truncate_p_values(feature_wise_SVM_unweighted_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_unweighted_pvals,
                             null_res = model_permutation_null_unweighted,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main Out-of-Sample and Null Model Fit Balanced Accuracy\nfor top AROMA+2P catch22 features, Unweighted",
                             xloc = 0.58, 
                             yloc = 4.5)

# Save plots
ggsave("plots/feature_wise_Null_Model_Fit_Top5_Regions_In_Sample_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_unweighted_pvals)
```

### CV, inverse probability weighted

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_model_permutation_null_inv_prob.Rds"))) {
  model_permutation_null_inv_prob <- run_null_model_n_permutations(rdata_path,
                                                                             noise_procs = noise_procs,
                                                                             grouping_var = "Feature",
                                                                             svm_feature_var = "Brain_Region",
                                                                             num_permutations = 40,
                                                                             use_inv_prob_weighting = TRUE,
                                                                             use_SMOTE = FALSE)
  
  saveRDS(model_permutation_null_inv_prob, file=paste0(rdata_path, "Feature_wise_model_permutation_null_inv_prob.Rds"))
} else {
  model_permutation_null_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_model_permutation_null_inv_prob.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_inv_prob %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=8, fig.height=4.5}
# Plot null accuracy and balanced accuracy compared with real metrics:
feature_wise_SVM_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_inv_prob,
                       null_res = model_permutation_null_inv_prob,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "Feature-Wise Inv Prob Linear SVM Results vs.\nNull Model Fits")

ggsave("plots/Feature_wise_Null_Model_Fit_Balanced_Accuracy_Inv_Prob.png",
       width=8, height=4.5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
if (!file.exists(paste0(rdata_path, "Feature_wise_In_Sample_Null_Model_Fits_pvals_inv_prob.Rds"))) {
  feature_wise_SVM_inv_prob_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_inv_prob,
                                                              null_data = model_permutation_null_inv_prob,
                                                              grouping_var = "Feature")
  saveRDS(feature_wise_SVM_inv_prob_pvals, file=paste0(rdata_path, "Feature_wise_Null_Model_Fits_pvals_inv_prob.Rds"))
} else {
  feature_wise_SVM_inv_prob_pvals <- readRDS(paste0(rdata_path, "Feature_wise_Null_Model_Fits_pvals_inv_prob.Rds"))
}

feature_wise_SVM_inv_prob_plabs <- truncate_p_values(feature_wise_SVM_inv_prob_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_inv_prob_pvals,
                             null_res = model_permutation_null_inv_prob,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main In-Sample Inv Prob and Null Model Fit\nBalanced Accuracyfor top AROMA+2P catch22 Features",
                             xloc = 0.875,
                             yloc = 7.5)

# Save plot
ggsave("plots/feature_wise_Null_Model_Fit_Top5_Regions_In_Sample_Inv_Prob_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_inv_prob_pvals)
```


### CV, SMOTE

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_model_permutation_null_SMOTE.Rds"))) {
  model_permutation_null_SMOTE <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Feature",
                                                                    svm_feature_var = "Brain_Region",
                                                                    num_permutations = 40,
                                                                    use_inv_prob_weighting = FALSE,
                                                                    use_SMOTE = TRUE)
  
  saveRDS(model_permutation_null_SMOTE, file=paste0(rdata_path, "Feature_wise_model_permutation_null_SMOTE.Rds"))
} else {
  model_permutation_null_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_model_permutation_null_SMOTE.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_SMOTE %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=8, fig.height=4.5}
# Plot null accuracy and balanced accuracy compared with real metrics:
feature_wise_SVM_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

plot_main_vs_null_hist(main_res = feature_wise_SVM_SMOTE,
                       null_res = model_permutation_null_SMOTE,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "Feature-Wise SMOTE Linear SVM Results vs.\nNull Model Fits")

# Save plot
ggsave("plots/Feature_wise_Null_Model_Fit_Balanced_Accuracy_SMOTE.png",
       width=8, height=4.5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
if (!file.exists(paste0(rdata_path, "Feature_wise_Null_Model_Fits_pvals_SMOTE.Rds"))) {
  feature_wise_SVM_SMOTE_pvals <- calc_empirical_nulls(class_res = feature_wise_SVM_SMOTE,
                                                              null_data = model_permutation_null_SMOTE,
                                                              grouping_var = "Feature")
  saveRDS(feature_wise_SVM_SMOTE_pvals, file=paste0(rdata_path, "Feature_wise_Null_Model_Fits_pvals_SMOTE.Rds"))
} else {
  feature_wise_SVM_SMOTE_pvals <- readRDS(paste0(rdata_path, "Feature_wise_Null_Model_Fits_pvals_SMOTE.Rds"))
}

feature_wise_SVM_SMOTE_plabs <- truncate_p_values(feature_wise_SVM_SMOTE_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_6_vars_main_vs_null(class_res_pvals = feature_wise_SVM_SMOTE_pvals,
                             null_res = model_permutation_null_SMOTE,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Null Model Fit Balanced Accuracy\nfor top AROMA+2P catch22 Features, CV SMOTE",
                             xloc = 0.57,
                             yloc = 4.5)

# Save plot
ggsave("plots/feature_wise_Null_Model_Fit_Top5_Regions_SMOTE_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(feature_wise_SVM_SMOTE_pvals)
```


## Comparing model-free shuffle with pooled empirical null distributions

```{r, fig.width = 7, fig.height = 7}
# In-sample inverse probability
in_sample_inv_prob_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_inv_prob %>% 
                     filter(Sample_Type == "In-sample") %>%
                     mutate(Null_Type = "Null Model Fit, In-sample Inv Prob")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 1.01)) +
  ylab("") +
  xlab("") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, Out-of-sample Inv Prob" = "dodgerblue",
                                  "Null Model Fit, Out-of-sample SMOTE" = "green"))

# Out-of-sample inverse probability
CV_inv_prob_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_inv_prob %>% 
                     filter(Sample_Type == "Out-of-sample") %>%
                     mutate(Null_Type = "Null Model Fit, Out-of-sample Inv Prob")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 1.01)) +
  ylab("Scaled Density") +
  xlab("") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, Out-of-sample Inv Prob" = "dodgerblue",
                                  "Null Model Fit, Out-of-sample SMOTE" = "green"))

# Out-of-sample SMOTE
CV_SMOTE_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_SMOTE %>% 
                     filter(Sample_Type == "Out-of-sample") %>%
                     mutate(Null_Type = "Null Model Fit, Out-of-sample SMOTE")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample Inv Prob",
                                                  "Null Model Fit, Out-of-sample SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 1.01)) +
  ylab("") +
  xlab("Balanced Accuracy") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, Out-of-sample Inv Prob" = "dodgerblue",
                                  "Null Model Fit, Out-of-sample SMOTE" = "green"))

in_sample_inv_prob_p / CV_inv_prob_p / CV_SMOTE_p  + 
  plot_annotation(title = "Null Distributions by Model Type") + 
  plot_layout(guides = "collect") & 
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow=2,byrow=TRUE))
ggsave("plots/Null_Distributions_by_Model_Type.png",
       width = 7, height = 7, units = "in", dpi=300)
```