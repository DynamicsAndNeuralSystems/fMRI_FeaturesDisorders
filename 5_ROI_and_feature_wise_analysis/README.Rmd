---
title: "Step 5: ROI+Feature Classification Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=F, message=F)
```

### Source functions
```{r}
source("../helper_functions/visualization_functions.R")
source("ROI_and_feature_analysis_functions.R")
source("D:/Virtual_Machines/Shared_Folder/github/theft-trent/R/fit_multi_feature_classifier.R")
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"
```

### Run multivariable classifier

We will use the multivariable classifier included in `theft` to evaluate how the catch22 feature set along with brain regions collectively performs at distinguishing control vs. schizophrenia subjects. We will use z-score normalisation and a linear support vector machine (SVM) with caret. 

The below code chunk calls `run_theft_multivar_classifier`, which is a wrapper for `fit_multivariable_classifier` from `theft`. Behind the scenes, we opt to use 10-fold cross validation (`use_k_fold = TRUE`, `num_folds = 10`) with empirical null model fitting (`use_empirical_null=TRUE`, `null_testing_method = "null model fits"`) and gaussian p-value calculation with 10 permutations (`p_value_method = "gaussian"`, `num_permutations = 10`).

```{r, warning=F, message=F}
# Use z-score normalisation
norm_method = "z-score"

# Use linear support vector machine (SVM) classification algorithm
test_method <- "svmLinear"

# Retain balanced accuracy in addition to raw accuracy for each ROI
use_balanced_accuracy <- TRUE

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Run theft's multivariable classifier on each ROI and save to an RDS object
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear.Rds"))) {
  
  ROI_feature_wise_class_res_list <- list()
  
  for (noise_proc in noise_procs) {
    ROI_feature_wise_class_res <- run_theft_multivar_classifier_ROI_feature(rdata_path,
                                                        test_method = test_method,
                                                        noise_proc = noise_proc,
                                                        use_balanced_accuracy = use_balanced_accuracy)
    
    ROI_feature_wise_class_res_list <- rlist::list.append(ROI_feature_wise_class_res_list, ROI_feature_wise_class_res)
  }
  
  ROI_feature_wise_class_res_df <- do.call(plyr::rbind.fill, ROI_feature_wise_class_res_list)
  saveRDS(ROI_feature_wise_class_res_df, file=paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear.Rds"))
} else {
  ROI_feature_wise_class_res_df <- readRDS(paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear.Rds"))
}
```

We can plot the accuracy across the three noise processing methods:

```{r}
ctrl_prop_list <- list()
for (noise_proc in noise_procs) {
  # Clean up names
  noise_label <- gsub("\\+", "_", noise_proc)
  
  # Load corresponding feature matrix
  feature_matrix <- readRDS(paste0(rdata_path, sprintf("UCLA_%s_catch22.Rds", 
                                                       noise_label)))
  
  # Calculate proportion of controls after dropping NA
  ctrl_proportion <- feature_matrix %>%
    group_by(Subject_ID, Brain_Region) %>%
    filter(!any(is.na(values))) %>%
    ungroup() %>%
    distinct(Subject_ID, group) %>%
    summarise(ctrl_prop = sum(group=="Control") / n()) %>%
    mutate(Noise_Proc = noise_proc)
  
  ctrl_prop_list <- rlist::list.append(ctrl_prop_list, ctrl_proportion)
}
ctrl_prop <- do.call(plyr::rbind.fill, ctrl_prop_list)

  
ROI_feature_wise_class_res_df %>%
  dplyr::select(Noise_Proc, accuracy, balanced_accuracy) %>%
  pivot_longer(cols=c(accuracy, balanced_accuracy)) %>%
  left_join(., ctrl_prop) %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs)) %>%
  mutate(ctrl_prop = ifelse(name=="accuracy", ctrl_prop, 0.5)) %>%
  dplyr::mutate(name = stringr::str_to_title(gsub("_", " ", name))) %>%
  ggplot(data=., mapping=aes(x=Noise_Proc, y=value)) +
  geom_bar(stat="identity", fill="lightsteelblue") +
  geom_hline(aes(yintercept = ctrl_prop),
             linetype = 2) +
  ylab("Mean statistic over 10-fold CV") +
  xlab("Noise processing method") +
  facet_grid(name ~ Noise_Proc, scales="free", switch="y") +
  theme(strip.text.y.left = element_text(angle=0),
        strip.placement = "outside",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

ggsave("plots/Acc_BalAcc_caret_SVM_no_reweighting.png", width=7, 
       height=6, units="in", dpi=300)
```

### In-sample linear SVM with inverse probability weighting

We can run linear SVM with the `e1071` package to directly test sample reweighting with in-sample accuracy and balanced accuracy. 

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use linear SVM
svm_kernel = "linear"

# Run theft's multivariable classifier on each ROI and save to an RDS object
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "UCLA_e1071_linear_SVM_ROI_feature_wise.Rds"))) {
  region_feature_wise_SVM_e1071 <- run_in_sample_e1071_SVM_by_all_feature_region(rdata_path = rdata_path,
                                                   svm_kernel = svm_kernel,
                                                   noise_procs = noise_procs)
  saveRDS(region_feature_wise_SVM_e1071, file=paste0(rdata_path, "UCLA_e1071_linear_SVM_ROI_feature_wise.Rds"))
} else {
  region_feature_wise_SVM_e1071 <- readRDS(paste0(rdata_path, "UCLA_e1071_linear_SVM_ROI_feature_wise.Rds"))
}

```

```{r}
region_feature_wise_SVM_e1071 %>%
  distinct() %>%
  dplyr::select(Noise_Proc, Accuracy, Balanced_Accuracy) %>%
  pivot_longer(cols=c(Accuracy, Balanced_Accuracy)) %>%
  left_join(., ctrl_prop) %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs)) %>%
  mutate(ctrl_prop = ifelse(name=="Accuracy", ctrl_prop, 0.5)) %>%
  dplyr::mutate(name = stringr::str_to_title(gsub("_", " ", name))) %>%
  ggplot(data=., mapping=aes(x=Noise_Proc, y=value)) +
  geom_bar(stat="identity", fill="lightsteelblue") +
  geom_hline(aes(yintercept = ctrl_prop),
             linetype = 2) +
  ylab("In-sample statistic") +
  xlab("Noise processing method") +
  facet_grid(name ~ Noise_Proc, scales="free", switch="y") +
  theme(strip.text.y.left = element_text(angle=0),
        strip.placement = "outside",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

ggsave("plots/In_Sample_Region_Feature_Wise_SVM_Multi_Feature_Reweighting.png", width=7,
       height=6, units="in", dpi=300)
```

### 10-fold cross-validated linear SVM with inverse probability weighting

We can implement 10-fold cross-validation (CV) with the `caret` package.

```{r}
# Try three different noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Retain balanced accuracy in addition to raw accuracy for each ROI
use_balanced_accuracy <- TRUE

# Implement inverse probability weighting
use_inv_prob_weighting = TRUE

# Run theft's multivariable classifier on each ROI and save to an RDS object
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear_inv_prob.Rds"))) {
  
   region_feature_wise_SVM_caret_inv_prob_df <- run_caret_multi_SVM_by_region_feature_inv_prop(rdata_path = rdata_path,
                                            use_inv_prob_weighting = TRUE,
                                            noise_procs = noise_procs)
  saveRDS(region_feature_wise_SVM_caret_inv_prob_df, file=paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear_inv_prob.Rds"))
} else {
  region_feature_wise_SVM_caret_inv_prob_df <- readRDS(paste0(rdata_path, "UCLA_multivar_ROI_feature_res_svmLinear_inv_prob.Rds"))
}
```

```{r}
region_feature_wise_SVM_caret_inv_prob_df %>%
  distinct() %>%
  dplyr::select(Noise_Proc, Accuracy, Balanced_Accuracy) %>%
  pivot_longer(cols=c(Accuracy, Balanced_Accuracy)) %>%
  left_join(., ctrl_prop) %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs)) %>%
  mutate(ctrl_prop = ifelse(name=="Accuracy", ctrl_prop, 0.5)) %>%
  dplyr::mutate(name = stringr::str_to_title(gsub("_", " ", name))) %>%
  ggplot(data=., mapping=aes(x=Noise_Proc, y=value)) +
  geom_bar(stat="identity", fill="lightsteelblue") +
  geom_hline(aes(yintercept = ctrl_prop),
             linetype = 2) +
  ylab("Mean statistic over 10-fold CV") +
  xlab("Noise processing method") +
  facet_grid(name ~ Noise_Proc, scales="free", switch="y") +
  theme(strip.text.y.left = element_text(angle=0),
        strip.placement = "outside",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

ggsave("plots/Caret_10CV_Region_Feature_Wise_SVM_Multi_Feature_Reweighting.png", width=7,
       height=6, units="in", dpi=300)
```

### Generating null distributions from model-free shuffles

```{r}
# Try three different noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

if (!file.exists(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))) {
  set.seed(127)
  model_free_shuffle_null_res <- run_model_free_n_shuffles(num_shuffles = 10000,
                                                    rdata_path = rdata_path,
                                                    noise_procs = noise_procs)
  saveRDS(model_free_shuffle_null_res, file = paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
} else {
  model_free_shuffle_null_res <- readRDS(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
}
```

```{r}
main_and_null_res <- region_feature_wise_SVM_caret_inv_prob_df %>%
    dplyr::select(Noise_Proc, Accuracy, Balanced_Accuracy) %>%
    mutate(Type = "main",
           Iteration = 0) %>%
  plyr::rbind.fill(., model_free_shuffle_null_res) %>%
  
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs))

main_p_values <- main_and_null_res  %>%
  group_by(Noise_Proc) %>%
  summarise(Acc_p = 1 - (sum(Accuracy[Type=="main"] > Accuracy[Type=="null"], na.rm=T)/n()),
            Bal_Acc_p = 1 - (sum(Balanced_Accuracy[Type=="main"] > Balanced_Accuracy[Type=="null"])/n())) %>%
  ungroup() %>%
  mutate(Acc_p_adj = p.adjust(Acc_p, method="BH"),
         Bal_Acc_p_adj = p.adjust(Bal_Acc_p, method="BH")) 

main_p_labs <- main_p_values %>%
  mutate(Acc_p = scales::scientific(Acc_p, digits = 3),
         Bal_Acc_p = scales::scientific(Bal_Acc_p, digits = 3),
         Acc_p_adj = scales::scientific(Acc_p_adj, digits = 3),
         Bal_Acc_p_adj = scales::scientific(Bal_Acc_p_adj, digits = 3))
```

```{r}
main_and_null_res %>%
  ggplot(data=subset(main_and_null_res, Type=="null"), 
         mapping=aes(x=Accuracy)) +
  geom_histogram(fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Accuracy") +
  facet_grid(. ~ Noise_Proc) +
  geom_vline(data = subset(main_and_null_res, Type=="main"),
             aes(xintercept = Accuracy), color="red") +
  geom_text(data = main_p_labs,
            aes(label = paste0("P = ", Acc_p, "\nBH-FDR = ", Acc_p_adj)), 
            x = 0.68, y = 1400) +
  theme(plot.title = element_text(hjust=0.5))

ggsave("plots/Main_vs_Null_Acc_AROMA_2P_DiCER.png", width=10, 
       height=4, units="in", dpi=300)
```
```{r}
main_and_null_res %>%
  ggplot(data=subset(main_and_null_res, Type=="null"), 
         mapping=aes(x=Balanced_Accuracy)) +
  geom_histogram(fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Balanced Accuracy") +
  facet_grid(. ~ Noise_Proc) +
  geom_vline(data = subset(main_and_null_res, Type=="main"),
             aes(xintercept = Balanced_Accuracy), color="red") +
  geom_text(data = main_p_labs,
            aes(label = paste0("P = ", Bal_Acc_p, "\nBH-FDR = ", Bal_Acc_p_adj)), 
            x = 0.68, y = 1400) +
  theme(plot.title = element_text(hjust=0.5))

ggsave("plots/Main_vs_Null_Bal_Acc_AROMA_2P_DiCER.png", width=10, 
       height=4, units="in", dpi=300)
```

```{r}
main_p_values %>%
  group_by(Noise_Proc) %>%
  summarise(num_sig_acc = sum(Acc_p < 0.05),
            num_sig_acc_fdr = sum(Acc_p_adj < 0.05),
            num_sig_bacc = sum(Bal_Acc_p < 0.05),
            num_sig_bacc_fdr = sum(Bal_Acc_p_adj < 0.05))
```