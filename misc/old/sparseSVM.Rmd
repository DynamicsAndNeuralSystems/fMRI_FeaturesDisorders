---
title: "sparseSVM"
author: "Annie Bryant"
date: "31/05/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
github_dir <- "D:/Virtual_Machines/Shared_Folder/github/fMRI_FeaturesDisorders/"
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"

# TO-DO: abstract out PCA functions to a helper script
library(tidyverse)
library(sparseSVM)
library(cowplot)
theme_set(theme_cowplot())

noise_proc = "AROMA+2P"
# Clean up names
noise_label <- gsub("\\+", "_", noise_proc)

# Load catch22 data for current noise processing method
feature_matrix <- readRDS(paste0(rdata_path, sprintf("UCLA_%s_catch22.Rds", 
                                                     noise_label)))      
```


Pivot dataset from long to wide

```{r}
data_for_svm <- feature_matrix %>%
  mutate(Unique_ID = paste0(names, "_", Brain_Region),
         .keep = "unused") %>%
  pivot_wider(id_cols = c(Subject_ID, group),
              names_from = Unique_ID, 
              values_from = values) %>%
  drop_na()
  

svm_mat <- data_for_svm %>%
  dplyr::select(-Subject_ID, -group) %>%
  as.matrix()

```

in-sample SVM + predictions

```{r}
sparse_SVM_res <- sparseSVM(X = svm_mat,
                            y = data_for_svm$group,
                            alpha = 1,
                            message = TRUE)

in_sample_pred <- predict(sparse_SVM_res, svm_mat)
actual_prop <- sum(data_for_svm$group == "Schz")/length(data_for_svm$group)

as.data.frame(in_sample_pred) %>%
  mutate(row_id = row_number()) %>%
  pivot_longer(cols = c(-row_id),
               names_to = "lambda",
               values_to = "prediction") %>%
  group_by(lambda) %>%
  summarise(num_control = sum(prediction == "Control"),
            num_schiz = sum(prediction == "Schz"),
            schz_prop = num_schiz / num_control) %>%
  mutate(lambda = as.numeric(lambda)) %>%
  ggplot(data = ., mapping = aes(x = lambda, y = schz_prop)) +
  geom_bar(stat = "identity", color="dodgerblue") +
  ylab("Schz Proportion") +
  ggtitle("In-sample Predicted Proportion of Schz Subjects\nby lambda value from sparseSVM package") +
  geom_hline(yintercept = actual_prop, 
             linetype = 2) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 20))
```

in-sample accuracy
```{r}
as.data.frame(in_sample_pred) %>%
  mutate(row_id = row_number(),
         actual_group = data_for_svm$group) %>%
  pivot_longer(cols = c(-row_id, -actual_group),
               names_to = "lambda",
               values_to = "predicted_group") %>%
  mutate(predicted_group = factor(predicted_group, levels = unique(actual_group)),
         actual_group = factor(actual_group, levels = unique(actual_group))) %>%
  group_by(lambda) %>%
  summarise(accuracy = sum(predicted_group == actual_group) / n(),
            balanced_accuracy = caret::confusionMatrix(reference=actual_group, 
                                                           data=predicted_group)$byClass[["Balanced Accuracy"]])  %>%
      mutate(lambda = as.numeric(lambda)) %>%
  ggplot(data=., mapping=aes(x = lambda, y = balanced_accuracy)) +
  geom_line() +
  ylab("Balanced Accuracy") +
  ggtitle("In-Sample Balanced Accuracy with Unweighted sparseSVM") +
  theme(legend.position = "none")
```


10-fold CV SVM + predictions

```{r}
k = 10
input_groups <- data_for_svm$group
input_groups <- factor(input_groups)

# Create train/test data folds
set.seed(127)
flds <- caret::createFolds(input_groups, k = 10, list = T, returnTrain = FALSE)
sparse_svm_CV_res_list <- list()

# Iterate over folds 1 through k
  for (i in 1:k) {
    
    # Define test and train data
    test_i <- flds[[i]]
    train_i <- setdiff(1:nrow(svm_mat), test_i)
    
    train_data <- svm_mat[train_i, ]
    train_group <- input_groups[train_i]
    test_data <- svm_mat[test_i, ]
    test_group <- input_groups[test_i]
    
    # Run linear SVM on fold
    svmModel <- sparseSVM(X = train_data,
                          y = train_group,
                          alpha = 1,
                          message = FALSE)
    
    # Generate out-of-sample predictions based on SVM model
    prediction_res <- as.data.frame(predict(svmModel, test_data)) %>%
      mutate(row_id = row_number(),
             actual_group = test_group) %>%
      pivot_longer(cols = c(-row_id, -actual_group),
                   names_to = "lambda",
                   values_to = "predicted_group") %>%
      mutate(predicted_group = factor(predicted_group, levels = levels(test_group))) %>%
      group_by(lambda) %>%
      summarise(predicted_control_n = sum(predicted_group == "Control"),
                actual_control_n = sum(actual_group == "Control"),
                predicted_schiz_n = sum(predicted_group == "Schz"),
                actual_schiz_n = sum(actual_group == "Schz"),
                predicted_schz_prop = predicted_schiz_n / predicted_control_n,
                actual_schz_prop = actual_schiz_n / actual_control_n,
                accuracy = sum(predicted_group == actual_group) / n(),
                balanced_accuracy = caret::confusionMatrix(reference=test_group, 
                                                           data=predicted_group)$byClass[["Balanced Accuracy"]]) %>%
      mutate(lambda = as.numeric(lambda),
             fold_number = i)
    
    sparse_svm_CV_res_list <- rlist::list.append(sparse_svm_CV_res_list, prediction_res)
  } 

sparse_svm_CV_res <- do.call(plyr::rbind.fill, sparse_svm_CV_res_list)
```


```{r}
sparse_svm_CV_res %>%
  mutate(fold_number = as.character(fold_number)) %>%
  ggplot(data = ., mapping = aes(x = lambda, y = predicted_schz_prop)) +
  geom_line(aes(group = fold_number, color = fold_number)) +
  ylab("Schz Proportion") +
  ggtitle("10-fold CV Predicted Proportion of Schz Subjects\nby lambda value from sparseSVM package") +
  geom_hline(yintercept = actual_prop, 
             linetype = 2) +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(color = "Fold") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

```{r}
sparse_svm_CV_res %>%
  mutate(fold_number = as.character(fold_number)) %>%
  ggplot(data = ., mapping = aes(x = lambda, y = balanced_accuracy)) +
  geom_line(aes(group = fold_number, color = fold_number)) +
  ylab("Balanced Accuracy") +
  ggtitle("10-fold CV Prediction Balanced Accuracy\nby lambda value from sparseSVM package") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(color = "Fold") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

