---
title: "Step 3: ROI-Wise catch22 Feature Analysis"
output: 
  github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
```

### Source functions
```{r}
source("../helper_functions/Linear_SVM.R")
source("../helper_functions/Visualization.R")
source("../helper_functions/Null_distributions.R")
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"
set.seed(127)
```


## In-sample SVM classification

### Simple in-sample linear SVM

We will start with a simple linear SVM classifier using all 22 features.

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_", test_package, ".Rds"))) {
  region_wise_SVM_in_sample <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                              svm_kernel = kernel,
                                                              test_package = test_package,
                                                              grouping_var = "Brain_Region",
                                                              svm_feature_var = "Feature",
                                                              noise_procs = noise_procs,
                                                              use_inv_prob_weighting = FALSE,
                                                               use_SMOTE = FALSE)
  saveRDS(region_wise_SVM_in_sample, file=paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_", test_package, ".Rds"))
} else {
  region_wise_SVM_in_sample <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_", test_package, ".Rds"))
}
```

```{r, fig.width=7, fig.height=5}
plot_class_acc_w_props(class_res = region_wise_SVM_in_sample,
                       group_var = "Brain_Region",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```
```{r, echo=F}
# Save plot
ggsave("plots/Region_Wise_In_Sample_SVM.png",
       width=7, height=5, units="in", dpi=300)
```
The above figure shows the in-sample results from running `e1071::svm` using all 22 catch22 features. The dashed line in the accuracy plot (left) shows the proportion of control subjects for each noise-processing method, and the dashed line in the balanced accuracy plot (right) is set at 0.5 -- the value when all subjects are classified as controls.

Clearly, the classification algorithm is biased for the majority of ROIs to classify all samples as controls in order to achieve a raw accuracy of ~0.7. Similarly, the balanced accuracy has a clear peak around 0.5.

This highlights the need to mitigate the class imbalances, either with inverse probability sample reweighting.


### In-sample linear SVM with inverse probability weighting

We can run linear SVM with the `e1071` package to directly test sample reweighting with in-sample accuracy and balanced accuracy. We will use inverse probability weighting, meaning that the weight given to a particular sample in the SVM classifier is inversely proportionate to the class size to which the sample belongs.  

By assigning each subject a weight equivalent to the inverse proportion of that subject's diagnosis, the linear SVM places a higher cost on incorrectly classifying schizophrenia subjects as controls. 

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_inv_prob_", test_package, ".Rds"))) {
  region_wise_SVM_in_sample_inv_prob <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                                       svm_kernel = kernel,
                                                                       test_package = test_package,
                                                                       grouping_var = "Brain_Region",
                                                                       svm_feature_var = "Feature",
                                                                       noise_procs = noise_procs,
                                                                       use_inv_prob_weighting = TRUE)
  saveRDS(region_wise_SVM_in_sample_inv_prob, file=paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_inv_prob_", test_package, ".Rds"))
} 

```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
region_wise_SVM_in_sample_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_inv_prob_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = region_wise_SVM_in_sample_inv_prob,
                       group_var = "Brain_Region",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Region_Wise_In_Sample_SVM_Inv_Prob.png",
       width=7, height=5, units="in", dpi=300)
```

This shifts the raw accuracy down to a mean of 0.68 to 0.7 across the three noise-processing methods, but the balanced accuracy increases to have a similar mean range -- compared with the majority of values around 0.5 previously. 

This indicates that inverse probability reweighting mitigates the class imbalance issue and can be carried forward into 10-fold cross-validation linear SVM.

### In-sample linear SVM with SMOTE

We can run linear SVM with the `e1071` package to directly test sample reweighting with in-sample accuracy and balanced accuracy. We will use inverse probability weighting, meaning that the weight given to a particular sample in the SVM classifier is inversely proportionate to the class size to which the sample belongs.  

By assigning each subject a weight equivalent to the inverse proportion of that subject's diagnosis, the linear SVM places a higher cost on incorrectly classifying schizophrenia subjects as controls. 

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_SMOTE_", test_package, ".Rds"))) {
  region_wise_SVM_in_sample_SMOTE <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                                       svm_kernel = kernel,
                                                                       test_package = test_package,
                                                                       grouping_var = "Brain_Region",
                                                                       svm_feature_var = "Feature",
                                                                       noise_procs = noise_procs,
                                                                       use_inv_prob_weighting = FALSE,
                                                                       use_SMOTE = TRUE)
  saveRDS(region_wise_SVM_in_sample_SMOTE, file=paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_SMOTE_", test_package, ".Rds"))
} 

```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
region_wise_SVM_in_sample_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_SMOTE_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = region_wise_SVM_in_sample_SMOTE,
                       group_var = "Brain_Region",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Region_Wise_In_Sample_SVM_SMOTE.png",
       width=7, height=5, units="in", dpi=300)
```

This shifts the raw accuracy down to a mean of 0.68 to 0.7 across the three noise-processing methods, but the balanced accuracy increases to have a similar mean range -- compared with the majority of values around 0.5 previously. 

This indicates that inverse probability reweighting mitigates the class imbalance issue and can be carried forward into 10-fold cross-validation linear SVM.


## Cross-validated SVM classification

### 10-fold cross-validated linear SVM

I have chosen to use 10-fold cross validation via manual implementation, as the sample reweighting options in caret were limited and difficult to interpret.

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, ".Rds"))) {
  region_wise_SVM_CV <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                       test_package = test_package,
                                                       svm_kernel = kernel,
                                                       grouping_var = "Brain_Region",
                                                       svm_feature_var = "Feature",
                                                       use_inv_prob_weighting = FALSE,
                                                       use_SMOTE = FALSE,
                                                       noise_procs = noise_procs)
  saveRDS(region_wise_SVM_CV, file=paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, ".Rds"))
}
```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
region_wise_SVM_CV <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = region_wise_SVM_CV,
                       group_var = "Brain_Region",
                       cv = TRUE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Region_Wise_CV_SVM.png",
       width=7, height=5, units="in", dpi=300)
```

Interestingly, unlike the in-sample results, there is a fair spread of accuracy and balanced accuracy values outside of the proportions expected from classifying all subjects as controls.

However, there still is a balanced accuracy peak around 0.5, so we move forward with inverse probability reweighting.

### 10-fold cross-validated linear SVM with inverse probability weighting

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"


# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, "_inv_prob.Rds"))) {
  region_wise_SVM_CV_inv_prob <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                                svm_kernel = kernel,
                                                                test_package = test_package,
                                                                grouping_var = "Brain_Region",
                                                                svm_feature_var = "Feature",
                                                                use_inv_prob_weighting = TRUE,
                                                                noise_procs = noise_procs)
  saveRDS(region_wise_SVM_CV_inv_prob, file=paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, "_inv_prob.Rds"))
}
```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
region_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = region_wise_SVM_CV_inv_prob,
                       group_var = "Brain_Region",
                       cv = TRUE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Region_Wise_CV_SVM_Inv_Prob.png",
       width=7, height=5, units="in", dpi=300)
```

As with the in-sample results, the accuracy values are negatively shifted while the balanced accuracy values are positively shifted after applying inverse probability reweighting to the samples.

### 10-fold cross-validated linear SVM with SMOTE
sa[']
```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, "_SMOTE.Rds"))) {
  region_wise_SVM_CV_SMOTE <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                         svm_kernel = kernel,
                                                         test_package = test_package,
                                                         grouping_var = "Brain_Region",
                                                         svm_feature_var = "Feature",
                                                         use_inv_prob_weighting = FALSE,
                                                         use_SMOTE = TRUE,
                                                         noise_procs = noise_procs)
  saveRDS(region_wise_SVM_CV_SMOTE, file=paste0(rdata_path, "ROI_wise_linear_SVM_CV_", test_package, "_SMOTE.Rds"))
}
```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
region_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = region_wise_SVM_CV_SMOTE,
                       group_var = "Brain_Region",
                       cv = TRUE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)

# Save plot
ggsave("plots/Region_Wise_CV_SVM_SMOTE.png",
       width=7, height=5, units="in", dpi=300)
```

As with the in-sample results, the accuracy values are negatively shifted while the balanced accuracy values are positively shifted after applying inverse probability reweighting to the samples.

## Model-free shuffle null distribution

### Generating null distributions from model-free shuffles

This first model-free shuffles method is borrowed from Trent's implementation in theft. With this method, the input class labels (Schz or Control) are randomly shuffled N times, and for each iteration, the classification accuracy and balanced accuracy are calculated. This yields a null distribution of accuracies and balanced accuracies, circumventing the need for running any classification algorithms across iterations.

Here, I've run 1,000,000 iterations of the model-free shuffle, generating 1,000,000 null values for Accuracy and Balanced Accuracy, respectively. Since this method is independent of brain region, the same null distribution can be used to compare with each brain region separately.

```{r}
# Try three different noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# One without minority upsampling
if (!file.exists(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))) {
  model_free_shuffle_null_res <- run_model_free_n_shuffles(num_shuffles = 1000000,
                                                    rdata_path = rdata_path,
                                                    noise_procs = noise_procs)
  saveRDS(model_free_shuffle_null_res, file = paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
} else {
  model_free_shuffle_null_res <- readRDS(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
}
```

### CV linear SVM
```{r, fig.width=7, fig.height=5}
region_wise_SVM_CV <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_CV,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "CV linear SVM Results vs. Model-Free Shuffles")

# Save plot
ggsave("plots/Region_Wise_CV_Null_vs_Real_Model_Free_Shuffle.png",
       width=7, height=5, units="in", dpi=300)
```

I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 82 ROIs on the left. Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
region_wise_SVM_CV <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071.Rds"))
if (!file.exists(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_pvals.Rds"))) {
  region_wise_SVM_CV_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_CV,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_CV_pvals, file=paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_pvals.Rds"))
} else {
  region_wise_SVM_CV_pvals <- readRDS(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_pvals.Rds"))
}

region_wise_SVM_CV_plabs <- truncate_p_values(region_wise_SVM_CV_pvals, N=3)
```


```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_CV_pvals,
                             null_res = model_free_shuffle_null_res,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P Brain Regions")

ggsave("plots/Region_Wise_Model_Free_Shuffle_Top5_Regions_CV_SVM_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_CV_pvals)
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.


### CV linear SVM -- inv prob
```{r, fig.width=7, fig.height=5}
region_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_CV_inv_prob,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "CV Inv Prob Linear SVM Results vs. Model-Free Shuffles")

# Save plot
ggsave("plots/Region_Wise_CV_Null_vs_Real_Model_Free_Shuffle_inv_prob.png",
       width=7, height=5, units="in", dpi=300)
```



I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 82 ROIs on the left. Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
region_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_inv_prob.Rds"))
if (!file.exists(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))) {
  region_wise_SVM_CV_inv_prob_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_CV_inv_prob,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_CV_inv_prob_pvals, file=paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))
} else {
  region_wise_SVM_CV_inv_prob_pvals <- readRDS(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_inv_prob_pvals.Rds"))
}


region_wise_SVM_CV_inv_prob_plabs <- truncate_p_values(region_wise_SVM_CV_inv_prob_pvals)
```


```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_CV_inv_prob_pvals,
                             null_res = model_free_shuffle_null_res,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P Brain Regions, Inverse Probability")

# Save plot
ggsave("plots/Region_Wise_Model_Free_Shuffle_Top5_Regions_CV_SVM_Balanced_Accuracy_Inv_Prob.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_CV_inv_prob_pvals)
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.

### CV linear SVM -- SMOTE
```{r, fig.width=7, fig.height=5}
region_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_CV_SMOTE,
                       null_res = model_free_shuffle_null_res,
                       xlab = "Value from n=1,000,000 Model-Free Shuffles",
                       title = "CV SMOTE linear SVM Results vs. Model-Free Shuffles")

# Save plot
ggsave("plots/Region_Wise_CV_Null_vs_Real_Model_Free_Shuffle_SMOTE.png",
       width=7, height=5, units="in", dpi=300)
```


I've plotted the distribution of null accuracies (teal) alongside the actual accuracies (pink) for the 82 ROIs on the left. Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated balanced accuracy:

```{r}
# Calculate p values from model-free shuffle null distribution
region_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_SMOTE.Rds"))
if (!file.exists(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))) {
  region_wise_SVM_CV_SMOTE_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_CV_SMOTE,
                                                   null_data = model_free_shuffle_null_res,
                                                   grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_CV_SMOTE_pvals, file=paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))
} else {
  region_wise_SVM_CV_SMOTE_pvals <- readRDS(paste0(rdata_path, "ROI_wise_CV_linear_SVM_e1071_SMOTE_pvals.Rds"))
}

region_wise_SVM_CV_SMOTE_plabs <- truncate_p_values(region_wise_SVM_CV_SMOTE_pvals)
```


```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_CV_SMOTE_pvals,
                             null_res = model_free_shuffle_null_res,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P Brain Regions, SMOTE")

# Save plot
ggsave("plots/Region_Wise_Model_Free_Shuffle_Top5_Regions_CV_SVM_Balanced_Accuracy_SMOTE.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_CV_SMOTE_pvals)
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.

## Empirical model-based pooled null distribution

### Generating null distributions from pooled null model fits

In contrast to the model-free shuffle method, here we are actually shuffling the input class labels right before running the linear SVM over N=10 iterations per ROI (N=82) and pooling the resulting accuracy and balanced accuracy values, to generate empirical null distributions of N=820 data points each, respectively.

### In-sample

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample.Rds"))) {
  model_permutation_null_in_sample <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Brain_Region",
                                                                    svm_feature_var = "Feature",
                                                                    num_permutations = 10,
                                                                    use_inv_prob_weighting = FALSE,
                                                                    cross_validate = FALSE)
  
  saveRDS(model_permutation_null_in_sample, file=paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample.Rds"))
} else {
  model_permutation_null_in_sample <- readRDS(paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample.Rds"))
}

# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_in_sample %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=7, fig.height=5}
# Plot null accuracy and balanced accuracy compared with real metrics:
region_wise_SVM_in_sample <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_e1071.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_in_sample,
                       null_res = model_permutation_null_in_sample,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "In-sample linear SVM Results vs.\nNull Model Fits")

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_In_Sample_Balanced_Accuracy.png",
       width=7, height=5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
region_wise_SVM_in_sample <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_e1071.Rds"))

if (!file.exists(paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals.Rds"))) {
  region_wise_SVM_in_sample_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_in_sample,
                                                          null_data = model_permutation_null_in_sample,
                                                          grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_in_sample_pvals, file=paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals.Rds"))
} else {
  region_wise_SVM_in_sample_pvals <- readRDS(paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals.Rds"))
}

region_wise_SVM_in_sample_plabs <- truncate_p_values(region_wise_SVM_in_sample_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_in_sample_pvals,
                             null_res = model_permutation_null_in_sample,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Null Model Fit Balanced Accuracy\nfor top AROMA+2P Brain Regions, In-Sample",
                             yloc = 45,
                             xloc = 0.65)

# Save plots
ggsave("plots/Region_Wise_Null_Model_Fit_Top5_Regions_In_Sample_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_in_sample_pvals)
```

### In-sample, inverse probability weighted

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample_inv_prob.Rds"))) {
  model_permutation_null_in_sample_inv_prob <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Brain_Region",
                                                                    svm_feature_var = "Feature",
                                                                    num_permutations = 10,
                                                                    use_inv_prob_weighting = TRUE,
                                                                    cross_validate = FALSE)
  
  saveRDS(model_permutation_null_in_sample_inv_prob, file=paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample_inv_prob.Rds"))
} else {
  model_permutation_null_in_sample_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_model_permutation_null_in_sample_inv_prob.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_in_sample_inv_prob %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=7, fig.height=5}
# Plot null accuracy and balanced accuracy compared with real metrics:
region_wise_SVM_in_sample_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_inv_prob_e1071.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_in_sample_inv_prob,
                       null_res = model_permutation_null_in_sample_inv_prob,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "In-sample Inv Prob linear SVM Results vs.\nNull Model Fits")

ggsave("plots/Region_Wise_Null_Model_Fit_In_Sample_Balanced_Accuracy_Inv_Prob.png",
       width=7, height=5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
region_wise_SVM_in_sample_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_in_sample_inv_prob_e1071.Rds"))

if (!file.exists(paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals_inv_prob.Rds"))) {
  region_wise_SVM_in_sample_inv_prob_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_in_sample_inv_prob,
                                                              null_data = model_permutation_null_in_sample_inv_prob,
                                                              grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_in_sample_inv_prob_pvals, file=paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals_inv_prob.Rds"))
} else {
  region_wise_SVM_in_sample_inv_prob_pvals <- readRDS(paste0(rdata_path, "ROI_wise_In_Sample_Null_Model_Fits_pvals_inv_prob.Rds"))
}

region_wise_SVM_in_sample_inv_prob_plabs <- truncate_p_values(region_wise_SVM_in_sample_inv_prob_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_in_sample_inv_prob_pvals,
                             null_res = model_permutation_null_in_sample_inv_prob,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Null Model Fit Balanced Accuracy\nfor top AROMA+2P Brain Regions, In-Sample Inv Prob",
                             xloc = 0.75, 
                             yloc = 6)

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_Top5_Regions_In_Sample_Inv_Prob_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_in_sample_inv_prob_pvals)
```




### CV, inverse probability weighted

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "ROI_wise_model_permutation_null_CV_inv_prob.Rds"))) {
  model_permutation_null_CV_inv_prob <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Brain_Region",
                                                                    svm_feature_var = "Feature",
                                                                    num_permutations = 10,
                                                                    use_inv_prob_weighting = TRUE,
                                                                    cross_validate = TRUE)
  
  saveRDS(model_permutation_null_CV_inv_prob, file=paste0(rdata_path, "ROI_wise_model_permutation_null_CV_inv_prob.Rds"))
} else {
  model_permutation_null_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_model_permutation_null_CV_inv_prob.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_CV_inv_prob %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=7, fig.height=5}
# Plot null accuracy and balanced accuracy compared with real metrics:
region_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_CV_inv_prob,
                       null_res = model_permutation_null_CV_inv_prob,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "CV Inv Prob linear SVM Results vs.\nNull Model Fits")

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_CV_Balanced_Accuracy_Inv_Prob.png",
       width=7, height=5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
region_wise_SVM_CV_inv_prob <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

if (!file.exists(paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_inv_prob.Rds"))) {
  region_wise_SVM_CV_inv_prob_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_CV_inv_prob,
                                                              null_data = model_permutation_null_CV_inv_prob,
                                                              grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_CV_inv_prob_pvals, file=paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_inv_prob.Rds"))
} else {
  region_wise_SVM_CV_inv_prob_pvals <- readRDS(paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_inv_prob.Rds"))
}

region_wise_SVM_CV_inv_prob_plabs <- truncate_p_values(region_wise_SVM_CV_inv_prob_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_CV_inv_prob_pvals,
                             null_res = model_permutation_null_CV_inv_prob,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Null Model Fit Balanced Accuracy\nfor top AROMA+2P Brain Regions, CV Inv Prob",
                             xloc = 0.6,
                             yloc = 4)

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_CV_Inv_Prob_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_CV_inv_prob_pvals)
```


### CV, SMOTE

```{r}
# Run null model permutation function
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
svm_kernel <- "linear"
set.seed(127)

if (!file.exists(paste0(rdata_path, "ROI_wise_model_permutation_null_CV_SMOTE.Rds"))) {
  model_permutation_null_CV_SMOTE <- run_null_model_n_permutations(rdata_path,
                                                                    noise_procs = noise_procs,
                                                                    grouping_var = "Brain_Region",
                                                                    svm_feature_var = "Feature",
                                                                    num_permutations = 10,
                                                                    use_inv_prob_weighting = TRUE,
                                                                    cross_validate = TRUE)
  
  saveRDS(model_permutation_null_CV_SMOTE, file=paste0(rdata_path, "ROI_wise_model_permutation_null_CV_SMOTE.Rds"))
} else {
  model_permutation_null_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_model_permutation_null_CV_SMOTE.Rds"))
}
# Find number of iterations for plot label
num_null_dist_values <- nrow(model_permutation_null_CV_SMOTE %>% filter(Noise_Proc == "AROMA+2P"))
```


```{r, fig.width=7, fig.height=5}
# Plot null accuracy and balanced accuracy compared with real metrics:
region_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

plot_main_vs_null_hist(main_res = region_wise_SVM_CV_SMOTE,
                       null_res = model_permutation_null_CV_SMOTE,
                       xlab = sprintf("Value from n=%s Null Model Fit Shuffles", num_null_dist_values),
                       title = "CV SMOTE linear SVM Results vs.\nNull Model Fits")

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_CV_Balanced_Accuracy_SMOTE.png",
       width=7, height=5, units="in", dpi=300)
```

The fitted empirical null model distribution is fairly similar to the real accuracy and balanced accuracy values using in-sample linear SVM with no reweighting. 

```{r}
region_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "ROI_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

if (!file.exists(paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_SMOTE.Rds"))) {
  region_wise_SVM_CV_SMOTE_pvals <- calc_empirical_nulls(class_res = region_wise_SVM_CV_SMOTE,
                                                              null_data = model_permutation_null_CV_SMOTE,
                                                              grouping_var = "Brain_Region")
  saveRDS(region_wise_SVM_CV_SMOTE_pvals, file=paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_SMOTE.Rds"))
} else {
  region_wise_SVM_CV_SMOTE_pvals <- readRDS(paste0(rdata_path, "ROI_wise_CV_Null_Model_Fits_pvals_SMOTE.Rds"))
}

region_wise_SVM_CV_SMOTE_plabs <- truncate_p_values(region_wise_SVM_CV_SMOTE_pvals)
```

```{r, fig.width=10, fig.height=5}
plot_top_5_vars_main_vs_null(class_res_pvals = region_wise_SVM_CV_SMOTE_pvals,
                             null_res = model_permutation_null_CV_SMOTE,
                             xlab = "Value",
                             ylab = "Scaled Density of Null Iterations",
                             title = "Main and Null Model Fit Balanced Accuracy\nfor top AROMA+2P Brain Regions, CV SMOTE",
                             xloc = 0.6,
                             yloc = 4)

# Save plot
ggsave("plots/Region_Wise_Null_Model_Fit_Top5_Regions_CV_SMOTE_Balanced_Accuracy.png", width=10, 
       height=5, units="in", dpi=300)
```

```{r}
summarise_num_sig_features(region_wise_SVM_CV_SMOTE_pvals)
```


## Comparing model-free shuffle with pooled empirical null distributions

```{r, fig.width = 7, fig.height = 7}
# In-sample inverse probability
in_sample_inv_prob_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_in_sample_inv_prob %>% 
                     mutate(Null_Type = "Null Model Fit, In-sample Inv Prob")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, CV Inv Prob",
                                                  "Null Model Fit, CV SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 0.8)) +
  ylab("") +
  xlab("") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, CV Inv Prob" = "dodgerblue",
                                  "Null Model Fit, CV SMOTE" = "green"))

# CV inverse probability
CV_inv_prob_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_CV_inv_prob %>% 
                     mutate(Null_Type = "Null Model Fit, CV Inv Prob")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, CV Inv Prob",
                                                  "Null Model Fit, CV SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 0.8)) +
  ylab("Scaled Density") +
  xlab("") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, CV Inv Prob" = "dodgerblue",
                                  "Null Model Fit, CV SMOTE" = "green"))

# CV SMOTE
CV_SMOTE_p <- model_free_shuffle_null_res %>%
  mutate(Null_Type = "Model-Free Shuffle") %>%
  plyr::rbind.fill(model_permutation_null_CV_SMOTE %>% 
                     mutate(Null_Type = "Null Model Fit, CV SMOTE")) %>%
  mutate(Null_Type = factor(Null_Type, levels = c("Model-Free Shuffle",
                                                  "Null Model Fit, In-sample Inv Prob",
                                                  "Null Model Fit, CV Inv Prob",
                                                  "Null Model Fit, CV SMOTE"))) %>%
  ggplot(data=., mapping=aes(x=balanced_accuracy, fill=Null_Type)) +
  geom_histogram(alpha=0.5, 
                 aes(y=0.5*..density..), 
                 position="identity",
                 bins = 50) +
  scale_x_continuous(limits = c(0.3, 0.8)) +
  ylab("") +
  xlab("Balanced Accuracy") +
  labs(fill = "Null Type") +
  scale_fill_manual(values = list("Model-Free Shuffle" = "gray70", 
                                  "Null Model Fit, In-sample Inv Prob" = "coral",
                                  "Null Model Fit, CV Inv Prob" = "dodgerblue",
                                  "Null Model Fit, CV SMOTE" = "green"))

in_sample_inv_prob_p / CV_inv_prob_p / CV_SMOTE_p  + 
  plot_annotation(title = "Null Distributions by Model Type") + 
  plot_layout(guides = "collect") & 
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow=2,byrow=TRUE))
ggsave("plots/Null_Distributions_by_Model_Type.png",
       width = 7, height = 7, units = "in", dpi=300)
```

 