to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
lookup_list <- list("NAME" = sprintf("univariate_%s_wise_null_model_fit",
grouping_type),
"MEMNUM" = "20",
"NCPUS" = "1",
"DATASET_ID" = dataset_ID,
"GITHUB_DIR" = github_dir,
"DATA_PATH" = data_path,
"EMAIL" = "abry4213@uni.sydney.edu.au",
"PBS_NOTIFY" = "a",
"WALL_HRS" = wall_hrs,
"NUM_K_FOLDS" = num_k_folds,
"NUM_PERMS_PER_ITER" = nperm_per_iter,
"OUTPUT_DATA_DIR" = output_data_dir,
"UNIVARIATE_FEATURE_SET" = univariate_feature_set,
"PAIRWISE_FEATURE_SET" = pairwise_feature_set,
"GROUPING_VAR" = grouping_var,
"SVM_FEATURE_VAR" = SVM_feature_var,
"WEIGHTING_NAME" = weighting_name)
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
source("~/github/fMRI_FeaturesDisorders/helper_functions/classification/Linear_SVM.R")
for (p in 1:num_permutations) {
# Run command if null file doesn't exist
if (!file.exists(sprintf("%s/%s_wise_%s_%s_null_model_fit_iter_%s.Rds",
output_data_dir,
grouping_var,
univariate_feature_set,
weighting_name, p))) {
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
system(paste0("qsub ", output_scripts_dir, "null_iter_", p, ".pbs"))
}
}
for (p in 1:num_permutations) {
# Run command if null file doesn't exist
if (!file.exists(sprintf("%s/%s_wise_%s_%s_null_model_fit_iter_%s.Rds",
output_data_dir,
grouping_var,
univariate_feature_set,
weighting_name, p))) {
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
system(paste0("qsub ", output_scripts_dir, "null_iter_", p, ".pbs"))
}
}
num_permutations = 10
for (p in 1:num_permutations) {
# Run command if null file doesn't exist
if (!file.exists(sprintf("%s/%s_wise_%s_%s_null_model_fit_iter_%s.Rds",
output_data_dir, grouping_var, univariate_feature_set,
weighting_name, p))) {
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
system(paste0("qsub ", output_scripts_dir, "null_iter_", p, ".pbs"))
}
}
num_permutations = 1000
for (p in 1:num_permutations) {
# Run command if null file doesn't exist
if (!file.exists(sprintf("%s/%s_wise_%s_%s_null_model_fit_iter_%s.Rds",
output_data_dir, grouping_var, univariate_feature_set,
weighting_name, p))) {
cat("\nNow running null perms for iteration", p, "\n")
new_pbs_file <- readLines(template_pbs_file)
# Replace file paths
pbs_text_replaced <- mgsub::mgsub(new_pbs_file,
to_be_replaced,
replacement_values)
# Replace null iteration number
pbs_text_replaced <- gsub("iterj", p, pbs_text_replaced)
# Write updated PBS script to file
output_pbs_file <- writeLines(pbs_text_replaced,
paste0(output_scripts_dir,
"null_iter_", p, ".pbs"))
system(paste0("qsub ", output_scripts_dir, "null_iter_", p, ".pbs"))
}
}
univariate_feature_set <- "catch22"
pairwise_feature_set <- "pyspi_19"
subject_csv <- "participants.csv"
github_dir <- "/headnode1/abry4213/github/fMRI_FeaturesDisorders/"
rdata_path <- "/headnode1/abry4213/data/ABIDE_ASD/Rdata/"
data_path <- "/headnode1/abry4213/data/ABIDE_ASD/"
dataset_ID <- "ABIDE_ASD"
noise_procs <- c("FC1000")
svm_kernel = "linear"
grouping_var = "Brain_Region"
svm_feature_var = "Feature"
noise_proc = "AROMA+2P+GMR"
noise_Proc = "FC1000"
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
paste(noise_procs, collapse=" ")
noise_proc="FC1000"
num_k_folds=10
use_inv_prob_weighting=T
num_perms_for_iter=10
null_iter_number=1
null_out <- 1:num_perms_for_iter  %>%
purrr::map_df( ~ run_univariate_cv_svm_by_input_var(data_path = data_path,
dataset_ID = dataset_ID,
svm_kernel = svm_kernel,
pairwise_feature_set = pairwise_feature_set,
univariate_feature_set = univariate_feature_set,
grouping_var = grouping_var,
svm_feature_var = svm_feature_var,
noise_procs = noise_proc,
num_k_folds = num_k_folds,
out_of_sample_only = TRUE,
use_inv_prob_weighting = use_inv_prob_weighting,
shuffle_labels = T) %>%
# Keep track of which null iteration this is
mutate(Null_Iter_Number = .x + (.x * (as.numeric(null_iter_number) - 1))))
library(tidyverse)
source("~/github/fMRI_FeaturesDisorders/helper_functions/classification/Linear_SVM.R")
null_out <- 1:num_perms_for_iter  %>%
purrr::map_df( ~ run_univariate_cv_svm_by_input_var(data_path = data_path,
dataset_ID = dataset_ID,
svm_kernel = svm_kernel,
pairwise_feature_set = pairwise_feature_set,
univariate_feature_set = univariate_feature_set,
grouping_var = grouping_var,
svm_feature_var = svm_feature_var,
noise_procs = noise_proc,
num_k_folds = num_k_folds,
out_of_sample_only = TRUE,
use_inv_prob_weighting = use_inv_prob_weighting,
shuffle_labels = T) %>%
# Keep track of which null iteration this is
mutate(Null_Iter_Number = .x + (.x * (as.numeric(null_iter_number) - 1))))
num_perms_for_iter=2
null_out <- 1:num_perms_for_iter  %>%
purrr::map_df( ~ run_univariate_cv_svm_by_input_var(data_path = data_path,
dataset_ID = dataset_ID,
svm_kernel = svm_kernel,
pairwise_feature_set = pairwise_feature_set,
univariate_feature_set = univariate_feature_set,
grouping_var = grouping_var,
svm_feature_var = svm_feature_var,
noise_procs = noise_proc,
num_k_folds = num_k_folds,
out_of_sample_only = TRUE,
use_inv_prob_weighting = use_inv_prob_weighting,
shuffle_labels = T) %>%
# Keep track of which null iteration this is
mutate(Null_Iter_Number = .x + (.x * (as.numeric(null_iter_number) - 1))))
null_out <- null_out %>%
group_by(grouping_var, Noise_Proc, Sample_Type, Null_Iter_Number) %>%
summarise(accuracy = sum(Prediction_Correct) / n(),
balanced_accuracy = caret::confusionMatrix(data = Predicted_Diagnosis,
reference = Actual_Diagnosis)$byClass[["Balanced Accuracy"]])
View(null_out)
rdata_path <- "/headnode1/abry4213/data/UCLA_Schizophrenia/Rdata/"
data_path <- "/headnode1/abry4213/data/UCLA_Schizophrenia/"
dataset_ID <- "UCLA_Schizophrenia"
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
rdata_path <- "/headnode1/abry4213/data/UCLA_Schizophrenia/Rdata/"
data_path <- "/headnode1/abry4213/data/UCLA_Schizophrenia/"
dataset_ID <- "UCLA_Schizophrenia"
noise_proc <- "AROMA+2P+GMR"
kernel = "linear"
subjects_to_use <- readRDS(paste0(data_path, sprintf("%s_samples_with_univariate_%s_and_pairwise_%s.Rds",
dataset_ID,
univariate_feature_set,
pairwise_feature_set)))
if (!file.exists(paste0(rdata_path, dataset_ID, "_samples_per_10_folds.Rds"))) {
# Make folds
set.seed(127)
k = 10
sample_folds <- caret::createFolds(subjects_to_use$Diagnosis, k = k, list = TRUE, returnTrain = FALSE)
# Save to Rds file
saveRDS(sample_folds, file=paste0(rdata_path, dataset_ID, "_samples_per_10_folds.Rds"))
} else {
sample_folds <- readRDS(paste0(rdata_path, dataset_ID, "_samples_per_10_folds.Rds"))
}
grouping_param_df <- data.frame(grouping_type = c("ROI", "Feature", "Combo"),
grouping_var = c("Brain_Region", "Feature", "Combo"),
SVM_feature_var = c("Feature", "Brain_Region", "Combo"))
weighting_param_df <- data.frame(name = c("inv_prob"),
use_inv_prob_weighting = c(TRUE))
i = 1
j = 1
grouping_type = grouping_param_df$grouping_type[i]
grouping_var = grouping_param_df$grouping_var[i]
SVM_feature_var = grouping_param_df$SVM_feature_var[i]
weighting_name <- weighting_param_df$name[j]
use_inv_prob_weighting <- weighting_param_df$use_inv_prob_weighting[j]
output_data_dir <- paste0(rdata_path, sprintf("%s_%s_wise_%s_%s_null_model_fits/",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name))
list.files(output_data_dir, pattern="Rds")
model_permutation_null_weighting <- list.files(output_data_dir, pattern="Rds") %>%
purrr::map_df(~ readRDS(paste0(output_data_dir, .x)))
saveRDS(model_permutation_null_weighting, paste0(rdata_path, sprintf("%s_%s_wise_model_permutation_null_%s_%s.Rds",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name)))
group_wise_SVM_balanced_accuracy <- readRDS(paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_%s_%s_balacc.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))
pvalues <- calc_empirical_nulls(class_res = group_wise_SVM_balanced_accuracy,
null_data = model_permutation_null_weighting,
feature_set = univariate_feature_set,
use_pooled_null = TRUE,
is_main_data_averaged = TRUE,
grouping_var = grouping_var)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
helper_script_dir = "../helper_functions/classification/"
source(paste0(helper_script_dir, "Linear_SVM.R"))
source(paste0(helper_script_dir, "Null_distributions.R"))
pvalues <- calc_empirical_nulls(class_res = group_wise_SVM_balanced_accuracy,
null_data = model_permutation_null_weighting,
feature_set = univariate_feature_set,
use_pooled_null = TRUE,
is_main_data_averaged = TRUE,
grouping_var = grouping_var)
source("~/github/fMRI_FeaturesDisorders/helper_functions/classification/Null_distributions.R")
# Calculate p-values
pvalues <- calc_empirical_nulls(class_res = group_wise_SVM_balanced_accuracy,
null_data = model_permutation_null_weighting,
feature_set = univariate_feature_set,
use_pooled_null = TRUE,
is_main_data_averaged = TRUE,
grouping_var = grouping_var)
saveRDS(pvalues, file=paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_model_permutation_null_%s_%s_pvals.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))
View(pvalues)
View(model_permutation_null_weighting)
View(null_out)
class_res = group_wise_SVM_balanced_accuracy
null_data = model_permutation_null_weighting
feature_set = univariate_feature_set
use_pooled_null = TRUE
is_main_data_averaged = TRUE
list.append <- function (.data, ...)
{
if (is.list(.data)) {
c(.data, list(...))
}
else {
c(.data, ..., recursive = FALSE)
}
}
is_main_data_averaged = TRUE
is_null_data_averaged = TRUE
merged_list <- list()
if (!("Sample_Type" %in% colnames(null_data))) {
null_in <- null_data %>%
mutate(Sample_Type = "In-sample")
null_out <- null_data %>%
mutate(Sample_Type = "Out-of-sample")
null_data <- plyr::rbind.fill(null_in, null_out)
}
if (!("grouping_var" %in% colnames(class_res))) {
class_res <- class_res %>%
dplyr::rename("grouping_var" = grouping_var)
}
if (!is_main_data_averaged) {
class_res <- class_res %>%
group_by(Sample_Type, grouping_var, Noise_Proc) %>%
summarise(accuracy_avg = mean(accuracy, na.rm=T),
accuracy_SD = sd(accuracy, na.rm=T),
balanced_accuracy_avg = mean(balanced_accuracy, na.rm=T),
balanced_accuracy_SD = sd(balanced_accuracy, na.rm=T)) %>%
dplyr::rename("accuracy"="accuracy_avg",
"balanced_accuracy"="balanced_accuracy_avg")
}
main_res <- class_res %>%
dplyr::select(grouping_var, Sample_Type, Noise_Proc, accuracy, balanced_accuracy) %>%
mutate(Type = "main") %>%
pivot_longer(cols=c(accuracy, balanced_accuracy),
names_to="Metric",
values_to="Value") %>%
pivot_wider(id_cols = c(grouping_var, Noise_Proc,
Type, Sample_Type),
names_from = Metric, values_from = Value)
View(main_res)
group_var = unique(class_res$grouping_var)[1]
if ("grouping_var" %in% colnames(null_data) & !(use_pooled_null)) {
group_null <- null_data %>%
dplyr::filter(grouping_var == group_var)
} else {
group_null <- null_data %>%
dplyr::mutate(grouping_var = group_var)
}
View(group_null)
group_main <- subset(main_res, grouping_var == group_var)
group_null$Type <- "null"
View(group_main)
if (!("Noise_Proc" %in% colnames(group_null))) {
group_null <- plyr::rbind.fill(group_null %>% mutate(Noise_Proc = "AROMA+2P"),
group_null %>% mutate(Noise_Proc = "AROMA+2P+GMR")) %>%
plyr::rbind.fill(., group_null %>% mutate(Noise_Proc = "AROMA+2P+DiCER"))
}
p_value_res <- plyr::rbind.fill(group_main,
group_null) %>%
group_by(grouping_var, Noise_Proc, Sample_Type) %>%
dplyr::summarise(num_null_obs = sum(Type == "null"),
main_accuracy = unique(accuracy[Type=="main"]),
main_balanced_accuracy = unique(balanced_accuracy[Type=="main"]),
num_main_acc_greater = sum(main_accuracy > accuracy[Type=="null"]),
num_main_bal_acc_greater = sum(main_balanced_accuracy > balanced_accuracy[Type=="null"])) %>%
ungroup() %>%
distinct() %>%
mutate(acc_p = 1 - (num_main_acc_greater) / num_null_obs,
bal_acc_p = 1 - (num_main_bal_acc_greater) / num_null_obs) %>%
dplyr::rename("accuracy" = "main_accuracy",
"balanced_accuracy" = "main_balanced_accuracy")
View(p_value_res)
noise_proc = "AROMA+2P+GMR"
class_res = group_wise_SVM_balanced_accuracy
null_data = model_permutation_null_weighting
if ("Noise_Proc" %in% colnames(null_data)) {
null_data <- subset(null_data, Noise_Proc == noise_proc)
}
if ("Noise_Proc" %in% colnames(class_res)) {
class_res <- subset(class_res, Noise_Proc == noise_proc)
}
if (!("Sample_Type" %in% colnames(null_data))) {
null_in <- null_data %>%
mutate(Sample_Type = "In-sample")
null_out <- null_data %>%
mutate(Sample_Type = "Out-of-sample")
null_data <- plyr::rbind.fill(null_in, null_out)
}
# Create grouping_var column if it doesn't exist
if (!("grouping_var" %in% colnames(class_res))) {
class_res <- class_res %>%
dplyr::rename("grouping_var" = grouping_var)
}
if (!is_main_data_averaged) {
class_res <- class_res %>%
group_by(Sample_Type, grouping_var, Noise_Proc) %>%
summarise(accuracy_avg = mean(accuracy, na.rm=T),
accuracy_SD = sd(accuracy, na.rm=T),
balanced_accuracy_avg = mean(balanced_accuracy, na.rm=T),
balanced_accuracy_SD = sd(balanced_accuracy, na.rm=T)) %>%
dplyr::rename("accuracy"="accuracy_avg",
"balanced_accuracy"="balanced_accuracy_avg")
}
main_res <- class_res %>%
dplyr::select(grouping_var, Sample_Type, Noise_Proc, accuracy, balanced_accuracy) %>%
mutate(Type = "main") %>%
pivot_longer(cols=c(accuracy, balanced_accuracy),
names_to="Metric",
values_to="Value") %>%
pivot_wider(id_cols = c(grouping_var, Noise_Proc,
Type, Sample_Type),
names_from = Metric, values_from = Value)
View(main_res)
if ("grouping_var" %in% colnames(null_data) & !(use_pooled_null)) {
group_null <- null_data %>%
dplyr::filter(grouping_var == group_var)
} else {
group_null <- null_data %>%
dplyr::mutate(grouping_var = group_var)
}
group_main <- subset(main_res, grouping_var == group_var)
group_null$Type <- "null"
p_value_res <- plyr::rbind.fill(group_main,
group_null) %>%
group_by(grouping_var, Noise_Proc, Sample_Type) %>%
dplyr::summarise(num_null_obs = sum(Type == "null"),
main_accuracy = unique(accuracy[Type=="main"]),
main_balanced_accuracy = unique(balanced_accuracy[Type=="main"]),
num_main_acc_greater = sum(main_accuracy > accuracy[Type=="null"]),
num_main_bal_acc_greater = sum(main_balanced_accuracy > balanced_accuracy[Type=="null"])) %>%
ungroup() %>%
distinct() %>%
mutate(acc_p = 1 - (num_main_acc_greater) / num_null_obs,
bal_acc_p = 1 - (num_main_bal_acc_greater) / num_null_obs) %>%
dplyr::rename("accuracy" = "main_accuracy",
"balanced_accuracy" = "main_balanced_accuracy")
View(p_value_res)
source("~/github/fMRI_FeaturesDisorders/helper_functions/classification/Null_distributions.R")
pvalues <- calc_empirical_nulls(class_res = group_wise_SVM_balanced_accuracy,
null_data = model_permutation_null_weighting,
feature_set = univariate_feature_set,
noise_proc = noise_proc,
use_pooled_null = TRUE,
is_main_data_averaged = TRUE,
grouping_var = grouping_var)
View(pvalues)
saveRDS(pvalues, file=paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_model_permutation_null_%s_%s_pvals.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))
for (i in 1:nrow(grouping_param_df)) {
grouping_type = grouping_param_df$grouping_type[i]
grouping_var = grouping_param_df$grouping_var[i]
SVM_feature_var = grouping_param_df$SVM_feature_var[i]
#### 10-fold linear SVM with different weights
# Iterate over weighting_param_df
for (j in 1:nrow(weighting_param_df)) {
weighting_name <- weighting_param_df$name[j]
use_inv_prob_weighting <- weighting_param_df$use_inv_prob_weighting[j]
# Generate null-model fits distribution
if (!file.exists(paste0(rdata_path, sprintf("%s_%s_wise_model_permutation_null_%s_%s.Rds",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name)))) {
# Define data directory
output_data_dir <- paste0(rdata_path, sprintf("%s_%s_wise_%s_%s_null_model_fits/",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name))
## Concatenate null results and save to RDS file
model_permutation_null_weighting <- list.files(output_data_dir, pattern="Rds") %>%
purrr::map_df(~ readRDS(paste0(output_data_dir, .x)))
saveRDS(model_permutation_null_weighting, paste0(rdata_path, sprintf("%s_%s_wise_model_permutation_null_%s_%s.Rds",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name)))
} else {
model_permutation_null_weighting <- readRDS(paste0(rdata_path, sprintf("%s_%s_wise_model_permutation_null_%s_%s.Rds",
dataset_ID,
grouping_type,
univariate_feature_set,
weighting_name)))
}
# Empirically derive p-values based on null model fits distribution
if (!file.exists(paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_model_permutation_null_%s_%s_pvals.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))) {
group_wise_SVM_balanced_accuracy <- readRDS(paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_%s_%s_balacc.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))
# Calculate p-values
pvalues <- calc_empirical_nulls(class_res = group_wise_SVM_balanced_accuracy,
null_data = model_permutation_null_weighting,
feature_set = univariate_feature_set,
noise_proc = noise_proc,
use_pooled_null = TRUE,
is_main_data_averaged = TRUE,
grouping_var = grouping_var)
saveRDS(pvalues, file=paste0(rdata_path, sprintf("%s_wise_CV_linear_SVM_model_permutation_null_%s_%s_pvals.Rds",
grouping_type,
univariate_feature_set,
weighting_name)))
}
}
}
