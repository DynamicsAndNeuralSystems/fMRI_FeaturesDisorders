{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting time-series features from resting-state fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from pyarrow import feather\n",
    "from nilearn.image import math_img, resample_img, index_img, threshold_img\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Load R packages\n",
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "    library(FactoMineR)\n",
    "    library(factoextra)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "We will start by computing the mean framewise displacement (FD) for each participant so that we know which participant(s) to exclude from further analysis.\n",
    "FD is computed using the method from [Power et al. (2012)](https://doi.org/10.1016/j.neuroimage.2011.10.018) and we apply the 'lenient' threshold described in [Parkes et al. (2018)](https://doi.org/10.1016/j.neuroimage.2017.12.073)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "                  R2023a (9.14.0.2206163) 64-bit (maci64)\n",
      "                             February 22, 2023\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "                  R2023a (9.14.0.2206163) 64-bit (maci64)\n",
      "                             February 22, 2023\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Define the path to the data\n",
    "github_path=$(echo $(pwd) | tr -d ' ')\n",
    "\n",
    "# Run the calc_FD.m script -- note that you might need to update your matlab path here\n",
    "cd code/movement_analysis\n",
    "\n",
    "# UCLA CNP\n",
    "matlab -nodisplay -singleCompThread -r \"calc_FD UCLA_CNP $github_path $github_path/data/movement_data/UCLA_CNP/; exit\"\n",
    "\n",
    "# ABIDE\n",
    "matlab -nodisplay -singleCompThread -r \"calc_FD ABIDE $github_path $github_path/data/movement_data/ABIDE/; exit\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FD data should be organized in a `.txt` file with two columns (comma-delimited): one for the `Sample_ID` and one for the `Mean_FD_Power`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Mean_FD_Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>0.110490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-10171</td>\n",
       "      <td>0.214750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-10189</td>\n",
       "      <td>0.204260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-10206</td>\n",
       "      <td>0.064667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-10217</td>\n",
       "      <td>0.062641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Mean_FD_Power\n",
       "0  sub-10159       0.110490\n",
       "1  sub-10171       0.214750\n",
       "2  sub-10189       0.204260\n",
       "3  sub-10206       0.064667\n",
       "4  sub-10217       0.062641"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCLA_CNP_mean_FD = pd.read_table('data/movement_data/UCLA_CNP/UCLA_CNP_Mean_FD_Power.txt', delimiter=',', header=None).rename(columns={0: 'Sample_ID', 1: 'Mean_FD_Power'})\n",
    "ABIDE_mean_FD = pd.read_table('data/movement_data/ABIDE/ABIDE_Mean_FD_Power.txt', delimiter=',', header=None).rename(columns={0: 'Sample_ID', 1: 'Mean_FD_Power'})\n",
    "\n",
    "# Print the first five rows of the UCLA CNP Mean FD\n",
    "UCLA_CNP_mean_FD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop any participants with a mean FD > 0.55mm per the 'lenient' threshold criteria and save the list of participants to drop to a .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA CNP participants to drop: 3\n",
      "ABIDE participants to drop: 59\n"
     ]
    }
   ],
   "source": [
    "# Identify any participants with Mean_FD_Power > 0.55 and write their sample IDs to a text file\n",
    "UCLA_CNP_participants_to_drop = UCLA_CNP_mean_FD[UCLA_CNP_mean_FD['Mean_FD_Power'] > 0.55]['Sample_ID']\n",
    "UCLA_CNP_participants_to_drop.to_csv('data/input_data/UCLA_CNP_participants_to_drop_lenient.txt', index=False, header=False)\n",
    "\n",
    "ABIDE_participants_to_drop = ABIDE_mean_FD[ABIDE_mean_FD['Mean_FD_Power'] > 0.55]['Sample_ID']\n",
    "ABIDE_participants_to_drop.to_csv('data/input_data/ABIDE_participants_to_drop_lenient.txt', index=False, header=False)\n",
    "\n",
    "UCLA_CNP_participants_to_drop = UCLA_CNP_participants_to_drop.tolist()\n",
    "ABIDE_participants_to_drop = ABIDE_participants_to_drop.tolist()\n",
    "ABIDE_participants_to_drop = [str(x) for x in ABIDE_participants_to_drop]\n",
    "\n",
    "# Print the number of participants to drop per study\n",
    "print('UCLA CNP participants to drop: {}'.format(len(UCLA_CNP_participants_to_drop)))\n",
    "print('ABIDE participants to drop: {}'.format(len(ABIDE_participants_to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will start with our resting-state fMRI data stored in a [`.feather` file](https://arrow.apache.org/docs/python/feather.html) (for easy conversion between R and Python).\n",
    "Data should be organized in a long format, such that there is one row for each brain region and timepoint per participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input time-series feather files for the two datasets\n",
    "UCLA_CNP_input_time_series_data = pd.read_feather('data/input_data/UCLA_CNP_fMRI_TS.feather')\n",
    "ABIDE_input_time_series_data = pd.read_feather('data/input_data/ABIDE_fMRI_TS.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information about the time-series features\n",
    "univariate_TS_feature_info = pd.read_csv(\"data/feature_info/univariate_feature_info.csv\")\n",
    "pairwise_TS_feature_info = pd.read_csv(\"data/feature_info/pairwise_feature_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the first five rows of this time-series dataset for the UCLA CNP cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Noise_Proc</th>\n",
       "      <th>Brain_Region</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>AROMA+2P+GMR</td>\n",
       "      <td>ctx-lh-bankssts</td>\n",
       "      <td>1</td>\n",
       "      <td>4.071963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>AROMA+2P+GMR</td>\n",
       "      <td>ctx-lh-caudalanteriorcingulate</td>\n",
       "      <td>1</td>\n",
       "      <td>1.078613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>AROMA+2P+GMR</td>\n",
       "      <td>ctx-lh-caudalmiddlefrontal</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.191693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>AROMA+2P+GMR</td>\n",
       "      <td>ctx-lh-cuneus</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-10159</td>\n",
       "      <td>AROMA+2P+GMR</td>\n",
       "      <td>ctx-lh-entorhinal</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.071331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID    Noise_Proc                    Brain_Region  timepoint  \\\n",
       "0  sub-10159  AROMA+2P+GMR                 ctx-lh-bankssts          1   \n",
       "1  sub-10159  AROMA+2P+GMR  ctx-lh-caudalanteriorcingulate          1   \n",
       "2  sub-10159  AROMA+2P+GMR      ctx-lh-caudalmiddlefrontal          1   \n",
       "3  sub-10159  AROMA+2P+GMR                   ctx-lh-cuneus          1   \n",
       "4  sub-10159  AROMA+2P+GMR               ctx-lh-entorhinal          1   \n",
       "\n",
       "     values  \n",
       "0  4.071963  \n",
       "1  1.078613  \n",
       "2 -0.191693  \n",
       "3  0.888717  \n",
       "4 -4.071331  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCLA_CNP_input_time_series_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be structured such that there are five columns:\n",
    "1. `Sample_ID`: The unique ID mapping to an individual participant.\n",
    "2. `Noise_Proc`: Name of the noise processing procedure, useful for when multiple noise processing pipelines are evaluated.\n",
    "3. `Brain_Region`: The name of the brain region.\n",
    "4. `timepoint`: The timepoint corresponding to the BOLD frame.\n",
    "5. `values`: The BOLD signal amplitude at the given timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting univariate time-series features\n",
    "\n",
    "First, we will extract 25 univariate time-series features comprising the [`catch22`](https://doi.org/10.1007/s10618-019-00647-x) feature set, mean, standard deviation, and fractional amplitude of low-frequency fluctuations (fALFF).\n",
    "The `catch22` features, mean, and SD can all be computed in R using the [`theft`](https://cran.r-project.org/web/packages/theft/vignettes/theft.html) package (collectively referred to as the `catch24` feature set), while the fALFF will be computed in Matlab.\n",
    "Computing the `catch24` features will take several minutes, so feel free to hit play on the next code chunk and grab a coffee ☕️\n",
    "(Alternatively, you can run this on a high-performance computing cluster if you prefer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Registered S3 method overwritten by 'quantmod':\n",
       "  method            from\n",
       "  as.zoo.data.frame zoo \n",
       "No IDs removed. All value vectors good for feature extraction.\n",
       "Running computations for catch22...\n",
       "\n",
       "Calculations completed for catch22.\n",
       "No IDs removed. All value vectors good for feature extraction.\n",
       "Running computations for catch22...\n",
       "\n",
       "Calculations completed for catch22.\n",
       "In addition: Warning messages:\n",
       "1: Using an external vector in selections was deprecated in tidyselect 1.1.0.\n",
       "ℹ Please use `all_of()` or `any_of()` instead.\n",
       "  # Was:\n",
       "  data %>% select(unique_columns)\n",
       "\n",
       "  # Now:\n",
       "  data %>% select(all_of(unique_columns))\n",
       "\n",
       "See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n",
       "2: There was 1 warning in `dplyr::summarise()`.\n",
       "ℹ In argument: `Rcatch22::catch22_all(.data$values, catch24 = catch24)`.\n",
       "ℹ In group 1: `id = \"sub-10159__Left-Accumbens-area__AROMA+2P+GMR\"`.\n",
       "Caused by warning:\n",
       "! As of 0.1.14 the feature 'CO_f1ecac' returns a double instead of int\n",
       "This warning is displayed once per session. \n",
       "3: Returning more (or less) than 1 row per `summarise()` group was deprecated in\n",
       "dplyr 1.1.0.\n",
       "ℹ Please use `reframe()` instead.\n",
       "ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n",
       "  always returns an ungrouped data frame and adjust accordingly.\n",
       "ℹ The deprecated feature was likely used in the theft package.\n",
       "  Please report the issue at <https://github.com/hendersontrent/theft/issues>.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i UCLA_CNP_input_time_series_data,ABIDE_input_time_series_data -o UCLA_CNP_catch24_features,ABIDE_catch24_features\n",
    "# Load the theft and tidyr packages\n",
    "library(theft)\n",
    "library(tidyr)\n",
    "\n",
    "# We can define a helper function to compute the `catch24` time-series features using the `theft` package\n",
    "catch24_all_samples <- function(full_TS_data,\n",
    "                                output_column_names = c(\"Output\"),\n",
    "                                unique_columns = c(\"Sample_ID\", \"Brain_Region\", \"Noise_Proc\")) {\n",
    "  \n",
    "  \n",
    "  # Merge columns into unique ID\n",
    "  full_TS_data <- full_TS_data %>%\n",
    "    tidyr::unite(\"Unique_ID\", unique_columns, sep=\"__\")\n",
    "  \n",
    "  # Compute the set of 24 time-series features using theft\n",
    "  TS_catch24 <- theft::calculate_features(data = full_TS_data, \n",
    "                                          id_var = \"Unique_ID\", \n",
    "                                          time_var = \"timepoint\", \n",
    "                                          values_var = \"values\", \n",
    "                                          feature_set = \"catch22\",\n",
    "                                          catch24 = TRUE)[[1]] %>%\n",
    "    tidyr::separate(\"id\", c(output_column_names), sep=\"__\")\n",
    "\n",
    "  # Return the resulting set of 24 features computed per brain region\n",
    "  return(TS_catch24)\n",
    "    \n",
    "}\n",
    "\n",
    "# Compute the 24 time-series features for UCLA CNP and ABIDE time-series data\n",
    "UCLA_CNP_catch24_features <- catch24_all_samples(UCLA_CNP_input_time_series_data,\n",
    "                                                 output_column_names = c(\"Sample_ID\", \"Brain_Region\", \"Noise_Proc\"))\n",
    "ABIDE_catch24_features <- catch24_all_samples(ABIDE_input_time_series_data,\n",
    "                                                output_column_names = c(\"Sample_ID\", \"Brain_Region\", \"Noise_Proc\"))\n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will separately compute the fractional amplitude of low-frequency fluctuations (fALFF) using the Matlab script `compute_regional_fALFF.m` as follows (note: Matlab license is required to run this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in catch24 data once it's been created\n",
    "UCLA_CNP_catch24_features = pd.read_feather('data/time_series_features/UCLA_CNP_catch24_features.feather')\n",
    "ABIDE_catch24_features = pd.read_feather('data/time_series_features/ABIDE_catch24_features.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# First, we need to convert our time-series feather file to a Matlab .mat file to be read in properly\n",
    "UCLA_CNP_time_series_file_base='data/input_data/UCLA_CNP_fMRI_TS'\n",
    "ABIDE_time_series_file_base='data/input_data/ABIDE_ASD_fMRI_TS'\n",
    "\n",
    "# Run the feather_to_mat.py script with the file base as the input argument, indicating that the output file should be a mat file\n",
    "python3 code/feature_extraction/feather_to_mat.py ${UCLA_CNP_time_series_file_base} mat\n",
    "python3 code/feature_extraction/feather_to_mat.py ${ABIDE_time_series_file_base} mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "                  R2023a (9.14.0.2206163) 64-bit (maci64)\n",
      "                             February 22, 2023\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "                  R2023a (9.14.0.2206163) 64-bit (maci64)\n",
      "                             February 22, 2023\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "# Run the feather_to_mat.py script with the file base as the input argument, indicating that the output file should be a mat file\n",
    "python3 code/feature_extraction/feather_to_mat.py data/input_data/UCLA_CNP_fMRI_TS mat\n",
    "python3 code/feature_extraction/feather_to_mat.py data/input_data/ABIDE_fMRI_TS mat\n",
    "\n",
    "# Define the path to the data\n",
    "data_path=$(echo $(pwd) | tr -d ' ')\n",
    "\n",
    "# Run the compute_regional_fALFF.m script -- note that you might need to update your matlab path here\n",
    "cd code/feature_extraction\n",
    "\n",
    "# UCLA CNP\n",
    "TS_mat_file=\"$data_path/data/input_data/UCLA_CNP_fMRI_TS.mat\"\n",
    "output_mat_file=\"data/time_series_features/UCLA_CNP_fALFF.mat\"\n",
    "/Applications/MATLAB_R2023a.app/bin/matlab -nodisplay -singleCompThread -r \"compute_regional_fALFF $data_path $TS_mat_file $output_mat_file; exit\"\n",
    "\n",
    "# ABIDE\n",
    "TS_mat_file=\"data/input_data/ABIDE_fMRI_TS.mat\"\n",
    "output_mat_file=\"data/time_series_features/ABIDE_fALFF.mat\"\n",
    "/Applications/MATLAB_R2023a.app/bin/matlab -nodisplay -singleCompThread -r \"compute_regional_fALFF $data_path $TS_mat_file $output_mat_file; exit\"\n",
    "\n",
    "# Convert the mat file back to feather for fALFF\n",
    "python3 feather_to_mat.py ${data_path}/data/time_series_features/UCLA_CNP_fALFF feather\n",
    "python3 feather_to_mat.py ${data_path}/data/time_series_features/ABIDE_fALFF feather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the fALFF feather files\n",
    "UCLA_CNP_fALFF = pd.read_feather('data/time_series_features/UCLA_CNP_fALFF.feather')\n",
    "ABIDE_fALFF = pd.read_feather('data/time_series_features/ABIDE_fALFF.feather')\n",
    "\n",
    "# Remove whitespace from Brain_Region column in the fALFF dataframes\n",
    "UCLA_CNP_fALFF['Brain_Region'] = UCLA_CNP_fALFF['Brain_Region'].str.strip()\n",
    "ABIDE_fALFF['Brain_Region'] = ABIDE_fALFF['Brain_Region'].str.strip()\n",
    "\n",
    "# Read in metadata files\n",
    "UCLA_CNP_metadata = pd.read_feather('data/input_data/UCLA_CNP_sample_metadata.feather')\n",
    "ABIDE_metadata = pd.read_feather('data/input_data/ABIDE_sample_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i UCLA_CNP_fALFF,ABIDE_fALFF,UCLA_CNP_catch24_features,ABIDE_catch24_features,UCLA_CNP_metadata,ABIDE_metadata,UCLA_CNP_participants_to_drop,ABIDE_participants_to_drop -o UCLA_CNP_catch25_filtered,ABIDE_catch25_filtered\n",
    "\n",
    "source(\"code/feature_extraction/QC_functions_univariate.R\")\n",
    "univariate_feature_set <- \"catch25\"\n",
    "\n",
    "UCLA_CNP_catch25_filtered <- run_QC_for_univariate_dataset(sample_metadata = UCLA_CNP_metadata,\n",
    "                                                           univariate_feature_set = univariate_feature_set,\n",
    "                                                           catch24_results = UCLA_CNP_catch24_features,\n",
    "                                                           fALFF_results = UCLA_CNP_fALFF,\n",
    "                                                           participants_to_drop = UCLA_CNP_participants_to_drop)\n",
    "\n",
    "\n",
    "ABIDE_catch25_filtered <- run_QC_for_univariate_dataset(sample_metadata = ABIDE_metadata,\n",
    "                                                       univariate_feature_set = univariate_feature_set,\n",
    "                                                       catch24_results = ABIDE_catch24_features,\n",
    "                                                       fALFF_results = ABIDE_fALFF,\n",
    "                                                       participants_to_drop = ABIDE_participants_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data to feather files\n",
    "UCLA_CNP_catch25_filtered.reset_index().to_feather('data/time_series_features/UCLA_CNP_catch25_filtered.feather')\n",
    "ABIDE_catch25_filtered.reset_index().to_feather('data/time_series_features/ABIDE_catch25_filtered.feather')\n",
    "\n",
    "# Save filtered metadata\n",
    "UCLA_CNP_metadata_filtered = UCLA_CNP_metadata[UCLA_CNP_metadata['Sample_ID'].isin(UCLA_CNP_catch25_filtered['Sample_ID'])]\n",
    "ABIDE_metadata_filtered = ABIDE_metadata[ABIDE_metadata['Sample_ID'].isin(ABIDE_catch25_filtered['Sample_ID'])]\n",
    "\n",
    "UCLA_CNP_metadata_filtered.reset_index().to_feather('data/input_data/UCLA_CNP_sample_metadata_filtered.feather')\n",
    "ABIDE_metadata_filtered.reset_index().to_feather('data/input_data/ABIDE_sample_metadata_filtered.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting statistics of pairwise interactions (SPIs) for coupling strengths\n",
    "\n",
    "For `pyspi` computations, we opted to run a distributed version on a high-performance computing cluster.\n",
    "We parallelized computations by separating the fMRI time-series data into individualized `numpy` array files (`.npy`) to be parsed by individual HPC job nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to iterate over each Sample_ID in the given time series dataframe and save the corresponding time series to a numpy file\n",
    "def split_MTS_into_npy(time_series_data, study):\n",
    "\n",
    "    # Create output directory if it doesn't already exist\n",
    "    try:\n",
    "        os.makedirs(\"data/time_series_features/\" + study, \n",
    "                    exist_ok = True)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # Iterate over each participant\n",
    "    for sample_id in time_series_data['Sample_ID'].unique().tolist():\n",
    "       # Extract just that participant's data\n",
    "        participant_TS_data = time_series_data.query('Sample_ID == @sample_id')\n",
    "\n",
    "        # Reshape data from long to wide\n",
    "        participant_TS_data_wide = participant_TS_data.pivot(index='Brain_Region', columns='timepoint', values='values').reset_index()\n",
    "\n",
    "        # Convert to numpy array\n",
    "        participant_TS_data_np = participant_TS_data_wide.drop(['Brain_Region'], axis=1).to_numpy()\n",
    "\n",
    "        # Z-score each row\n",
    "        data_norm = np.apply_along_axis(stats.zscore, 1, participant_TS_data_np)\n",
    "\n",
    "        # Save the numpy array to a numpy binary file\n",
    "        np.save('data/time_series_features/' + study + '/' + sample_id + '.npy', data_norm)\n",
    "\n",
    "# Call the function for UCLA_CNP and ABIDE\n",
    "split_MTS_into_npy(UCLA_CNP_input_time_series_data, 'UCLA_CNP')\n",
    "split_MTS_into_npy(ABIDE_input_time_series_data, 'ABIDE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a `.yaml` file for each study, containing information about the file location for each sample ID, along with a label containing diagnostic group.\n",
    "We specify that the dimension order is presented with brain regions ('processes') as rows and timepoints as columns by setting `dim_order` to `ps`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.2     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YAML output: data/time_series_features/UCLA_CNP/sample.yaml \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.2     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YAML output: data/time_series_features/ABIDE/sample.yaml \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ID_var='Sample_ID'\n",
    "label_vars='Diagnosis'\n",
    "\n",
    "# Run for UCLA CNP\n",
    "data_dir='data/time_series_features/UCLA_CNP/'\n",
    "sample_metadata_file='data/input_data/UCLA_CNP_sample_metadata.feather'\n",
    "\n",
    "Rscript code/feature_extraction/create_yaml_for_samples.R  \\\n",
    "    --data_dir $data_dir \\\n",
    "    --sample_metadata_file $sample_metadata_file \\\n",
    "    --ID_var $ID_var \\\n",
    "    --label_vars $label_vars \\\n",
    "    --dim_order ps\n",
    "\n",
    "# Run for ABIDE\n",
    "data_dir='data/time_series_features/ABIDE/'\n",
    "sample_metadata_file='data/input_data/ABIDE_sample_metadata.feather'\n",
    "\n",
    "Rscript code/feature_extraction/create_yaml_for_samples.R  \\\n",
    "    --data_dir $data_dir \\\n",
    "    --sample_metadata_file $sample_metadata_file \\\n",
    "    --ID_var $ID_var \\\n",
    "    --label_vars $label_vars \\\n",
    "    --dim_order ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend that you clone the [pyspi-distribute](https://github.com/olivercliff/pyspi-distribute) repository to make use of job distribution on an HPC cluster.\n",
    "To do so, you can clone with the following command:\n",
    "```\n",
    "git clone https://github.com/olivercliff/pyspi-distribute.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pyspi_distribute_path='../pyspi-distribute/' # Change to the path where you cloned the pyspi-distribute repo\n",
    "conda_env='base' # Change to the name of the conda environment you want to use\n",
    "queue='normal' # Change to the name of the queue you want to use for your HPC\n",
    "pyspi_walltime_hrs=2 # Change to the maximum walltime in hours you want to allow for each job\n",
    "pyspi_ncpus=1 # Change to the number of CPUs you want to use for each job\n",
    "pyspi_mem=20 # Change to the amount of memory in GB you want to use for each job\n",
    "\n",
    "# UCLA CNP\n",
    "python3 ${pyspi_distribute_path}/distribute_jobs.py \\\n",
    "--data_dir data/time_series_features/UCLA_CNP/ \\\n",
    "--calc_file_name calc.pkl \\\n",
    "--compute_file ${pyspi_distribute_path}/pyspi_compute.py \\\n",
    "--template_pbs_file code/feature_extraction/template_pyspi_distribute.pbs \\\n",
    "--pyspi_config code/feature_extraction/SPIs_14_config.yaml \\\n",
    "--sample_yaml data/time_series_features/UCLA_CNP/sample.yaml \\\n",
    "--pbs_notify a \\\n",
    "--email [your_email_address_here] \\\n",
    "--conda_env $conda_env \\\n",
    "--queue $queue \\\n",
    "--walltime_hrs $pyspi_walltime_hrs \\\n",
    "--cpu $pyspi_ncpus \\\n",
    "--mem $pyspi_mem \\\n",
    "--table_only\n",
    "\n",
    "# ABIDE\n",
    "python3 ${pyspi_distribute_path}/distribute_jobs.py \\\n",
    "--data_dir data/time_series_features/ABIDE/ \\\n",
    "--calc_file_name calc.pkl \\\n",
    "--compute_file ${pyspi_distribute_path}/pyspi_compute.py \\\n",
    "--template_pbs_file code/feature_extraction/template_pyspi_distribute.pbs \\\n",
    "--pyspi_config code/feature_extraction/SPIs_14_config.yaml \\\n",
    "--sample_yaml data/time_series_features/ABIDE/sample.yaml \\\n",
    "--pbs_notify a \\\n",
    "--email [your_email_address_here] \\\n",
    "--conda_env $conda_env \\\n",
    "--queue $queue \\\n",
    "--walltime_hrs $pyspi_walltime_hrs \\\n",
    "--cpu $pyspi_ncpus \\\n",
    "--mem $pyspi_mem \\\n",
    "--table_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this for all participants, you should have a folder for each participant under `data/time_series_features/[Study]/[Sample_ID]` containing the following files:\n",
    "- `pyspi_run.pbs`: This is the job submission script that was automatically created and submitted for this participant.\n",
    "- `pyspi_run.out`: Notes where the `.npy` file was loaded from and where the resulting `calc.pkl` file was saved for this participant.\n",
    "- `pbsjob.out`: All outputs printed to `stdout`, and `stderr` if applicable. Useful for debugging/confirming that everything ran okay.\n",
    "- `calc.pkl`: pyspi computation results for this participant, saved as a `pandas DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brain_region_from</th>\n",
       "      <th>value</th>\n",
       "      <th>SPI</th>\n",
       "      <th>brain_region_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proc-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cov_EmpiricalCovariance</td>\n",
       "      <td>proc-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proc-1</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>cov_EmpiricalCovariance</td>\n",
       "      <td>proc-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proc-2</td>\n",
       "      <td>-0.103124</td>\n",
       "      <td>cov_EmpiricalCovariance</td>\n",
       "      <td>proc-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proc-3</td>\n",
       "      <td>0.041604</td>\n",
       "      <td>cov_EmpiricalCovariance</td>\n",
       "      <td>proc-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proc-4</td>\n",
       "      <td>-0.097217</td>\n",
       "      <td>cov_EmpiricalCovariance</td>\n",
       "      <td>proc-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brain_region_from     value                      SPI brain_region_to\n",
       "0            proc-0       NaN  cov_EmpiricalCovariance          proc-0\n",
       "1            proc-1 -0.043263  cov_EmpiricalCovariance          proc-0\n",
       "2            proc-2 -0.103124  cov_EmpiricalCovariance          proc-0\n",
       "3            proc-3  0.041604  cov_EmpiricalCovariance          proc-0\n",
       "4            proc-4 -0.097217  cov_EmpiricalCovariance          proc-0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_calc_table = pd.read_pickle('data/time_series_features/UCLA_CNP/sub-70086/calc.pkl')\n",
    "example_calc_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above example table, the results are stored in a long format such that there is a `brain_region_from` and a `brain_region_to`, an `SPI` (in this case, `cov_EmpiricalCovariance` which is equivalent to the Pearson correlation coefficient) and a `value`.\n",
    "Note that the `value` is `NaN` in the first row since that corresponds to a self-connection, which is not a valid measurement (and will subsequently be dropped when we merge the results).\n",
    "The default output value nomenclature for `pyspi` is process IDs, such as `proc-0`, `proc-1`, etc., which we will map to brain region names subsequently, too.\n",
    "\n",
    "Merging and data cleaning is accomplished with the script `code/feature_extraction/merge_pyspi_data.py`, which can be run as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python3 code/feature_extraction/merge_pyspi_data.py \\\n",
    "--data_path data/ \\\n",
    "--dataset_ID UCLA_CNP \\\n",
    "--pkl_file calc.pkl \\\n",
    "--pairwise_feature_set pyspi14 \\\n",
    "--brain_region_lookup data/input_data/UCLA_CNP_Brain_Region_Lookup.feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have the following files in your `data/time_series_features/` path for subsequent classification analysis:\n",
    "- `ABIDE_catch25_filtered.feather`\n",
    "- `ABIDE_pyspi14_filtered.feather`\n",
    "- `UCLA_CNP_catch25_filtered.feather`\n",
    "- `UCLA_CNP_pyspi14_filtered.feather`\n",
    "\n",
    "\n",
    "Our last step will be to compare across the univariate and pairwise feature sets for each dataset and find the participants with data available for both feature sets as a quality control check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_univariate_pairwise(data_path, dataset_ID, univariate_feature_set, pairwise_feature_set):\n",
    "\n",
    "    # Load in data on samples with univariate feature data\n",
    "    filtered_univariate_data = pd.read_feather(f\"{data_path}/{dataset_ID}_{univariate_feature_set}_filtered.feather\")\n",
    "    filtered_univariate_samples = pd.DataFrame(filtered_univariate_data.Sample_ID.unique(), columns=[\"Sample_ID\"])\n",
    "    \n",
    "    # Load in data on samples with pairwise feature data\n",
    "    filtered_pairwise_data = pd.read_feather(f\"{data_path}/{dataset_ID}_{pairwise_feature_set}_filtered.feather\")\n",
    "    filtered_pairwise_samples = pd.DataFrame(filtered_pairwise_data.Sample_ID.unique(), columns=[\"Sample_ID\"])\n",
    "    \n",
    "    # Merge the two datasets\n",
    "    merged_sample_info = pd.merge(filtered_univariate_samples, filtered_pairwise_samples, how=\"inner\")\n",
    "    merged_sample_info.to_feather(f\"{data_path}/{dataset_ID}_filtered_sample_info_{univariate_feature_set}_{pairwise_feature_set}.feather\")\n",
    "    \n",
    "# Run for UCLA CNP\n",
    "intersection_univariate_pairwise(data_path='data/time_series_features',\n",
    "                                 dataset_ID='UCLA_CNP',\n",
    "                                 univariate_feature_set='catch25',\n",
    "                                 pairwise_feature_set='pyspi14')\n",
    "\n",
    "# Run for ABIDE\n",
    "intersection_univariate_pairwise(data_path='data/time_series_features',\n",
    "                                 dataset_ID='ABIDE',\n",
    "                                 univariate_feature_set='catch25',\n",
    "                                 pairwise_feature_set='pyspi14')\n",
    "\n",
    "# Apply this final filter to the .feather files\n",
    "UCLA_CNP_filtered_sample_info = pd.read_feather('data/time_series_features/UCLA_CNP_filtered_sample_info_catch25_pyspi14.feather')\n",
    "\n",
    "UCLA_CNP_catch25_filtered = pd.read_feather('data/time_series_features/UCLA_CNP_catch25_filtered.feather').query(\"Sample_ID in @UCLA_CNP_filtered_sample_info.Sample_ID.unique().tolist()\")\n",
    "UCLA_CNP_catch25_filtered.to_feather('data/time_series_features/UCLA_CNP_catch25_filtered.feather')\n",
    "\n",
    "UCLA_CNP_pyspi14_filtered = pd.read_feather('data/time_series_features/UCLA_CNP_pyspi14_filtered.feather').query(\"Sample_ID in @UCLA_CNP_filtered_sample_info.Sample_ID.unique().tolist()\")\n",
    "UCLA_CNP_pyspi14_filtered.to_feather('data/time_series_features/UCLA_CNP_pyspi14_filtered.feather')\n",
    "\n",
    "ABIDE_filtered_sample_info = pd.read_feather('data/time_series_features/ABIDE_filtered_sample_info_catch25_pyspi14.feather')\n",
    "\n",
    "ABIDE_catch25_filtered = pd.read_feather('data/time_series_features/ABIDE_catch25_filtered.feather').query(\"Sample_ID in @ABIDE_filtered_sample_info.Sample_ID.unique().tolist()\")\n",
    "ABIDE_catch25_filtered.reset_index().to_feather('data/time_series_features/ABIDE_catch25_filtered.feather')\n",
    "\n",
    "ABIDE_pyspi14_filtered = pd.read_feather('data/time_series_features/ABIDE_pyspi14_filtered.feather').query(\"Sample_ID in @ABIDE_filtered_sample_info.Sample_ID.unique().tolist()\")\n",
    "ABIDE_pyspi14_filtered.reset_index().to_feather('data/time_series_features/ABIDE_pyspi14_filtered.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will fit a principal components analysis (PCA) on the univariate region times feature combination matrices to retain the first 25 PCs per disorder, as a validation analysis for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "In PCA(select(data_for_PCA, c(-Sample_ID, -Diagnosis)), ncp = n_PCs,  :\n",
       "  Missing values are imputed by the mean of the variable: you should use the imputePCA function of the missMDA package\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i UCLA_CNP_metadata,ABIDE_metadata -o first_25_PCs_by_disorder\n",
    "\n",
    "# Helper function to compute n_PCs from a given input dataset\n",
    "compute_first_n_PCs <- function(univariate_feature_data, dataset_ID, metadata, disorder, n_PCs) {\n",
    "  \n",
    "  # Extract the univariate region times feature data for the given disorder\n",
    "  data_for_PCA <- univariate_feature_data %>%\n",
    "    left_join(., metadata, by = join_by(Sample_ID)) %>%\n",
    "    filter(Diagnosis %in% c(\"Control\", disorder)) %>%\n",
    "    mutate(unique_ID = paste0(names, \"__\", Brain_Region), .keep=\"unused\") %>%\n",
    "    dplyr::select(unique_ID, Sample_ID, Diagnosis, values) %>%\n",
    "    pivot_wider(id_cols=c(Sample_ID, Diagnosis), names_from=unique_ID, values_from=values) %>%\n",
    "    mutate(Diagnosis=factor(Diagnosis, levels=c(\"Control\", disorder)))\n",
    "  \n",
    "  # Compute PCA\n",
    "  pca_res <- PCA(select(data_for_PCA, c(-Sample_ID, -Diagnosis)), ncp=n_PCs, graph = FALSE, scale.unit = TRUE)\n",
    "  pca_scores <- as.data.frame(pca_res$ind$coord) %>%\n",
    "    mutate(Sample_ID = data_for_PCA$Sample_ID,\n",
    "           Diagnosis = data_for_PCA$Diagnosis,\n",
    "           Disorder = disorder,\n",
    "           Study = dataset_ID)\n",
    "  \n",
    "  return(pca_scores)\n",
    "}\n",
    "\n",
    "# Iterate over each disorder and compute the first 25 PCs\n",
    "first_25_PCs_by_disorder_list <- list()\n",
    "for (disorder in c(\"Schizophrenia\", \"Bipolar\", \"ADHD\")) {\n",
    "  pca_scores_disorder <- compute_first_n_PCs(UCLA_CNP_catch25_filtered, \n",
    "                                             dataset_ID='UCLA_CNP', \n",
    "                                             metadata=UCLA_CNP_metadata, \n",
    "                                             disorder=disorder, \n",
    "                                             n_PCs=25)\n",
    "  first_25_PCs_by_disorder_list[[disorder]] <- pca_scores_disorder\n",
    "}\n",
    "for (disorder in c(\"ASD\")) {\n",
    "  pca_scores_disorder <- compute_first_n_PCs(ABIDE_catch25_filtered, \n",
    "                                             dataset_ID='ABIDE', \n",
    "                                             metadata=ABIDE_metadata, \n",
    "                                             disorder=disorder, \n",
    "                                             n_PCs=25)\n",
    "  first_25_PCs_by_disorder_list[[disorder]] <- pca_scores_disorder\n",
    "}\n",
    "first_25_PCs_by_disorder = do.call(rbind, first_25_PCs_by_disorder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save first_25_PCs_by_disorder to a feather file\n",
    "first_25_PCs_by_disorder.to_feather('data/time_series_features/univariate_combo_first25_PCs.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
