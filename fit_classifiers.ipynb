{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Uncomment the next two lines if you're running this on an HPC and want to speed up scikit-learn\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Load tidyverse R package\n",
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running linear SVMs\n",
    "\n",
    "This Jupyter notebook includes all code needed to perform 10-repeated 10-fold cross-validation analysis using linear support vector machine (SVM) classifiers for each of the five representations.\n",
    "First, we will import all functions from the `code/classification_analysis/core_classification_functions.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path to classification analysis functions\n",
    "sys.path.insert(0, 'code/classification_analysis/')\n",
    "from core_classification_functions import *\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Load participants included\n",
    "UCLA_CNP_subjects_to_keep = pd.read_feather(\"data/time_series_features/UCLA_CNP_filtered_sample_info_catch25_pyspi14.feather\")\n",
    "ABIDE_subjects_to_keep = pd.read_feather(\"data/time_series_features/ABIDE_filtered_sample_info_catch25_pyspi14.feather\")\n",
    "\n",
    "# Load metadata\n",
    "UCLA_CNP_metadata = (pd.read_feather(\"data/input_data/UCLA_CNP_sample_metadata.feather\")\n",
    "                        .assign(Study = \"UCLA_CNP\")\n",
    "                        .query(\"Sample_ID in @UCLA_CNP_subjects_to_keep.Sample_ID\"))\n",
    "ABIDE_metadata = (pd.read_feather(\"data/input_data/ABIDE_sample_metadata.feather\")\n",
    "                        .assign(Study = \"ABIDE\")\n",
    "                        .query(\"Sample_ID in @ABIDE_subjects_to_keep.Sample_ID\"))\n",
    "HCP100_metadata = pd.read_feather(\"data/input_data/HCP100_sample_metadata.feather\")\n",
    "\n",
    "# Load head movement \n",
    "UCLA_CNP_head_mvmt = (pd.read_table('data/movement_data/UCLA_CNP_Mean_FD_Power.txt', sep=',')\n",
    "                      .assign(Study = \"UCLA_CNP\")\n",
    "                        .query(\"Sample_ID in @UCLA_CNP_subjects_to_keep.Sample_ID\"))\n",
    "ABIDE_head_mvmt = (pd.read_table('data/movement_data/ABIDE_Mean_FD_Power.txt', sep=',', dtype={'Sample_ID': str,\n",
    "                                                                                              'Mean_FD_Power': float})\n",
    "                   .assign(Study = \"ABIDE\")\n",
    "                        .query(\"Sample_ID in @ABIDE_subjects_to_keep.Sample_ID\"))\n",
    "\n",
    "# Merge metadata + head movement\n",
    "merged_metadata = pd.concat([UCLA_CNP_metadata, ABIDE_metadata], axis=0).merge(pd.concat([UCLA_CNP_head_mvmt, ABIDE_head_mvmt], axis=0))\n",
    "\n",
    "# Study/disorder lookup table\n",
    "study_disorder_lookup = {'SCZ': 'UCLA_CNP', \n",
    "                          'BP': 'UCLA_CNP', \n",
    "                          'ADHD': 'UCLA_CNP', \n",
    "                          'ASD': 'ABIDE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load univariate time-series feature data for the two datasets\n",
    "UCLA_CNP_univariate_features = pd.read_feather('data/time_series_features/UCLA_CNP_catch25_filtered.feather')\n",
    "ABIDE_univariate_features = pd.read_feather('data/time_series_features/ABIDE_catch25_filtered.feather')\n",
    "HCP100_univariate_features = pd.read_feather('data/time_series_features/HCP100_catch25_filtered.feather')\n",
    "\n",
    "# # Load pairwise time-series feature data for the two datasets\n",
    "# UCLA_CNP_pairwise_features = pd.read_feather('data/time_series_features/UCLA_CNP_pyspi14_filtered.feather')\n",
    "# ABIDE_pairwise_features = pd.read_feather('data/time_series_features/ABIDE_pyspi14_filtered.feather')\n",
    "\n",
    "# Load first 25 principal components for univariate region times feature combination matrices\n",
    "univariate_combo_first25_PCs = pd.read_feather('data/time_series_features/univariate_combo_first25_PCs.feather')\n",
    "\n",
    "# Load univariate time-series feature info\n",
    "univariate_feature_info = pd.read_csv('data/feature_info/univariate_feature_info.csv')\n",
    "pairwise_feature_info = pd.read_csv('data/feature_info/pairwise_feature_info.csv')\n",
    "\n",
    "# Define parameters that you can change\n",
    "univariate_feature_set = \"catch25\"\n",
    "pairwise_feature_set = \"pyspi14\"\n",
    "classifier_type = \"Linear_SVM\"\n",
    "SPI_directionality_file = f\"{current_path}/code/classification_analysis/SPI_Direction_Info.csv\"\n",
    "\n",
    "num_jobs = 1 # You can increase this if you are running this on an HPC with multiple cores available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core classification settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_repeats = 10\n",
    "num_null_iters = 1000\n",
    "RepeatedStratifiedKFold_splitter = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=127)\n",
    "\n",
    "model = svm.SVC(kernel=\"linear\", C=1, class_weight=\"balanced\")\n",
    "pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)),\n",
    "                    ('model', model)])\n",
    "\n",
    "scorers = [make_scorer(balanced_accuracy_score)]\n",
    "scoring_names = [\"Balanced_Accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathrm{A_{region}}$, $\\mathrm{A_{feature}}$, and $\\mathrm{A_{uni\\_combo}}$: Fitting linear SVMs to intra-regional univariate time-series properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    # Load class labels and sample IDs\n",
    "    class_labels = np.load(f\"data/input_data/{study}_{disorder}_class_labels.npy\", allow_pickle=True).tolist()\n",
    "    sample_IDs = np.load(f\"data/input_data/{study}_{disorder}_sample_IDs.npy\", allow_pickle=True).tolist()\n",
    "    \n",
    "    study_disorder_univariate_models = pd.read_table(f\"data/time_series_features/processed_numpy_files/{study}_{disorder}_univariate_models.txt\",\n",
    "                                                     header=None)\n",
    "    study_disorder_univariate_models.columns = [\"Model_Name\"]\n",
    "\n",
    "    for model in study_disorder_univariate_models.Model_Name:\n",
    "\n",
    "        # Define analysis type\n",
    "        if \"ROI\" in model:\n",
    "            Analysis_Type = \"Brain_Region\"\n",
    "        elif \"combo_catch25_features_all_regions\" in model:\n",
    "            Analysis_Type = \"Univariate_Combo\"\n",
    "        else:\n",
    "            Analysis_Type = \"catch25_feature\"\n",
    "        # Define grouping var\n",
    "        if Analysis_Type==\"Brain_Region\":\n",
    "            grouping_var = model.split(\"_ROI_\")[1]\n",
    "        elif Analysis_Type==\"Univariate_Combo\":\n",
    "            grouping_var = \"Combo\"\n",
    "        else:\n",
    "            grouping_var = model.split(\"_catch25_feature_\")[1]\n",
    "\n",
    "        # Read in the tabular data for the corresponding model\n",
    "        model_data = np.load(f\"data/time_series_features/processed_numpy_files/{model}.npy\")\n",
    "\n",
    "        # Define main output data file for this feature\n",
    "        main_output_file_base = f\"{study}_{disorder}_{Analysis_Type}_{grouping_var}_{classifier_type}_{num_repeats}_repeats_{num_folds}_folds_CV\"\n",
    "\n",
    "        # Fit classifier\n",
    "        main_classification_res, _, null_classification_res = run_k_fold_classifier_for_feature(feature_data = model_data, \n",
    "                                                                                            pipe = pipe,\n",
    "                                                                                            CV_splitter = RepeatedStratifiedKFold_splitter,\n",
    "                                                                                            class_labels=class_labels,\n",
    "                                                                                            sample_IDs = sample_IDs,\n",
    "                                                                                            scorers=scorers,\n",
    "                                                                                            scoring_names=scoring_names,\n",
    "                                                                                            num_null_iters=num_null_iters,\n",
    "                                                                                            num_folds = num_folds,\n",
    "                                                                                            num_repeats = num_repeats,\n",
    "                                                                                            num_jobs = num_jobs)\n",
    "        \n",
    "        # Assign key details to dataframes\n",
    "        main_classification_res[\"Study\"] = study \n",
    "        main_classification_res[\"Disorder\"] = disorder\n",
    "        main_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "        main_classification_res[\"group_var\"] = grouping_var\n",
    "        main_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "\n",
    "        # Save results to feather file\n",
    "        main_classification_res.to_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}/{main_output_file_base}_main_res.feather\")\n",
    "\n",
    "        # If nulls were requested, save those too\n",
    "        if num_null_iters > 0:\n",
    "            null_classification_res[\"Study\"] = study \n",
    "            null_classification_res[\"Disorder\"] = disorder\n",
    "            null_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "            null_classification_res[\"group_var\"] = grouping_var\n",
    "            null_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "            null_classification_res.to_feather(f\"data/classification_results/null_results/{study}_{disorder}/{main_output_file_base}_nulls.feather\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this code, you should have the following two folders in your `data/classification_results/` directory:\n",
    "- `balanced_accuracy/`: contains individual `.feather` files with the fold-wise balanced accuracy results for each disorder\n",
    "- `null_results/`: contains individual `.feather` files with the null balanced accuracy distributions for each disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathrm{A_{FC}}$ and $\\mathrm{A_{FC\\_combo}}$: Fitting linear SVMs to inter-regional bivariate time-series properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    # Load class labels and sample IDs\n",
    "    class_labels = np.load(f\"data/input_data/{study}_{disorder}_class_labels.npy\", allow_pickle=True).tolist()\n",
    "    sample_IDs = np.load(f\"data/input_data/{study}_{disorder}_sample_IDs.npy\", allow_pickle=True).tolist()\n",
    "    \n",
    "    # Pairwise A_FC first\n",
    "    study_disorder_pairwise_models = pd.read_table(f\"data/time_series_features/processed_numpy_files/{study}_{disorder}_pairwise_models.txt\",\n",
    "                                                     header=None)\n",
    "    study_disorder_pairwise_models.columns = [\"Model_Name\"]\n",
    "\n",
    "    for model in study_disorder_pairwise_models.Model_Name:\n",
    "\n",
    "        # Define analysis type\n",
    "        Analysis_Type = \"pyspi14_SPI\"\n",
    "\n",
    "        # Define grouping var\n",
    "        grouping_var = model.split(\"_pyspi14_SPI_\")[1]\n",
    "\n",
    "        # Read in the tabular data for the corresponding model\n",
    "        model_data = np.load(f\"data/time_series_features/processed_numpy_files/{model}.npy\")\n",
    "\n",
    "        # Define main output data file for this feature\n",
    "        main_output_file_base = f\"{study}_{disorder}_{Analysis_Type}_{grouping_var}_{classifier_type}_{num_repeats}_repeats_{num_folds}_folds_CV\"\n",
    "\n",
    "        # Fit classifier\n",
    "        main_classification_res, _, null_classification_res = run_k_fold_classifier_for_feature(feature_data = model_data, \n",
    "                                                                                            pipe = pipe,\n",
    "                                                                                            CV_splitter = RepeatedStratifiedKFold_splitter,\n",
    "                                                                                            class_labels=class_labels,\n",
    "                                                                                            sample_IDs = sample_IDs,\n",
    "                                                                                            scorers=scorers,\n",
    "                                                                                            scoring_names=scoring_names,\n",
    "                                                                                            num_null_iters=num_null_iters,\n",
    "                                                                                            num_folds = num_folds,\n",
    "                                                                                            num_repeats = num_repeats,\n",
    "                                                                                            num_jobs = num_jobs)\n",
    "        \n",
    "        # Assign key details to dataframes\n",
    "        main_classification_res[\"Study\"] = study \n",
    "        main_classification_res[\"Disorder\"] = disorder\n",
    "        main_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "        main_classification_res[\"group_var\"] = grouping_var\n",
    "        main_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "\n",
    "        # # Save results to feather file\n",
    "        # main_classification_res.to_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}/{main_output_file_base}_main_res.feather\")\n",
    "\n",
    "        # If nulls were requested, save those too\n",
    "        if num_null_iters > 0:\n",
    "            null_classification_res[\"Study\"] = study \n",
    "            null_classification_res[\"Disorder\"] = disorder\n",
    "            null_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "            null_classification_res[\"group_var\"] = grouping_var\n",
    "            null_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "            null_classification_res.to_feather(f\"data/classification_results/null_results/{study}_{disorder}/{main_output_file_base}_nulls.feather\")\n",
    "\n",
    "\n",
    "    # Then pairwise A_FC_combo\n",
    "    study_disorder_combined_univariate_pairwise_models = pd.read_table(f\"data/time_series_features/processed_numpy_files/{study}_{disorder}_combined_univariate_pairwise_models.txt\",\n",
    "                                                     header=None)\n",
    "    study_disorder_combined_univariate_pairwise_models.columns = [\"Model_Name\"]\n",
    "\n",
    "    for model in study_disorder_combined_univariate_pairwise_models.Model_Name:\n",
    "\n",
    "        # Define analysis type\n",
    "        Analysis_Type = \"SPI_Combo\"\n",
    "\n",
    "        # Define grouping var\n",
    "        grouping_var = model.split(\"combined_univariate_catch25_and_pyspi14_SPI_\")[1]\n",
    "\n",
    "        # Read in the tabular data for the corresponding model\n",
    "        model_data = np.load(f\"data/time_series_features/processed_numpy_files/{model}.npy\")\n",
    "\n",
    "        # Define main output data file for this feature\n",
    "        main_output_file_base = f\"{study}_{disorder}_{Analysis_Type}_{grouping_var}_{classifier_type}_{num_repeats}_repeats_{num_folds}_folds_CV\"\n",
    "\n",
    "        # Fit classifier\n",
    "        main_classification_res, _, null_classification_res = run_k_fold_classifier_for_feature(feature_data = model_data, \n",
    "                                                                                            pipe = pipe,\n",
    "                                                                                            CV_splitter = RepeatedStratifiedKFold_splitter,\n",
    "                                                                                            class_labels=class_labels,\n",
    "                                                                                            sample_IDs = sample_IDs,\n",
    "                                                                                            scorers=scorers,\n",
    "                                                                                            scoring_names=scoring_names,\n",
    "                                                                                            num_null_iters=num_null_iters,\n",
    "                                                                                            num_folds = num_folds,\n",
    "                                                                                            num_repeats = num_repeats,\n",
    "                                                                                            num_jobs = num_jobs)\n",
    "        \n",
    "        # Assign key details to dataframes\n",
    "        main_classification_res[\"Study\"] = study \n",
    "        main_classification_res[\"Disorder\"] = disorder\n",
    "        main_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "        main_classification_res[\"group_var\"] = grouping_var\n",
    "        main_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "\n",
    "        # Save results to feather file\n",
    "        main_classification_res.to_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}/{main_output_file_base}_main_res.feather\")\n",
    "\n",
    "        # If nulls were requested, save those too\n",
    "        if num_null_iters > 0:\n",
    "            null_classification_res[\"Study\"] = study \n",
    "            null_classification_res[\"Disorder\"] = disorder\n",
    "            null_classification_res[\"Analysis_Type\"] = Analysis_Type\n",
    "            null_classification_res[\"group_var\"] = grouping_var\n",
    "            null_classification_res[\"Classifier_Type\"] = classifier_type\n",
    "            null_classification_res.to_feather(f\"data/classification_results/null_results/{study}_{disorder}/{main_output_file_base}_nulls.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping results for visualization\n",
    "\n",
    "Now that we have fit all linear SVMs and null models for each of the five representations, we can tabulate data into a format that is amenable to statistical analysis and data visualization.\n",
    "\n",
    "First, we will compile balanced accuracy and null results that were saved separately across disorders into one feather file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_balanced_accuracy_results_list = []\n",
    "pairwise_balanced_accuracy_results_list = []\n",
    "combined_univariate_pairwise_balanced_accuracy_results_list = []\n",
    "\n",
    "# Lists for all folds\n",
    "univariate_balanced_accuracy_results_all_folds_list = []\n",
    "pairwise_balanced_accuracy_results_all_folds_list = []\n",
    "combined_univariate_pairwise_balanced_accuracy_results_all_folds_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "    \n",
    "    # Read in univariate results\n",
    "    univariate_balanced_accuracy_results_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_univariate_Linear_SVM_sklearn_balanced_accuracy.feather\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "    univariate_balanced_accuracy_results_list.append(univariate_balanced_accuracy_results_disorder)\n",
    "    \n",
    "    univariate_balanced_accuracy_results_all_folds_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_univariate_Linear_SVM_sklearn_balanced_accuracy_all_folds.feather\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "    univariate_balanced_accuracy_results_all_folds_list.append(univariate_balanced_accuracy_results_all_folds_disorder)\n",
    "    \n",
    "    # Read in pairwise results and set Disorder to Comparison_Group if Disorder is NA\n",
    "    pairwise_balanced_accuracy_results_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_pairwise_Linear_SVM_sklearn_balanced_accuracy.feather\")\n",
    "                        .assign(Study=study, Disorder=disorder))\n",
    "    pairwise_balanced_accuracy_results_list.append(pairwise_balanced_accuracy_results_disorder)\n",
    "\n",
    "    pairwise_balanced_accuracy_results_all_folds_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_pairwise_Linear_SVM_sklearn_balanced_accuracy_all_folds.feather\")\n",
    "                        .assign(Study=study, Disorder=disorder))\n",
    "    pairwise_balanced_accuracy_results_all_folds_list.append(pairwise_balanced_accuracy_results_all_folds_disorder)\n",
    "    \n",
    "    # Read in combined univariate and pairwise results\n",
    "    combined_univariate_pairwise_balanced_accuracy_results_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_combined_univariate_pairwise_Linear_SVM_sklearn_balanced_accuracy.feather\")\n",
    "                                        .assign(Study=study, Disorder=disorder))\n",
    "    combined_univariate_pairwise_balanced_accuracy_results_list.append(combined_univariate_pairwise_balanced_accuracy_results_disorder)\n",
    "\n",
    "    combined_univariate_pairwise_balanced_accuracy_results_all_folds_disorder = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_combined_univariate_pairwise_Linear_SVM_sklearn_balanced_accuracy_all_folds.feather\")\n",
    "                                        .assign(Study=study, Disorder=disorder))\n",
    "    combined_univariate_pairwise_balanced_accuracy_results_all_folds_list.append(combined_univariate_pairwise_balanced_accuracy_results_all_folds_disorder)\n",
    "\n",
    "# Concatenate results\n",
    "univariate_balanced_accuracy_results = pd.concat(univariate_balanced_accuracy_results_list).reset_index(drop=True)\n",
    "univariate_balanced_accuracy_results_all_folds = pd.concat(univariate_balanced_accuracy_results_all_folds_list).reset_index(drop=True)\n",
    "pairwise_balanced_accuracy_results = pd.concat(pairwise_balanced_accuracy_results_list).reset_index(drop=True)\n",
    "pairwise_balanced_accuracy_results_all_folds = pd.concat(pairwise_balanced_accuracy_results_all_folds_list).reset_index(drop=True)\n",
    "combined_univariate_pairwise_balanced_accuracy_results = pd.concat(combined_univariate_pairwise_balanced_accuracy_results_list).reset_index(drop=True)\n",
    "combined_univariate_pairwise_balanced_accuracy_results_all_folds = pd.concat(combined_univariate_pairwise_balanced_accuracy_results_all_folds_list).reset_index(drop=True)\n",
    "\n",
    "# Add 1 to Fold and Repeat columns\n",
    "univariate_balanced_accuracy_results_all_folds['Fold'] = univariate_balanced_accuracy_results_all_folds['Fold'] + 1\n",
    "pairwise_balanced_accuracy_results_all_folds['Fold'] = pairwise_balanced_accuracy_results_all_folds['Fold'] + 1\n",
    "combined_univariate_pairwise_balanced_accuracy_results_all_folds['Fold'] = combined_univariate_pairwise_balanced_accuracy_results_all_folds['Fold'] + 1\n",
    "univariate_balanced_accuracy_results_all_folds['Repeat'] = univariate_balanced_accuracy_results_all_folds['Repeat'] + 1\n",
    "pairwise_balanced_accuracy_results_all_folds['Repeat'] = pairwise_balanced_accuracy_results_all_folds['Repeat'] + 1\n",
    "combined_univariate_pairwise_balanced_accuracy_results_all_folds['Repeat'] = combined_univariate_pairwise_balanced_accuracy_results_all_folds['Repeat'] + 1\n",
    "\n",
    "# Save balanced accuracy results to feather files\n",
    "univariate_balanced_accuracy_results.reset_index().to_feather(\"data/classification_results/univariate_balanced_accuracy_results.feather\")\n",
    "univariate_balanced_accuracy_results_all_folds.reset_index().to_feather(\"data/classification_results/univariate_balanced_accuracy_results_all_folds.feather\")\n",
    "pairwise_balanced_accuracy_results.reset_index().to_feather(\"data/classification_results/pairwise_balanced_accuracy_results.feather\")\n",
    "pairwise_balanced_accuracy_results_all_folds.reset_index().to_feather(\"data/classification_results/pairwise_balanced_accuracy_results_all_folds.feather\")\n",
    "combined_univariate_pairwise_balanced_accuracy_results.reset_index().to_feather(\"data/classification_results/combined_univariate_pairwise_balanced_accuracy_results.feather\")\n",
    "combined_univariate_pairwise_balanced_accuracy_results_all_folds.reset_index().to_feather(\"data/classification_results/combined_univariate_pairwise_balanced_accuracy_results_all_folds.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compile the results for L1-regularized SVM and PCA-based SVM across the four disorders\n",
    "L1_regularized_balanced_accuracy_list = []\n",
    "PCA_balanced_accuracy_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "    \n",
    "    # Read in L1-regularized SVM results\n",
    "    L1_regularized_results = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_Univariate_{univariate_feature_set}_{classifier_type}_Combo_L1_Regularized_balanced_accuracy.feather\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "    L1_regularized_balanced_accuracy_list.append(L1_regularized_results)\n",
    "    \n",
    "    # Read in PCA-based SVM results\n",
    "    PCA_results = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_Univariate_{univariate_feature_set}_{classifier_type}_Combo_25_PCs_balanced_accuracy.feather\")\n",
    "                        .assign(Study=study, Disorder=disorder))\n",
    "    PCA_balanced_accuracy_list.append(PCA_results)\n",
    "\n",
    "# Concatenate results into one balanced accuracy dataframe\n",
    "L1_regularized_balanced_accuracy_results = (pd.concat(L1_regularized_balanced_accuracy_list, axis=0)\n",
    "                                            .reset_index(level=0, drop=True)\n",
    "                                            .drop(columns=['index', 'level_0']))\n",
    "PCA_balanced_accuracy_results = (pd.concat(PCA_balanced_accuracy_list, axis=0)\n",
    "                                            .reset_index(level=0, drop=True)\n",
    "                                            .drop(columns=['index', 'level_0']))\n",
    "\n",
    "# Save to one feather file\n",
    "L1_regularized_balanced_accuracy_results.to_feather(\"data/classification_results/all_L1_regularized_balanced_accuracy_results.feather\")\n",
    "PCA_balanced_accuracy_results.to_feather(\"data/classification_results/all_PCA_balanced_accuracy_results.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same compilation for fold assignments and null balanced accuracy distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_null_distribution_list = []\n",
    "pairwise_null_distribution_list = []\n",
    "combined_univariate_pairwise_null_distribution_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "    \n",
    "    # Read in null distribution results\n",
    "    null_distribution_univariate = (pd.read_feather(f\"data/classification_results/null_results/{study}_{disorder}_univariate_Linear_SVM_sklearn_null_balanced_accuracy_distributions.feather\")\n",
    "                         .assign(Study=study, Disorder=disorder))\n",
    "    univariate_null_distribution_list.append(null_distribution_univariate)\n",
    "\n",
    "    null_distribution_pairwise = (pd.read_feather(f\"data/classification_results/null_results/{study}_{disorder}_pairwise_Linear_SVM_sklearn_null_balanced_accuracy_distributions.feather\")\n",
    "                         .assign(Study=study, Disorder=disorder))\n",
    "    pairwise_null_distribution_list.append(null_distribution_pairwise)\n",
    "\n",
    "    null_distribution_combo = (pd.read_feather(f\"data/classification_results/null_results/{study}_{disorder}_combined_univariate_pairwise_Linear_SVM_sklearn_null_balanced_accuracy_distributions.feather\")\n",
    "                         .assign(Study=study, Disorder=disorder))\n",
    "    combined_univariate_pairwise_null_distribution_list.append(null_distribution_combo)\n",
    "\n",
    "# Concatenate results into one dataframe\n",
    "univariate_null_distribution = pd.concat(univariate_null_distribution_list, axis=0).reset_index()\n",
    "pairwise_null_distribution = pd.concat(pairwise_null_distribution_list, axis=0).reset_index()\n",
    "combined_univariate_pairwise_null_distribution = pd.concat(combined_univariate_pairwise_null_distribution_list, axis=0).reset_index()\n",
    "\n",
    "# Save null distributions to feather files\n",
    "univariate_null_distribution.reset_index().to_feather(\"data/classification_results/univariate_null_balanced_accuracy_distribution.feather\")\n",
    "pairwise_null_distribution.reset_index().to_feather(\"data/classification_results/pairwise_null_balanced_accuracy_distribution.feather\")\n",
    "combined_univariate_pairwise_null_distribution.reset_index().to_feather(\"data/classification_results/combined_univariate_pairwise_null_balanced_accuracy_distribution.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we'll define a function to compute a $p$-value for a given observed balanced accuracy based on the corresponding empirical null distribution, comprising 1000 null balanced accuracy estimates for the given model.\n",
    "From this distribution, we will derive the mean and SD null balanced accuracy, which will be used to compute the cumulative density function for the corresponding Gaussian distribution to obtain a p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o compute_p_values\n",
    "\n",
    "# Functions to calculate empirical p-value\n",
    "compute_p_values <- function(observed_balanced_accuracy_df, null_distribution_df) {\n",
    "  \n",
    "  # Filter null to the same analysis type and grouping variable\n",
    "  null_distribution_df <- null_distribution_df %>%\n",
    "      dplyr::select(Analysis_Type, Disorder, Study, Balanced_Accuracy, group_var) %>%\n",
    "      semi_join(., observed_balanced_accuracy_df %>% dplyr::select(Analysis_Type, Disorder, Study, Balanced_Accuracy, group_var),\n",
    "                by = join_by(Analysis_Type, Disorder, Study, group_var))\n",
    "\n",
    "  # Compare main balanced accuracy with that of the empirical null distribution\n",
    "  observed_balanced_accuracy_value <- observed_balanced_accuracy_df$Balanced_Accuracy\n",
    "  \n",
    "  # Extract the mean and variance from the null distribution\n",
    "  null_mean <- mean(null_distribution_df$Balanced_Accuracy)\n",
    "  null_SD <- sd(null_distribution_df$Balanced_Accuracy)\n",
    "  \n",
    "  # Compute the probability of observing the main balanced accuracy given a null Gaussian distribution with the above parameters\n",
    "  p_value <- pnorm(q=observed_balanced_accuracy_value, mean=null_mean, sd=null_SD, lower.tail = FALSE)\n",
    "  \n",
    "  # Organize results into dataframe to return\n",
    "  observed_balanced_accuracy_df$p_value <- p_value\n",
    "  return(observed_balanced_accuracy_df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compute $p$-values for all balanced accuracy results and save the results to a feather file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i compute_p_values,univariate_balanced_accuracy_results,univariate_null_distribution,pairwise_balanced_accuracy_results,pairwise_null_distribution,combined_univariate_pairwise_balanced_accuracy_results,combined_univariate_pairwise_null_distribution -o univariate_p_values,pairwise_p_values,combined_univariate_pairwise_p_values\n",
    "\n",
    "# Split the balanced accuracy results by study, disorder, and analysis type\n",
    "univariate_balanced_accuracy_results_split <- univariate_balanced_accuracy_results %>%\n",
    "    group_by(Study, Disorder, Analysis_Type, group_var) %>%\n",
    "    group_split()\n",
    "\n",
    "pairwise_balanced_accuracy_results_split <- pairwise_balanced_accuracy_results %>%\n",
    "    group_by(Study, Disorder, Analysis_Type, group_var) %>%\n",
    "    group_split()\n",
    "\n",
    "combined_univariate_pairwise_balanced_accuracy_results_split <- combined_univariate_pairwise_balanced_accuracy_results %>%\n",
    "    group_by(Study, Disorder, Analysis_Type, group_var) %>%\n",
    "    group_split()\n",
    "\n",
    "univariate_p_values <- univariate_balanced_accuracy_results_split %>%\n",
    "    purrr::map_df(~ compute_p_values(observed_balanced_accuracy_df = .x,\n",
    "                                     null_distribution_df = univariate_null_distribution)) %>%\n",
    "  # Adjust p-values by group\n",
    "    group_by(Study, Disorder, Analysis_Type) %>%\n",
    "    mutate(p_value_HolmBonferroni = p.adjust(p_value, method=\"holm\"),\n",
    "           p_value_BenjaminiHochberg = p.adjust(p_value, method=\"BH\"))\n",
    "\n",
    "pairwise_p_values <- pairwise_balanced_accuracy_results_split %>%\n",
    "    purrr::map_df(~ compute_p_values(observed_balanced_accuracy_df = .x,\n",
    "                                     null_distribution_df = pairwise_null_distribution)) %>%\n",
    "  # Adjust p-values by group\n",
    "    group_by(Study, Disorder, Analysis_Type) %>%\n",
    "    mutate(p_value_HolmBonferroni = p.adjust(p_value, method=\"holm\"),\n",
    "           p_value_BenjaminiHochberg = p.adjust(p_value, method=\"BH\"))\n",
    "\n",
    "combined_univariate_pairwise_p_values <- combined_univariate_pairwise_balanced_accuracy_results_split %>%\n",
    "    purrr::map_df(~ compute_p_values(observed_balanced_accuracy_df = .x,\n",
    "                                     null_distribution_df = combined_univariate_pairwise_null_distribution)) %>%\n",
    "  # Adjust p-values by group\n",
    "    group_by(Study, Disorder, Analysis_Type) %>%\n",
    "    mutate(p_value_HolmBonferroni = p.adjust(p_value, method=\"holm\"),\n",
    "           p_value_BenjaminiHochberg = p.adjust(p_value, method=\"BH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save p-values to feather file\n",
    "univariate_p_values.reset_index().to_feather(\"data/classification_results/univariate_p_values.feather\")\n",
    "pairwise_p_values.reset_index().to_feather(\"data/classification_results/pairwise_p_values.feather\")\n",
    "combined_univariate_pairwise_p_values.reset_index().to_feather(\"data/classification_results/combined_univariate_pairwise_p_values.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis with different classifier types\n",
    "\n",
    "While all previous analyses used a linear SVM classifier, we also considered the possibility that---given the spatiotemporal complexity of these neuropsychiatric disorders---cases and controls may not be linearly separable in feature space.\n",
    "We therefore repeated A<sub>region</sub>, A<sub>region</sub>, and A<sub>region</sub> using SVM with a (nonlinear) radial basis function (RBF) kernel and using the random forest ensemble classifier, both from 'scikit-learn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CV splitters\n",
    "main_cv = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=127)\n",
    "inner_cv = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=127)\n",
    "\n",
    "# Define the model dict\n",
    "model_dict = {\"Linear_SVM_sklearn\": svm.SVC(kernel=\"linear\", class_weight=\"balanced\", C=1),\n",
    "                \"Linear_SVM_libsvm\": svm.LinearSVC(C=1, dual=False, penalty='l1', class_weight='balanced'),\n",
    "                \"RBF_SVM_sklearn\": svm.SVC(kernel=\"rbf\", class_weight=\"balanced\", C=1),\n",
    "                \"RandomForest\": RandomForestClassifier(n_estimators=100, class_weight=\"balanced\"),\n",
    "                \"GradientBoost\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)}\n",
    "\n",
    "# Define class weight and C parameter grid for tuning\n",
    "param_grid={\"model__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            \"model__class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    # Load class labels and sample IDs\n",
    "    class_labels = np.load(f\"data/input_data/{study}_{disorder}_class_labels.npy\", allow_pickle=True).tolist()\n",
    "    sample_IDs = np.load(f\"data/input_data/{study}_{disorder}_sample_IDs.npy\", allow_pickle=True).tolist()\n",
    "    \n",
    "    study_disorder_univariate_models = pd.read_table(f\"data/time_series_features/processed_numpy_files/{study}_{disorder}_univariate_models.txt\",\n",
    "                                                     header=None)\n",
    "    study_disorder_univariate_models.columns = [\"Model_Name\"]\n",
    "\n",
    "    for model in study_disorder_univariate_models.Model_Name:\n",
    "\n",
    "        # Define analysis type\n",
    "        if \"ROI\" in model:\n",
    "            Analysis_Type = \"Brain_Region\"\n",
    "        elif \"combo_catch25_features_all_regions\" in model:\n",
    "            Analysis_Type = \"Univariate_Combo\"\n",
    "        else:\n",
    "            Analysis_Type = \"catch25_feature\"\n",
    "        # Define grouping var\n",
    "        if Analysis_Type==\"Brain_Region\":\n",
    "            grouping_var = model.split(\"_ROI_\")[1]\n",
    "        elif Analysis_Type==\"Univariate_Combo\":\n",
    "            grouping_var = \"Combo\"\n",
    "        else:\n",
    "            grouping_var = model.split(\"_catch25_feature_\")[1]\n",
    "\n",
    "        # Read in the tabular data for the corresponding model\n",
    "        model_data = np.load(f\"data/time_series_features/processed_numpy_files/{model}.npy\")\n",
    "\n",
    "        # Define main output data file for this feature\n",
    "        robustness_output_file_base = f\"{dataset_ID}_{disorder}_{Analysis_Type}_{grouping_var}\"\n",
    "\n",
    "        # Run the robustness analysis\n",
    "        (training_balacc_df, classifier_type_df, nested_CV_df) = robustness_analysis(model_data, class_labels, model_dict, inner_cv, main_cv, \n",
    "                                                                                    num_folds=num_folds, num_repeats=num_repeats, \n",
    "                                                                                    base_model_name=\"Linear_SVM_sklearn\", \n",
    "                                                                                    scoring=\"balanced_accuracy\", num_jobs=num_jobs)\n",
    "        \n",
    "        # Assign Analysis_Type, group_var, Disorder, and Dataset columns\n",
    "        for df in [training_balacc_df, classifier_type_df, nested_CV_df]:\n",
    "            df[\"Analysis_Type\"] = Analysis_Type\n",
    "            df[\"group_var\"] = grouping_var\n",
    "            df[\"Disorder\"] = disorder\n",
    "            df[\"Dataset\"] = study\n",
    "\n",
    "        # Save results to feather files\n",
    "        training_balacc_df.to_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{robustness_output_file_base}_training_balacc_df.feather\")\n",
    "        classifier_type_df.to_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{robustness_output_file_base}_classifier_type_df.feather\")\n",
    "        nested_CV_df.to_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{robustness_output_file_base}_nested_CV_df.feather\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from these nonlinear classifiers can be tabulated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_types_result_list = []\n",
    "nested_CV_results_list = []\n",
    "training_balacc_results_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    # Find classifier type result files\n",
    "    classifier_type_result_files = [f for f in os.listdir(f\"data/classification_results/robustness_analysis/{study}_{disorder}/\") if f.endswith(\"classifier_type_df.feather\")]\n",
    "\n",
    "    for classifier_type_result in classifier_type_result_files: \n",
    "        # Read in classifier type results\n",
    "        classifier_type_results = (pd.read_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{classifier_type_result}\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "        classifier_types_result_list.append(classifier_type_results.reset_index(drop=True))\n",
    "    \n",
    "    # Find nested CV result files\n",
    "    nested_CV_result_files = [f for f in os.listdir(f\"data/classification_results/robustness_analysis/{study}_{disorder}/\") if f.endswith(\"nested_CV_df.feather\")]\n",
    "\n",
    "    for nested_CV_result in nested_CV_result_files:\n",
    "        # Read in nested CV results\n",
    "        nested_CV_results = (pd.read_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{nested_CV_result}\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "        nested_CV_results_list.append(nested_CV_results.reset_index(drop=True))\n",
    "\n",
    "    # Find the training balanced accuracy result files\n",
    "    training_balacc_result_files = [f for f in os.listdir(f\"data/classification_results/robustness_analysis/{study}_{disorder}/\") if f.endswith(\"training_balacc_df.feather\")]\n",
    "\n",
    "    for training_balacc_result in training_balacc_result_files:\n",
    "        # Read in training balanced accuracy results\n",
    "        training_balacc_results = (pd.read_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{training_balacc_result}\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "        training_balacc_results_list.append(training_balacc_results.reset_index(drop=True))\n",
    "\n",
    "# Concatenate results\n",
    "classifier_types_results = pd.concat(classifier_types_result_list).reset_index(drop=True)\n",
    "nested_CV_results = pd.concat(nested_CV_results_list).reset_index(drop=True)\n",
    "training_balacc_results = pd.concat(training_balacc_results_list).reset_index(drop=True)\n",
    "\n",
    "# Save to feather files\n",
    "classifier_types_results.to_feather(\"data/classification_results/robustness_analysis/all_classifier_types_results.feather\")\n",
    "nested_CV_results.to_feather(\"data/classification_results/robustness_analysis/all_nested_CV_results.feather\")\n",
    "training_balacc_results.to_feather(\"data/classification_results/robustness_analysis/all_training_balacc_results.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the effect of inverse probability weighting\n",
    "\n",
    "We will also fit linear SVM classifiers with no sample weighting to compare against those fit with inverse probability weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run univariate classification for UCLA CNP for each disorder\n",
    "for disorder in [\"SCZ\", \"BP\", \"ADHD\"]:\n",
    "    run_univariate_classifier_no_weighting(dataset_ID=\"UCLA_CNP\",\n",
    "                        data_path=f\"{current_path}/data/\",\n",
    "                        metadata=UCLA_CNP_metadata,\n",
    "                        univariate_feature_data=UCLA_CNP_univariate_features,\n",
    "                        univariate_first_25_PCs=univariate_combo_first25_PCs,\n",
    "                        disorder=disorder,\n",
    "                        univariate_feature_set=univariate_feature_set, \n",
    "                        pairwise_feature_set=pairwise_feature_set,\n",
    "                        classifier_type = classifier_type,\n",
    "                        num_folds = num_folds,\n",
    "                        num_repeats = num_repeats,\n",
    "                        num_jobs = num_jobs,\n",
    "                        num_null_iters = num_null_iters)\n",
    "\n",
    "# Run univariate classification for ABIDE\n",
    "for disorder in [\"ASD\"]:\n",
    "    run_univariate_classifier_no_weighting(dataset_ID=\"ABIDE\",\n",
    "                            data_path=f\"{current_path}/data/\",\n",
    "                            metadata=ABIDE_metadata,\n",
    "                            univariate_feature_data=ABIDE_univariate_features,\n",
    "                            univariate_first_25_PCs=univariate_combo_first25_PCs,\n",
    "                            disorder=disorder,\n",
    "                            univariate_feature_set=univariate_feature_set, \n",
    "                            pairwise_feature_set=pairwise_feature_set,\n",
    "                            classifier_type = classifier_type,\n",
    "                            num_folds = num_folds,\n",
    "                            num_repeats = num_repeats,\n",
    "                            num_jobs = num_jobs,\n",
    "                            num_null_iters = num_null_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_SVM_no_weighting_balanced_accuracy_list = []\n",
    "\n",
    "# Iterate over each row of study_to_disorder_df to extract the study and disorder\n",
    "for index, row in study_to_disorder_df.iterrows():\n",
    "    study = row['Study']\n",
    "    disorder = row['Disorder']\n",
    "    \n",
    "    # Read in univariate results\n",
    "    Linear_SVM_no_weighting_univariate_results = (pd.read_feather(f\"data/classification_results/balanced_accuracy/{study}_{disorder}_Univariate_{univariate_feature_set}_Linear_SVM_no_weighting_balanced_accuracy.feather\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "    Linear_SVM_no_weighting_balanced_accuracy_list.append(Linear_SVM_no_weighting_univariate_results.reset_index(drop=True))\n",
    "    \n",
    "\n",
    "# Concatenate results into one balanced accuracy dataframe\n",
    "Linear_SVM_no_weighting_balanced_accuracy = pd.concat(Linear_SVM_no_weighting_balanced_accuracy_list, axis=0).reset_index()\n",
    "\n",
    "# Save to one feather file\n",
    "Linear_SVM_no_weighting_balanced_accuracy.to_feather(\"data/classification_results/all_linear_SVM_no_weighting_balanced_accuracy_results.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confound analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_balanced_accuracy_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    class_labels = np.load(f\"../../data/input_data/{study}_{disorder}_class_labels.npy\")\n",
    "    num_folds=10\n",
    "    num_repeats=10\n",
    "\n",
    "    age_feature = merged_metadata.query(\"Diagnosis in ['Control', @disorder] & Study == @study\").Age.values\n",
    "    sex_feature = merged_metadata.query(\"Diagnosis in ['Control', @disorder] & Study == @study\").Sex.values \n",
    "    head_mvmt_feature = merged_metadata.query(\"Diagnosis in ['Control', @disorder] & Study == @study\").Mean_FD_Power.values\n",
    "\n",
    "    # Convert M to 0 and F to 1\n",
    "    sex_feature = np.where(sex_feature == \"M\", 0, 1)\n",
    "\n",
    "    SVM_model = svm.SVC(kernel='linear', class_weight='balanced', C=1)\n",
    "    pipeline = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)), \n",
    "                            ('model', SVM_model)])\n",
    "    RepeatedStratifiedKFold_splitter = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=127) \n",
    "\n",
    "    analysis_type_results = []\n",
    "    for analysis_type in [\"Age\", \"Sex\", \"Mean_FD_Power\"]:\n",
    "        if analysis_type == \"Age\":\n",
    "            feature_data = age_feature.reshape(-1,1) \n",
    "        elif analysis_type == \"Sex\": \n",
    "            feature_data = sex_feature.reshape(-1,1) \n",
    "        elif analysis_type == \"Mean_FD_Power\": \n",
    "            feature_data = head_mvmt_feature.reshape(-1,1)\n",
    "\n",
    "        # Find balanced accuracy for dataset \n",
    "        confound_balanced_accuracy = cross_validate(pipeline, feature_data, class_labels, \n",
    "                                                    cv=RepeatedStratifiedKFold_splitter, scoring=\"balanced_accuracy\", n_jobs=1,\n",
    "                                                    return_estimator=False)['test_score']\n",
    "        \n",
    "        # Create dataframe\n",
    "        confound_balanced_accuracy_df = pd.DataFrame({\"Study\" : study, \n",
    "                                                        \"Disorder\": disorder,\n",
    "                                                        \"Analysis_Type\": analysis_type,\n",
    "                                                        \"Balanced_Accuracy\": confound_balanced_accuracy})\n",
    "        \n",
    "        # Assign folds and repeats \n",
    "        confound_balanced_accuracy_df[\"Fold\"] = confound_balanced_accuracy_df.index % num_folds\n",
    "        confound_balanced_accuracy_df[\"Repeat\"] = confound_balanced_accuracy_df.index // num_repeats\n",
    "\n",
    "        # Append results to list \n",
    "        confounds_balanced_accuracy_list.append(confound_balanced_accuracy_df)\n",
    "\n",
    "# Concatenate results\n",
    "confounds_balanced_accuracy_results_all_folds = pd.concat(confounds_balanced_accuracy_list, axis=0)\n",
    "\n",
    "# Take average across folds per disorder \n",
    "confounds_balanced_accuracy_results = (confounds_balanced_accuracy_results_all_folds\n",
    "                                 .groupby([\"Study\", \"Disorder\", \"Analysis_Type\"], as_index=False)['Balanced_Accuracy']\n",
    "                                 .agg(['mean', 'std'])\n",
    "                                 .reset_index()\n",
    "                                 .rename(columns={\"mean\": \"Balanced_Accuracy\", \"std\": \"Balanced_Accuracy_SD\"}))\n",
    "\n",
    "\n",
    "# Save to feather file\n",
    "confounds_balanced_accuracy_results_all_folds.reset_index().to_feather(\"data/classification_results/confounds_balanced_accuracy_results_all_folds.feather\")\n",
    "confounds_balanced_accuracy_results.reset_index().to_feather(\"data/classification_results/confounds_balanced_accuracy_results.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site-specific analyses for ABIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABIDE_site_specific_results_list = []\n",
    "study = \"ABIDE\" \n",
    "disorder = \"ASD\"\n",
    "\n",
    "for site_number in [5, 20]:\n",
    "    # Find classifier type result files\n",
    "    site_specific_result_files = [f for f in os.listdir(f\"data/classification_results/robustness_analysis/{study}_{disorder}/\") if f.endswith(f\"_Site{site_number}_main_classification_res.feather\")]\n",
    "\n",
    "    for site_specific_result_file in site_specific_result_files: \n",
    "        # Read in classifier type results\n",
    "        site_specific_result = (pd.read_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{site_specific_result_file}\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "        ABIDE_site_specific_results_list.append(site_specific_result.reset_index(drop=True))\n",
    "\n",
    "# Concatenate results \n",
    "ABIDE_site_specific_results_all_folds = pd.concat(ABIDE_site_specific_results_list).reset_index(drop=True)\n",
    "\n",
    "# Take average across folds per disorder \n",
    "ABIDE_site_specific_results = (ABIDE_site_specific_results_all_folds\n",
    "                                 .groupby([\"Study\", \"Disorder\", \"Analysis_Type\", \"Site_Number\", \"group_var\"], as_index=False)['Balanced_Accuracy']\n",
    "                                 .agg(['mean', 'std'])\n",
    "                                 .reset_index()\n",
    "                                 .rename(columns={\"mean\": \"Balanced_Accuracy\", \"std\": \"Balanced_Accuracy_SD\"}))\n",
    "\n",
    "# Save to feather file\n",
    "ABIDE_site_specific_results_all_folds.reset_index().to_feather(\"data/classification_results/robustness_analysis/ABIDE_site_specific_balanced_accuracy_all_folds.feather\")\n",
    "ABIDE_site_specific_results.reset_index().to_feather(\"data/classification_results/robustness_analysis/ABIDE_site_specific_balanced_accuracy.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with the first 10 PCs per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_PCs_results_list = []\n",
    "\n",
    "# Iterate over the four disorders\n",
    "for disorder in study_disorder_lookup.keys():\n",
    "    study = study_disorder_lookup[disorder]\n",
    "\n",
    "    # Find first 10 PCs result files\n",
    "    first_10_PCs_result_files = [f for f in os.listdir(f\"data/classification_results/robustness_analysis/{study}_{disorder}/\") if f.endswith(\"first10_PCs_main_classification_res.feather\")]\n",
    "\n",
    "    for first_10_PCs_result in first_10_PCs_result_files: \n",
    "        # Read in classifier type results\n",
    "        first_10_PCs_results = (pd.read_feather(f\"data/classification_results/robustness_analysis/{study}_{disorder}/{first_10_PCs_result}\")\n",
    "                          .assign(Study=study, Disorder=disorder))\n",
    "        first_10_PCs_results_list.append(first_10_PCs_results.reset_index(drop=True))\n",
    "\n",
    "# Concatenate results\n",
    "first_10_PCs_results_all_folds = pd.concat(first_10_PCs_results_list).reset_index(drop=True).assign(Fold = lambda x: x.Fold + 1,\n",
    "                                                                                                    Repeat = lambda x: x.Repeat + 1)\n",
    "\n",
    "# Save to feather files\n",
    "first_10_PCs_results_all_folds.to_feather(\"data/classification_results/robustness_analysis/all_first_10_PCs_classification_results.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
