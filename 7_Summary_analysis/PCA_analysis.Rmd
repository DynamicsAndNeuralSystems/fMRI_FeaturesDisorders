---
title: "PCA analysis"
author: "Annie Bryant"
date: "5/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(FactoMineR)
library(factoextra)
library(cowplot)
theme_set(theme_cowplot())
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"

noise_proc = "AROMA+2P"
# Clean up names
noise_label <- gsub("\\+", "_", noise_proc)

# Load catch22 data for current noise processing method
feature_matrix <- readRDS(paste0(rdata_path, sprintf("UCLA_%s_catch22.Rds", 
                                                     noise_label)))      
```

## Step 3

AROMA + 2P

```{r}
eigen_list <- list()
for (brain_region in unique(feature_matrix$Brain_Region)) {
  region_data <- subset(feature_matrix, Brain_Region == brain_region) %>%
    pivot_wider(id_cols = c(Subject_ID, group, Brain_Region),
                names_from = names,
                values_from = values)
  region_data_mat <- region_data %>%
    select(-Subject_ID, -group, -Brain_Region) %>%
    drop_na() %>%
    as.matrix()
  region_data_PCA <- PCA(region_data_mat, scale.unit = TRUE, ncp = 22, graph = FALSE)
  region_eigen  <- data.frame(Components = 1:length(region_data_PCA$eig[, 2]),
                              Percent_Variance = region_data_PCA$eig[, 2]) %>%
    mutate(Brain_Region = brain_region)
  
  eigen_list <- rlist::list.append(eigen_list, region_eigen)
}

eigen_df <- do.call(plyr::rbind.fill, eigen_list)
```

```{r}
eigen_df %>%
  ggplot(data = ., mapping = aes(x=Components, y=Percent_Variance)) +
  geom_point() +
  geom_line(aes(group = Brain_Region), alpha = 0.5) +
  ylab("Percent Variance") +
  xlab("Number of PCs") +
  ggtitle("Region-wise PCA Scree Plots") +
  theme(plot.title = element_text(hjust = 0.5))
```



## Step 4

AROMA + 2P

```{r}
eigen_list <- list()
for (catch22_feature in unique(feature_matrix$names)) {
  feature_data <- subset(feature_matrix, names == catch22_feature) %>%
    pivot_wider(id_cols = c(Subject_ID, group, names),
                names_from = Brain_Region,
                values_from = values)
  feature_data_mat <- feature_data %>%
    select(-Subject_ID, -group, -names) %>%
    drop_na() %>%
    as.matrix()
  feature_data_PCA <- PCA(feature_data_mat, scale.unit = TRUE, ncp = 82, graph = FALSE)
  feature_eigen  <- data.frame(Components = 1:length(feature_data_PCA$eig[, 2]),
                              Percent_Variance = feature_data_PCA$eig[, 2]) %>%
    mutate(catch22_Feature = catch22_feature)
  
  eigen_list <- rlist::list.append(eigen_list, feature_eigen)
}

eigen_df <- do.call(plyr::rbind.fill, eigen_list)
```

```{r}
eigen_df %>%
  filter(Components < 23) %>%
  ggplot(data = ., mapping = aes(x=Components, y=Percent_Variance)) +
  geom_point() +
  geom_line(aes(group = catch22_Feature), alpha = 0.5) +
  ylab("Percent Variance") +
  xlab("Number of PCs") +
  ggtitle("Feature-wise PCA Scree Plots") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Step 5

AROMA + 2P

```{r}
combo_data <- feature_matrix %>%
  tidyr::unite("Combo", Brain_Region, names, sep="_") %>%
  pivot_wider(id_cols = c(Subject_ID, group),
              names_from = Combo,
              values_from = values) %>%
  drop_na() 
combo_data_mat <- combo_data %>%
  select(-Subject_ID, -group) %>%
  as.matrix()
combo_data_PCA <- prcomp(combo_data_mat, center = TRUE, scale. = TRUE)
combo_eigen  <- get_eig(combo_data_PCA) %>%
  mutate(Components = 1:nrow(.)) %>%
  dplyr::rename("Percent_Variance" = "variance.percent",
                "Cumulative_Variance" = "cumulative.variance.percent")
  
```

Scree plot
```{r}
combo_eigen %>%
  filter(Components < 83) %>%
  ggplot(data = ., mapping = aes(x=Components, y=Percent_Variance)) +
  geom_point() +
  geom_line() +
  ylab("Percent Variance") +
  xlab("Number of PCs") +
  ggtitle("Combo-wise PCA Scree Plot") +
  theme(plot.title = element_text(hjust = 0.5))
```

Cumulative analysis

```{r}
combo_eigen %>%
  filter(Components < 83) %>%
  ggplot(data = ., mapping = aes(x=Components, y=Cumulative_Variance)) +
  geom_point() +
  geom_line() +
  ylab("Cumulative Variance") +
  xlab("Number of PCs") +
  ggtitle("Combo-wise PCA Cumulative Variance") +
  theme(plot.title = element_text(hjust = 0.5))
```

Run linear SVM for each number of PCs from 1 to 82
```{r}
groups <- combo_data$group
res_df_list <- list()
for (i in 1:82) {
  svm_for_pc <- as.data.frame(cbind(groups, combo_data_PCA$x[, 1:i]))
  
  svmModel <- e1071::svm(factor(groups) ~ .,
                         kernel = "linear",
                         cost = 1,
                         data = svm_for_pc)
  
  # Generate in-sample predictions based on SVM model
  pred <- predict(svmModel, svm_for_pc)
  svm_for_pc$group <- factor(svm_for_pc$group, levels = levels(pred))
  
  # Calculate accuracy and balanced accuracy
  accuracy <- sum(pred == svm_for_pc$group)/length(pred)
  balanced_accuracy <- caret::confusionMatrix(data=pred, 
                                              reference=svm_for_pc$group)$byClass[["Balanced Accuracy"]]
  balanced_accuracy <- ifelse(is.na(balanced_accuracy), 0.5, balanced_accuracy)
  
  # Compile results into a dataframe
  df_res <- data.frame(Num_PCs = i,
                       accuracy = accuracy,
                       balanced_accuracy = balanced_accuracy)
  
  # Append results to list
  res_df_list <- rlist::list.append(res_df_list, df_res)
}

res_df_in_sample <- do.call(plyr::rbind.fill, res_df_list)
saveRDS(res_df_in_sample, "res_df_in_sample.Rds")
```

```{r}
res_df %>%
  pivot_longer(cols = c("accuracy", "balanced_accuracy"),
               names_to = "Metric",
               values_to = "Values") %>%
  ggplot(data = ., mapping = aes(x = Num_PCs,
                                 y = Values)) +
  geom_line() +
  facet_grid(. ~ Metric, scales = "free")
```

Run linear 10-fold SVM for each number of PCs from 1 to 82
```{r}
groups <- combo_data$group
res_df_list <- list()
seed = 127
set.seed(seed)

for (i in 1:82) {
  svm_for_pc <- as.data.frame(cbind(groups, as.numeric(combo_data_PCA$x[, 1:i]))) %>%
    mutate_at(vars(contains("V")), funs(as.numeric(.)))
  
  # Create ten folds from data
  set.seed(seed)
  flds <- caret::createFolds(svm_for_pc$groups, k = 10, list = TRUE, returnTrain = FALSE)
  
  accuracy_list <- list()
  balanced_accuracy_list <- list()
  
  # Iterate over each fold
  for (j in 1:length(flds)) {
    test_j <- flds[[j]]
    train_j <- setdiff(1:nrow(svm_for_pc), test_j)
    
    test_data <- svm_for_pc[test_j, ]
    train_data <- svm_for_pc[train_j, ]
    
    svmModel <- e1071::svm(factor(groups) ~ .,
                           kernel = "linear",
                           cost = 1,
                           data = train_data)
    
    # Generate out-of-sample predictions based on SVM model
    pred <- predict(svmModel, test_data)
    test_data$groups <- factor(test_data$groups, levels = levels(pred))
    
    # Calculate accuracy and balanced accuracy
    accuracy <- sum(pred == test_data$groups)/length(pred)
    balanced_accuracy <- caret::confusionMatrix(reference=test_data$groups, 
                                                data=pred)$byClass[["Balanced Accuracy"]]
    
    accuracy_list[[i]] <- accuracy
    balanced_accuracy_list[[i]] <- balanced_accuracy
  } 
  
  accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
  accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
  balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
  balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)
  
    
  # Compile results into a dataframe
  df_res <- data.frame(Num_PCs = i,
                       accuracy = accuracy,
                       accuracy_sd = accuracy_sd,
                       balanced_accuracy = balanced_accuracy,
                       balanced_accuracy_sd = balanced_accuracy_sd)
  
  # Append results to list
  res_df_list <- rlist::list.append(res_df_list, df_res)
}

res_df_CV <- do.call(plyr::rbind.fill, res_df_list)
saveRDS(res_df_CV, "res_df_CV.Rds")
```

```{r}
res_df_CV %>%
  pivot_longer(cols = c("accuracy", "balanced_accuracy"),
               names_to = "Metric",
               values_to = "Values") %>%
  ggplot(data = ., mapping = aes(x = Num_PCs,
                                 y = Values)) +
  geom_line() +
  facet_grid(. ~ Metric, scales = "free")
```


#### inv prob
Run linear 10-fold SVM for each number of PCs from 1 to 82
```{r}
groups <- combo_data$group
res_df_list <- list()
seed = 127
set.seed(seed)

for (i in 1:82) {
  svm_for_pc <- as.data.frame(cbind(groups, as.numeric(combo_data_PCA$x[, 1:i]))) %>%
    mutate_at(vars(contains("V")), funs(as.numeric(.)))
  
  sample_props <- svm_for_pc %>%
    dplyr::summarise(control_prop = sum(groups=="Control") / n(),
                     schz_prop = sum(groups=="Schz")/n())
  
  # Convert to sample weights based on inverse of probability
  sample_wts <- list("Control" = 1/sample_props$control_prop,
                     "Schz" = 1/sample_props$schz_prop)
  
  # Create ten folds from data
  set.seed(seed)
  flds <- caret::createFolds(svm_for_pc$groups, k = 10, list = TRUE, returnTrain = FALSE)
  
  accuracy_list <- list()
  balanced_accuracy_list <- list()
  
  # Iterate over each fold
  for (j in 1:length(flds)) {
    test_j <- flds[[j]]
    train_j <- setdiff(1:nrow(svm_for_pc), test_j)
    
    test_data <- svm_for_pc[test_j, ]
    train_data <- svm_for_pc[train_j, ]
    
    svmModel <- e1071::svm(factor(groups) ~ .,
                           kernel = "linear",
                           cost = 1,
                           data = train_data,
                                 class.weights = sample_wts)
    
    # Generate out-of-sample predictions based on SVM model
    pred <- predict(svmModel, test_data)
    test_data$groups <- factor(test_data$groups, levels = levels(pred))
    
    # Calculate accuracy and balanced accuracy
    accuracy <- sum(pred == test_data$groups)/length(pred)
    balanced_accuracy <- caret::confusionMatrix(reference=test_data$groups, 
                                                data=pred)$byClass[["Balanced Accuracy"]]
    
    accuracy_list[[i]] <- accuracy
    balanced_accuracy_list[[i]] <- balanced_accuracy
  } 
  
  accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
  accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
  balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
  balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)
  
    
  # Compile results into a dataframe
  df_res <- data.frame(Num_PCs = i,
                       accuracy = accuracy,
                       accuracy_sd = accuracy_sd,
                       balanced_accuracy = balanced_accuracy,
                       balanced_accuracy_sd = balanced_accuracy_sd)
  
  # Append results to list
  res_df_list <- rlist::list.append(res_df_list, df_res)
}

res_df_CV_inv_prob <- do.call(plyr::rbind.fill, res_df_list)
saveRDS(res_df_CV, "res_df_CV_inv_prob.Rds")
```


look at this graph out to maybe 1,000 at intervals of 5-10
```{r}
res_df_CV_inv_prob %>%
  pivot_longer(cols = c("accuracy", "balanced_accuracy"),
               names_to = "Metric",
               values_to = "Values") %>%
  ggplot(data = ., mapping = aes(x = Num_PCs,
                                 y = Values)) +
  geom_line() +
  facet_grid(. ~ Metric, scales = "free")
```

#### SMOTE
Run linear 10-fold SVM for each number of PCs from 1 to 82
```{r}
groups <- combo_data$group
res_df_list <- list()
seed = 127
set.seed(seed)

for (i in 2:82) {
  svm_for_pc <- as.data.frame(cbind(groups, combo_data_PCA$x[, 1:i])) %>%
    mutate_at(vars(contains(c("V", "PC"))), funs(as.numeric(.)))
  
  svm_for_pc <- smotefamily::SMOTE(as.data.frame(svm_for_pc[,-1]), 
                                   svm_for_pc$groups, K = 5)$data %>%
          dplyr::rename("groups" = "class")
  
  # Create ten folds from data
  set.seed(seed)
  flds <- caret::createFolds(svm_for_pc$groups, k = 10, list = TRUE, returnTrain = FALSE)
  
  accuracy_list <- list()
  balanced_accuracy_list <- list()
  
  # Iterate over each fold
  for (j in 1:length(flds)) {
    test_j <- flds[[j]]
    train_j <- setdiff(1:nrow(svm_for_pc), test_j)
    
    test_data <- svm_for_pc[test_j, ]
    train_data <- svm_for_pc[train_j, ]
    
    svmModel <- e1071::svm(factor(groups) ~ .,
                           kernel = "linear",
                           cost = 1,
                           data = train_data)
    
    # Generate out-of-sample predictions based on SVM model
    pred <- predict(svmModel, test_data)
    test_data$groups <- factor(test_data$groups, levels = levels(pred))
    
    # Calculate accuracy and balanced accuracy
    accuracy <- sum(pred == test_data$groups)/length(pred)
    balanced_accuracy <- caret::confusionMatrix(reference=test_data$groups, 
                                                data=pred)$byClass[["Balanced Accuracy"]]
    
    accuracy_list[[i]] <- accuracy
    balanced_accuracy_list[[i]] <- balanced_accuracy
  } 
  
  accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
  accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
  balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
  balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)
  
    
  # Compile results into a dataframe
  df_res <- data.frame(Num_PCs = i,
                       accuracy = accuracy,
                       accuracy_sd = accuracy_sd,
                       balanced_accuracy = balanced_accuracy,
                       balanced_accuracy_sd = balanced_accuracy_sd)
  
  # Append results to list
  res_df_list <- rlist::list.append(res_df_list, df_res)
}

res_df_CV_SMOTE <- do.call(plyr::rbind.fill, res_df_list)
saveRDS(res_df_CV, "res_df_CV_SMOTE.Rds")
```

```{r}
res_df_CV_SMOTE %>%
  pivot_longer(cols = c("accuracy", "balanced_accuracy"),
               names_to = "Metric",
               values_to = "Values") %>%
  ggplot(data = ., mapping = aes(x = Num_PCs,
                                 y = Values)) +
  geom_line() +
  facet_grid(. ~ Metric, scales = "free")
```