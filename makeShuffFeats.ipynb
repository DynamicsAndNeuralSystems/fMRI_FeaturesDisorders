{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import analysisFunctions as af\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Read in and store the framewise displacement (fd) for the given dataset in a variable called fdAvgs,\n",
    "# and create the TS_path_names and indices2Keep variables\n",
    "\n",
    "# Store the fdAvgs and set a threshold fd\n",
    "filePath = '/Users/AV/Dropbox/COBRE/movementData/fdAvgs_COBRE.txt'\n",
    "fdAvgs = pd.read_csv(filePath,header=None);\n",
    "threshold_fd = 0.5\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame({'feature': [], 'featBalancedAcc': [], 'stdDev': [], 'svmWeights' : []})\n",
    "\n",
    "\n",
    "# Store the path of the folder containing the subject data for the given dataset\n",
    "subPath = '/Users/AV/Dropbox/COBRE/cfgData/'\n",
    "\n",
    "# Need to alphabetise and store the subject file names into a variable\n",
    "TS_path_names = sorted(glob.glob(subPath + '*.mat'))\n",
    "\n",
    "# Filter the subjects based on their fd, and retain the subjects that have an fd < threshold_fd\n",
    "TS_path_names, indices2Keep = af.removePathNames(filePath, threshold_fd, TS_path_names)\n",
    "indices2Keep = indices2Keep.tolist()\n",
    "\n",
    "# Adding 1 to every element in the array to convert to MATLAB indexing\n",
    "indices2KeepMat = list(np.asarray(indices2Keep) + 1)\n",
    "\n",
    "# print(indices2KeepMat)\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Add a multi-level index to the tsData and store some key variables\n",
    "\n",
    "element = 'element1_COBRE.txt' # Read in the feature matrix data from the saved .txt file\n",
    "PyFeatList = 'PythonFeatureList.txt' # This text file contains the 22 feature names\n",
    "\n",
    "# Add a multi-level index to the feature matrix and save into the variable, tsData\n",
    "# Also store the number of ROIs and subjects in the data\n",
    "tsData, ROIs, subjects, feats, featList = af.addIndices(element,subPath,PyFeatList)\n",
    "#-------------------------------------------------------------------------------\n",
    "# Define a function to retrieve the svm weights\n",
    "\n",
    "def giveMeSVMWeights(X,y):\n",
    "    ''' This function returns the feature weights when given X and y '''\n",
    "\n",
    "    # Import the support vector classifier and balance the classes\n",
    "    from sklearn.svm import SVC\n",
    "    svclassifier = SVC(kernel='linear', class_weight='balanced')#, C=1e-2)\n",
    "\n",
    "    # Import accuracy score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "    svclassifier.fit(X, y)\n",
    "        \n",
    "    svmWeights = svclassifier.coef_\n",
    "    svmW_shape = svmWeights.shape\n",
    "\n",
    "    return svmWeights[0]\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Create the target column - unique for each dataset\n",
    "\n",
    "# Select which dataset is being used\n",
    "dataset = 'COBRE'\n",
    "\n",
    "if dataset == 'UCLA':\n",
    "\n",
    "    # Creating the target column\n",
    "    targetCol = af.getTargetCol(TS_path_names)\n",
    "\n",
    "elif dataset == 'COBRE':\n",
    "\n",
    "    # Creating the target column\n",
    "    csvPath = '/Users/AV/Dropbox/COBRE/participants.csv'\n",
    "    COBRE = pd.read_csv(csvPath,header=None);\n",
    "\n",
    "    targetCol = COBRE.iloc[1:,2]\n",
    "    targetCol = targetCol.tolist()\n",
    "    targetCol = pd.DataFrame(data=targetCol, columns=['target'])\n",
    "\n",
    "    targetCol = targetCol.iloc[indices2Keep,:]\n",
    "    targetCol = np.asarray(targetCol,dtype=np.int)\n",
    "\n",
    "    # A '0' indicates a control subject and a '1' indicates a subject with SCZ\n",
    "    targetColModified = np.where(targetCol==1, 0, targetCol) # First change the pre-existing 1s to 0s\n",
    "    targetCol = np.where(targetCol==2, 1, targetColModified) # Then change the 2s to 1s\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "for feature in range(1, 23):\n",
    "\n",
    "    # Choose which feature to analyse\n",
    "    featureName = featList[feature-1]\n",
    "    featSlice = af.getFeatSlice(ROIs,subjects,tsData,featureName,indices2KeepMat)\n",
    "    DataSlice = featSlice\n",
    "    DataSlice_zscored = DataSlice.apply(zscore)\n",
    "    X = DataSlice_zscored    \n",
    "    y = np.ravel(targetCol)\n",
    "\n",
    "    # Perform 10-Fold Cross Validation\n",
    "\n",
    "    # Store the function's output as a variable\n",
    "    scores = af.get10FoldCVScore(X,y)\n",
    "    weights = giveMeSVMWeights(X,y)\n",
    "    \n",
    "    featBalancedAcc = scores.mean()\n",
    "    stdDev = scores.std()\n",
    "\n",
    "    df3 = df3.append({'feature': feature, 'featBalancedAcc': featBalancedAcc, 'stdDev': stdDev, 'svmWeights' : weights}, ignore_index=True)\n",
    "    df3_sorted = df3.sort_values(by='featBalancedAcc',ascending=False)\n",
    "    df3_sorted = df3_sorted.set_index('feature')\n",
    "    \n",
    "#     for i in range(1,1001):\n",
    "        \n",
    "#         iteration = i\n",
    "            \n",
    "#         # Shuffled target column\n",
    "#         np.random.shuffle(targetCol)\n",
    "#         y = np.ravel(targetCol)\n",
    "#         #-------------------------------------------------------------------------------\n",
    "\n",
    "#         # Perform 10-Fold Cross Validation\n",
    "\n",
    "#         # Store the function's output as a variable\n",
    "#         scores = af.get10FoldCVScore(X,y)\n",
    "\n",
    "#         featBalancedAcc = scores.mean()\n",
    "#         stdDev = scores.std()\n",
    "\n",
    "#         df3 = df3.append({'feature': feature, 'iteration': iteration, 'featBalancedAcc': featBalancedAcc, 'stdDev': stdDev}, ignore_index=True)\n",
    "\n",
    "#         print('Feature ', str(feature), ', Iteration ', str(iteration), '... Stored.')\n",
    "\n",
    "# outFileName = 'featBalancedAcc_' + str(dataset) + '_shuff.txt'\n",
    "        \n",
    "# df3.to_csv(outFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
