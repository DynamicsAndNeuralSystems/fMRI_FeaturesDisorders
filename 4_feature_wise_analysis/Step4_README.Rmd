---
title: "Step 4: Feature-wise catch22 ROI Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning=F, message=F)
```

### Source functions
```{r}
source("../helper_functions/SVM_functions.R")
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"
set.seed(127)
library(patchwork)
```

## In-sample SVM classification

### Simple in-sample linear SVM

We will start with a simple linear SVM classifier using all 22 features.

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"
  
# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, ".Rds"))) {
  feature_wise_SVM_in_sample <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                               svm_kernel = kernel,
                                                               test_package = test_package,
                                                               svm_feature_var = "Brain_Region",
                                                               grouping_var = "Feature",
                                                               noise_procs = noise_procs,
                                                               use_inv_prob_weighting = FALSE,
                                                               use_SMOTE = FALSE)
  saveRDS(feature_wise_SVM_in_sample, file=paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, ".Rds"))
} 
```



```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_in_sample <- readRDS(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_in_sample,
                       group_var = "Feature",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/In_Sample_Feature_Wise_linear_SVM_Multivar_e1071.png",
       width=7,height=5, units="in", dpi=300)
```


### In-sample linear SVM with inverse probability weighting

We can run linear SVM with the `kernlab` package to directly test sample reweighting with in-sample accuracy and balanced accuracy. 

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"
  
  # Run in-sample SVM using given package + kernel
  # If the RDS object doesn't already exist, otherwise load it in
  if (!file.exists(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, "_inv_prob.Rds"))) {
    feature_wise_SVM_in_sample_inv_prob <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                               svm_kernel = kernel,
                                                               test_package = test_package,
                                                               svm_feature_var = "Brain_Region",
                                                               grouping_var = "Feature",
                                                               noise_procs = noise_procs,
                                                               use_inv_prob_weighting = TRUE)
    saveRDS(feature_wise_SVM_in_sample_inv_prob, file=paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, "_inv_prob.Rds"))
  } 

```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_in_sample_inv_prob <- readRDS(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_e1071_inv_prob.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_in_sample_inv_prob,
                       group_var = "Feature",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/In_Sample_Feature_Wise_linear_SVM_Multivar_e1071_inv_prob.png",
       width=7,height=5, units="in", dpi=300)
```

By assigning each subject a weight equivalent to the inverse proportion of that subject's diagnosis, the linear SVM places a higher cost on incorrectly classifying schizophrenia subjects as controls. 

This shifts the raw accuracy down to a mean of around 0.68 across the three noise-processing methods, but the balanced accuracy increases to have an average of around 0.68 also -- compared with almost exclusively values of 0.35 previously.

This indicates that inverse probability reweighting mitigates the class imbalance issue and can be carried forward into 10-fold cross-validation linear SVM.


### In-sample linear SVM with SMOTE

We can run linear SVM with the `e1071` package to directly test sample reweighting with in-sample accuracy and balanced accuracy. 

```{r}
# Compare all three noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"
  
  # Run in-sample SVM using given package + kernel
  # If the RDS object doesn't already exist, otherwise load it in
  if (!file.exists(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, "_SMOTE.Rds"))) {
    feature_wise_SVM_in_sample_SMOTE <- run_in_sample_svm_by_input_var(rdata_path = rdata_path,
                                                               svm_kernel = kernel,
                                                               test_package = test_package,
                                                               svm_feature_var = "Brain_Region",
                                                               grouping_var = "Feature",
                                                               noise_procs = noise_procs,
                                                               use_inv_prob_weighting = FALSE,
                                                               use_SMOTE = TRUE) 
    saveRDS(feature_wise_SVM_in_sample_SMOTE, file=paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_", test_package, "_SMOTE.Rds"))
  } 

```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_in_sample_SMOTE <- readRDS(paste0(rdata_path, "multivar_feature_res_svmLinear_in_sample_e1071_SMOTE.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_in_sample_SMOTE,
                       group_var = "Feature",
                       cv = FALSE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/In_Sample_Feature_Wise_linear_SVM_Multivar_e1071_SMOTE.png",
       width=7,height=5, units="in", dpi=300)
```

By assigning each subject a weight equivalent to the inverse proportion of that subject's diagnosis, the linear SVM places a higher cost on incorrectly classifying schizophrenia subjects as controls. 

This shifts the raw accuracy down to a mean of around 0.68 across the three noise-processing methods, but the balanced accuracy increases to have an average of around 0.68 also -- compared with almost exclusively values of 0.35 previously.

This indicates that inverse probability reweighting mitigates the class imbalance issue and can be carried forward into 10-fold cross-validation linear SVM.


## Cross-validated SVM classification

### 10-fold cross-validated linear SVM

We can implement 10-fold cross-validation (CV) with the `caret` package.

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"
  
# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, ".Rds"))) {
  feature_wise_SVM_CV <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                 test_package = test_package,
                                                 svm_kernel = kernel,
                                                 grouping_var = "Feature",
                                                 svm_feature_var = "Brain_Region",
                                                 use_inv_prob_weighting = FALSE,
                                                 use_SMOTE = FALSE,
                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_CV, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, ".Rds"))
}

```


```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_CV <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_CV,
                       cv = TRUE,
                       group_var = "Feature",
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV_Multivar_e1071.png",
       width=7,height=5, units="in", dpi=300)
```


As with in-sample SVM, the unweighted input samples are virtually all classified as control subjects across all 82 ROIs using the 10-fold cross-validation linear SVM with caret.

### 10-fold cross-validated linear SVM with inverse probability weighting

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, "_inv_prob.Rds"))) {
  feature_wise_SVM_in_sample_inv_prob <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                                 test_package = test_package,
                                                                 svm_kernel = kernel,
                                                                 grouping_var = "Feature",
                                                                 svm_feature_var = "Brain_Region",
                                                                 use_inv_prob_weighting = TRUE,
                                                                 use_SMOTE = FALSE,
                                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_in_sample_inv_prob, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, "_inv_prob.Rds"))
}
```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_in_sample_inv_prob <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_in_sample_inv_prob,
                       group_var = "Feature",
                       cv = TRUE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV_Multivar_e1071_inv_prob.png",
       width=7,height=5, units="in", dpi=300)
```


Surprisingly, incorporating inverse probability weighting has minimal impact when it comes to the ten-fold cross-validated SVM. Of note, the in-sample and cross-validated SVM were both run with kernlab::ksvm using default parameters.


### 10-fold cross-validated linear SVM with SMOTE

```{r}
# Noise processing methods
noise_procs <- c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# Use e1071 SVM with a linear kernel
test_package = "e1071"
kernel = "linear"

# Run in-sample SVM using given package + kernel
# If the RDS object doesn't already exist, otherwise load it in
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, "_SMOTE.Rds"))) {
  feature_wise_SVM_CV_SMOTE <- run_cv_svm_by_input_var(rdata_path = rdata_path,
                                                                 test_package = test_package,
                                                                 svm_kernel = kernel,
                                                                 grouping_var = "Feature",
                                                                 svm_feature_var = "Brain_Region",
                                                                 use_inv_prob_weighting = FALSE,
                                                                 use_SMOTE = TRUE,
                                                                 noise_procs = noise_procs)
  saveRDS(feature_wise_SVM_CV_SMOTE, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_", test_package, "_SMOTE.Rds"))
}
```

```{r, fig.width=7, fig.height=5}
# Plot accuracy + balanced accuracy in histograms
# Control subject proportion is highlighted for accuracy
feature_wise_SVM_CV_SMOTE <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_SMOTE.Rds"))

noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")
plot_class_acc_w_props(class_res = feature_wise_SVM_CV_SMOTE,
                       group_var = "Feature",
                       cv = TRUE,
                       rdata_path = rdata_path,
                       noise_procs = noise_procs)
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/Feature_Wise_linear_SVM_CV_Multivar_e1071_SMOTE.png",
       width=7,height=5, units="in", dpi=300)
```


Surprisingly, incorporating inverse probability weighting has minimal impact when it comes to the ten-fold cross-validated SVM. Of note, the in-sample and cross-validated SVM were both run with kernlab::ksvm using default parameters.



## Null distribution

### Generating null distributions from model-free shuffles

```{r}
# Try three different noise processing methods
noise_procs = c("AROMA+2P", "AROMA+2P+GMR", "AROMA+2P+DiCER")

# One without minority upsampling
if (!file.exists(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))) {
  set.seed(127) 
  model_free_shuffle_null_res <- run_model_free_n_shuffles(num_shuffles = 1000000,
                                                    rdata_path = rdata_path,
                                                    noise_procs = noise_procs)
  saveRDS(model_free_shuffle_null_res, file = paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
} else {
  model_free_shuffle_null_res <- readRDS(paste0(rdata_path, "Null_Model_Free_Shuffles.Rds"))
}

```

```{r, fig.width=7, fig.height=5}
e1071_feature_wise_SVM_CV %>%
  dplyr::select(grouping_var, Noise_Proc, accuracy, balanced_accuracy) %>%
  mutate(Type = "main") %>%
  plyr::rbind.fill(., model_free_shuffle_null_res) %>%
  pivot_longer(cols=c(accuracy, balanced_accuracy),
               names_to = "Metric",
               values_to = "Values") %>%
  mutate(Metric = stringr::str_to_title(str_replace_all(Metric, "_", " "))) %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = c("AROMA+2P",
                                                    "AROMA+2P+GMR",
                                                    "AROMA+2P+DiCER"))) %>%
  ggplot(data=., mapping=aes(x=Values)) +
  geom_histogram(aes(fill = Type, y=0.5*..density..), 
                 bins = 50,
                 alpha=0.6, position="identity") +
  facet_grid(Noise_Proc ~ Metric, switch="y", scales="free_x") +
  xlab("Value from n=1,000,000 Model-Free Shuffles") +
  ylab("Scaled Density") +
  labs(fill = "Distribution") +
  theme(strip.text.y.left = element_text(angle=0),
        strip.placement = "outside",
        legend.position = "bottom",
        legend.direction = "horizontal") 
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/Main_vs_Null_Acc_BAcc_10FCV_Feature_Wise_Linear_SVM.png",
       width=7,height=5, units="in", dpi=300)
```

The model-free shuffles method is borrowed from Trent's implementation in theft. With this method, the input class labels (Schz or Control) are randomly shuffled N times, and for each iteration, the classification accuracy and balanced accuracy is calculated. This yields a null distribution of accuracies and balanced accuracies, circumventing the need for running any classification algorithms across iterations.

Here, I've run 1,000,000 iterations of the model-free shuffle, generating 1,000,000 null values for Accuracy and Balanced Accuracy, respectively. Since this method is independent of brain region, the same null distribution can be used to compare with each brain region separately.

I've plotted the distribution of null accuracies (coral) alongside the actual accuracies (teal) for the 82 ROIs on the left. 

We can do the same for inverse probability:

```{r, fig.width=7, fig.height=5}
e1071_feature_wise_SVM_CV_inv_prob %>%
  dplyr::select(grouping_var, Noise_Proc, accuracy, balanced_accuracy) %>%
  mutate(Type = "main") %>%
  plyr::rbind.fill(., model_free_shuffle_null_res) %>%
  pivot_longer(cols=c(accuracy, balanced_accuracy),
               names_to = "Metric",
               values_to = "Values") %>%
  mutate(Metric = stringr::str_to_title(str_replace_all(Metric, "_", " "))) %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = c("AROMA+2P",
                                                    "AROMA+2P+GMR",
                                                    "AROMA+2P+DiCER"))) %>%
  ggplot(data=., mapping=aes(x=Values)) +
  geom_histogram(aes(fill = Type, y=0.5*..density..), 
                 bins = 50,
                 alpha=0.6, position="identity") +
  facet_grid(Noise_Proc ~ Metric, switch="y", scales="free_x") +
  xlab("Value from n=1,000,000 Model-Free Shuffles") +
  ylab("Scaled Density") +
  labs(fill = "Distribution") +
  theme(strip.text.y.left = element_text(angle=0),
        strip.placement = "outside",
        legend.position = "bottom",
        legend.direction = "horizontal") 
```

```{r, eval=F, echo=F}
# Save plot
ggsave("plots/Main_vs_Null_Acc_BAcc_10FCV_Feature_Wise_Linear_SVM_inv_prob.png",
       width=7,height=5, units="in", dpi=300)
```



We can empirically derive p-values for both metrics to see if the classification accuracy/balanced accuracy is significantly greater than that in the null distribution.

### Deriving p-values using model-free shuffle null distributions

```{r}
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_pvals.Rds"))) {
  e1071_feature_wise_SVM_CV_pvals <- calc_empirical_nulls(class_res = e1071_feature_wise_SVM_CV,
                                                                   null_data = model_free_shuffle_null_res,
                                                                   grouping_var = "Feature")
  saveRDS(e1071_feature_wise_SVM_CV_pvals, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_pvals.Rds"))
  
} else {
  e1071_feature_wise_SVM_CV_pvals <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_pvals.Rds"))
}

e1071_feature_wise_SVM_CV_plabs <- e1071_feature_wise_SVM_CV_pvals %>%
  mutate(acc_p = scales::scientific(acc_p, digits = 3),
         bal_acc_p = scales::scientific(bal_acc_p, digits = 3),
         acc_p_adj = scales::scientific(acc_p_adj, digits = 3),
         bal_acc_p_adj = scales::scientific(bal_acc_p_adj, digits = 3))
```


Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated accuracy:
```{r, fig.width=10, fig.height=8}
top_features <- e1071_feature_wise_SVM_CV %>%
  filter(Noise_Proc == "AROMA+2P") %>%
  arrange(desc(accuracy)) %>%
  top_n(5, accuracy) %>%
  pull(grouping_var)

e1071_feature_wise_SVM_CV_pvals %>%
  filter(Noise_Proc == "AROMA+2P",
         grouping_var %in% top_features) %>%
  mutate(grouping_var = factor(grouping_var, levels = top_features)) %>%
  ggplot(data=.) +
  geom_histogram(data = model_free_shuffle_null_res %>% 
                   dplyr::filter(Noise_Proc == "AROMA+2P"),
                 aes(x=accuracy, y=0.5*..density..),
                 fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Accuracy\nfor top AROMA+2P catch22 Features") +
  geom_vline(aes(xintercept = accuracy), color = "red") +
  facet_wrap(grouping_var ~ ., scales="free_y", nrow = 2) +
  ylab("Scaled Density of Null Iterations") +
  geom_text(data = e1071_feature_wise_SVM_CV_plabs %>%
              filter(Noise_Proc == "AROMA+2P", grouping_var %in% top_features) %>%
              mutate(grouping_var = factor(grouping_var, levels = top_features)),
            aes(label = paste0("P = ", acc_p, "\nBH-FDR = ", acc_p_adj)), 
            x = 0.67, y = 10.5) +
  theme(plot.title = element_text(hjust=0.5))
```

```{r, echo=F, eval=F}
ggsave("plots/Main_vs_Null_Acc_AROMA_2P_Top5_catch22_Features.png", width=10, 
       height=6, units="in", dpi=300)
```

This panel panel shows the five brain regions with the highest raw accuracy from multi-feature 10-fold CV linear SVM. The red bar indicates the real accuracy while the gray bars depict the null distribution (derived from model-free shuffles as shown above). 

Even after adjusting for multiple comparisons (82 ROIs x 3 Noise-processing methods) using Benjamini-Hochberg False Discovery Rate (BH-FDR), the accuracy values for these five regions are still significant (p < 1.00e-06, FDR < 1.00e-05).

We can do the same for balanced accuracy:
```{r, fig.width=10, fig.height=5}
top_features <- e1071_feature_wise_SVM_CV %>%
  filter(Noise_Proc == "AROMA+2P") %>%
  arrange(desc(balanced_accuracy)) %>%
  top_n(5, balanced_accuracy) %>%
  pull(grouping_var)

e1071_feature_wise_SVM_CV_pvals %>%
  filter(Noise_Proc == "AROMA+2P",
         grouping_var %in% top_features) %>%
  mutate(grouping_var = factor(grouping_var, levels = top_features)) %>%
  ggplot(data=.) +
  geom_histogram(data = model_free_shuffle_null_res %>% 
                   dplyr::filter(Noise_Proc == "AROMA+2P"),
                 aes(x=balanced_accuracy, y=0.5*..density..),
                 fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P catch22 Features") +
  geom_vline(aes(xintercept = accuracy), color = "red") +
  facet_wrap(grouping_var ~ ., scales="free_y", nrow = 2) +
  ylab("Scaled Density of Null Iterations") +
  geom_text(data = e1071_feature_wise_SVM_CV_plabs %>%
              filter(Noise_Proc == "AROMA+2P", grouping_var %in% top_features) %>%
              mutate(grouping_var = factor(grouping_var, levels = top_features)),
            aes(label = paste0("P = ", bal_acc_p, "\nBH-FDR = ", bal_acc_p_adj)), 
            x = 0.6, y = 8.5) +
  theme(plot.title = element_text(hjust=0.5))
```
```{r, echo=F, eval=F}
ggsave("plots/Main_vs_Null_Bal_Acc_AROMA_2P_Top5_catch22_Features.png", width=10, 
       height=6, units="in", dpi=300)
```

This panel panel shows the five brain regions with the highest balanced accuracy from multi-feature 10-fold CV linear SVM. The red bar indicates the real accuracy while the gray bars depict the null distribution (derived from model-free shuffles as shown above). 

Even after adjusting for multiple comparisons (82 ROIs x 3 Noise-processing methods) using Benjamini-Hochberg False Discovery Rate (BH-FDR), the accuracy values for these five regions are still significant (p = 0, BH-FDR = 0).

```{r}
e1071_feature_wise_SVM_CV_pvals %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs)) %>%
  group_by(Noise_Proc) %>%
  summarise(num_sig_acc = sum(acc_p < 0.05),
            num_sig_acc_fdr = sum(acc_p_adj < 0.05),
            num_sig_bacc = sum(bal_acc_p < 0.05),
            num_sig_bacc_fdr = sum(bal_acc_p_adj < 0.05))
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the upsampled model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.  


### Deriving p-values using model-free shuffle null distributions -- inv prob

```{r}
if (!file.exists(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob_pvals.Rds"))) {
  e1071_feature_wise_SVM_CV_inv_prob_pvals <- calc_empirical_nulls(class_res = e1071_feature_wise_SVM_CV_inv_prob,
                                                                   null_data = model_free_shuffle_null_res,
                                                                   grouping_var = "Feature")
  saveRDS(e1071_feature_wise_SVM_CV_inv_prob_pvals, file=paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob_pvals.Rds"))
  
} else {
  e1071_feature_wise_SVM_CV_inv_prob_pvals <- readRDS(paste0(rdata_path, "Feature_wise_linear_SVM_CV_e1071_inv_prob_pvals.Rds"))
}

e1071_feature_wise_SVM_CV_inv_prob_plabs <- e1071_feature_wise_SVM_CV_inv_prob_pvals %>%
  mutate(acc_p = scales::scientific(acc_p, digits = 3),
         bal_acc_p = scales::scientific(bal_acc_p, digits = 3),
         acc_p_adj = scales::scientific(acc_p_adj, digits = 3),
         bal_acc_p_adj = scales::scientific(bal_acc_p_adj, digits = 3))
```


Let's zoom in on AROMA+2P and pick the five brain regions with the highest cross-validated accuracy:
```{r, fig.width=10, fig.height=5}
top_features <- e1071_feature_wise_SVM_CV_inv_prob %>%
  filter(Noise_Proc == "AROMA+2P") %>%
  arrange(desc(accuracy)) %>%
  top_n(5, accuracy) %>%
  pull(grouping_var)

e1071_feature_wise_SVM_CV_inv_prob_pvals %>%
  filter(Noise_Proc == "AROMA+2P",
         grouping_var %in% top_features) %>%
  mutate(grouping_var = factor(grouping_var, levels = top_features)) %>%
  ggplot(data=.) +
  geom_histogram(data = model_free_shuffle_null_res %>% 
                   dplyr::filter(Noise_Proc == "AROMA+2P"),
                 aes(x=accuracy, y=0.5*..density..),
                 fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Accuracy\nfor top AROMA+2P catch22 Features") +
  geom_vline(aes(xintercept = accuracy), color = "red") +
  facet_wrap(grouping_var ~ ., scales="free_y", nrow = 2) +
  ylab("Scaled Density of Null Iterations") +
  geom_text(data = e1071_feature_wise_SVM_CV_inv_prob_plabs %>%
              filter(Noise_Proc == "AROMA+2P", grouping_var %in% top_features) %>%
              mutate(grouping_var = factor(grouping_var, levels = top_features)),
            aes(label = paste0("P = ", acc_p, "\nBH-FDR = ", acc_p_adj)), 
            x = 0.67, y = 10.5) +
  theme(plot.title = element_text(hjust=0.5))
```

```{r, echo=F, eval=F}
ggsave("plots/Main_vs_Null_Acc_AROMA_2P_Top5_catch22_Features_inv_prob.png", width=10, 
       height=6, units="in", dpi=300)
```

This panel panel shows the five brain regions with the highest raw accuracy from multi-feature 10-fold CV linear SVM. The red bar indicates the real accuracy while the gray bars depict the null distribution (derived from model-free shuffles as shown above). 

Even after adjusting for multiple comparisons (82 ROIs x 3 Noise-processing methods) using Benjamini-Hochberg False Discovery Rate (BH-FDR), the accuracy values for these five regions are still significant (p < 1.00e-06, FDR < 1.00e-05).

We can do the same for balanced accuracy:
```{r, fig.width=10, fig.height=5}
top_features <- e1071_feature_wise_SVM_CV_inv_prob %>%
  filter(Noise_Proc == "AROMA+2P") %>%
  arrange(desc(balanced_accuracy)) %>%
  top_n(5, balanced_accuracy) %>%
  pull(grouping_var)

e1071_feature_wise_SVM_CV_inv_prob_pvals %>%
  filter(Noise_Proc == "AROMA+2P",
         grouping_var %in% top_features) %>%
  mutate(grouping_var = factor(grouping_var, levels = top_features)) %>%
  ggplot(data=.) +
  geom_histogram(data = model_free_shuffle_null_res %>% 
                   dplyr::filter(Noise_Proc == "AROMA+2P"),
                 aes(x=balanced_accuracy, y=0.5*..density..),
                 fill = "gray70", bins=50) +
  ggtitle("Main and Model-Free Shuffle Null Balanced Accuracy\nfor top AROMA+2P catch22 Features") +
  geom_vline(aes(xintercept = accuracy), color = "red") +
  facet_wrap(grouping_var ~ ., scales="free_y", nrow = 2) +
  ylab("Scaled Density of Null Iterations") +
  geom_text(data = e1071_feature_wise_SVM_CV_inv_prob_plabs %>%
              filter(Noise_Proc == "AROMA+2P", grouping_var %in% top_features) %>%
              mutate(grouping_var = factor(grouping_var, levels = top_features)),
            aes(label = paste0("P = ", bal_acc_p, "\nBH-FDR = ", bal_acc_p_adj)), 
            x = 0.6, y = 9) +
  theme(plot.title = element_text(hjust=0.5))
```
```{r, echo=F, eval=F}
ggsave("plots/Main_vs_Null_Bal_Acc_AROMA_2P_Top5_catch22_Features_inv_prob.png", width=10, 
       height=6, units="in", dpi=300)
```

This panel panel shows the five brain regions with the highest balanced accuracy from multi-feature 10-fold CV linear SVM. The red bar indicates the real accuracy while the gray bars depict the null distribution (derived from model-free shuffles as shown above). 

Even after adjusting for multiple comparisons (82 ROIs x 3 Noise-processing methods) using Benjamini-Hochberg False Discovery Rate (BH-FDR), the accuracy values for these five regions are still significant (p = 0, BH-FDR = 0).

```{r}
e1071_feature_wise_SVM_CV_inv_prob_pvals %>%
  mutate(Noise_Proc = factor(Noise_Proc, levels = noise_procs)) %>%
  group_by(Noise_Proc) %>%
  summarise(num_sig_acc = sum(acc_p < 0.05),
            num_sig_acc_fdr = sum(acc_p_adj < 0.05),
            num_sig_bacc = sum(bal_acc_p < 0.05),
            num_sig_bacc_fdr = sum(bal_acc_p_adj < 0.05))
```

This table summarises the number of ROIs for which raw accuracy or balanced accuracy is significantly greater than the upsampled model-free shuffle null distribution, both before and after adjusting for multiple comparisons with BH-FDR.  

## Null model for overall accuracy

### AROMA+2P
Take the average of 22 random accuracy values from the null distribution 10,000x and compare with the mean from AROMA+2P:

```{r}
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))) {
  random_acc_list <- list()
  for (i in 1:10000) {
    random_acc <- model_free_shuffle_null_res %>%
      sample_n(22) %>%
      summarise(mean_accuracy = mean(accuracy, na.rm=T),
                mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
      mutate(Type="null")
    random_acc_list <- rlist::list.append(random_acc_list, random_acc)
  }
  random_22_acc <- do.call(plyr::rbind.fill, random_acc_list)
  saveRDS(random_22_acc, file=paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
} else {
  random_22_acc <- readRDS(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
}

real_22_acc <- e1071_feature_wise_SVM_CV %>%
  filter(Noise_Proc=="AROMA+2P") %>%
  summarise(mean_accuracy = mean(accuracy, na.rm=T),
            mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
  mutate(Type="main")

# Plot the accuracy
acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Accuracy") +
  ggtitle("Mean Accuracy in AROMA+2P Feature-Based Data") +
  theme(plot.title=element_text(hjust=0.5))

# Plot the balanced accuracy
bal_acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_balanced_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_balanced_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Balanced Accuracy") +
  ggtitle("Mean Balanced Accuracy in AROMA+2P Feature-Based Data") +
  theme(plot.title=element_text(hjust=0.5))

acc_p / bal_acc_p
ggsave("plots/Meta_Null_AROMA_2P_Feature_wise.png", width=7, height=8, units="in", dpi=300)
```



### AROMA+2P with inverse probability weighting 
Take the average of 22 random accuracy values from the null distribution 10,000x and compare with the mean from AROMA+2P with inverse probability weighting:

```{r}
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))) {
  random_acc_list <- list()
  for (i in 1:10000) {
    random_acc <- model_free_shuffle_null_res %>%
      sample_n(22) %>%
      summarise(mean_accuracy = mean(accuracy, na.rm=T),
                mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
      mutate(Type="null")
    random_acc_list <- rlist::list.append(random_acc_list, random_acc)
  }
  random_22_acc <- do.call(plyr::rbind.fill, random_acc_list)
  saveRDS(random_22_acc, file=paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
} else {
  random_22_acc <- readRDS(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
}

real_22_acc <- e1071_feature_wise_SVM_CV_inv_prob %>%
  filter(Noise_Proc=="AROMA+2P") %>%
  summarise(mean_accuracy = mean(accuracy, na.rm=T),
            mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
  mutate(Type="main")

# Plot the accuracy
acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Accuracy") +
  ggtitle("Mean Accuracy in AROMA+2P Feature-Based Data\nwith Inverse Probability Sample Weighting") +
  theme(plot.title=element_text(hjust=0.5))

# Plot the balanced accuracy
bal_acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_balanced_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_balanced_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Balanced Accuracy") +
  ggtitle("Mean Balanced Accuracy in AROMA+2P Feature-Based Data\nwith Inverse Probability Sample Weighting") +
  theme(plot.title=element_text(hjust=0.5))

acc_p / bal_acc_p
ggsave("plots/Meta_Null_AROMA_2P_Feature_wise_inv_prob.png", width=7, height=8, units="in", dpi=300)
```



### AROMA+2P with SMOTE
Take the average of 22 random accuracy values from the null distribution 10,000x and compare with the mean from AROMA+2P with inverse probability weighting:

```{r}
set.seed(127)

if (!file.exists(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))) {
  random_acc_list <- list()
  for (i in 1:10000) {
    random_acc <- model_free_shuffle_null_res %>%
      sample_n(22) %>%
      summarise(mean_accuracy = mean(accuracy, na.rm=T),
                mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
      mutate(Type="null")
    random_acc_list <- rlist::list.append(random_acc_list, random_acc)
  }
  random_22_acc <- do.call(plyr::rbind.fill, random_acc_list)
  saveRDS(random_22_acc, file=paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
} else {
  random_22_acc <- readRDS(paste0(rdata_path, "Feature_wise_meta_null_acc_AROMA_2P.Rds"))
}

real_22_acc <- feature_wise_SVM_CV_SMOTE %>%
  filter(Noise_Proc=="AROMA+2P") %>%
  summarise(mean_accuracy = mean(accuracy, na.rm=T),
            mean_balanced_accuracy = mean(balanced_accuracy, na.rm=T)) %>%
  mutate(Type="main")

# Plot the accuracy
acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Accuracy") +
  ggtitle("Mean Accuracy in AROMA+2P Feature-Based Data\nwith Inverse Probability Sample Weighting") +
  theme(plot.title=element_text(hjust=0.5))

# Plot the balanced accuracy
bal_acc_p <- ggplot() +
  geom_histogram(data = random_22_acc, mapping=aes(x=mean_balanced_accuracy), fill="gray70") +
  geom_vline(data = real_22_acc, mapping=aes(xintercept = mean_balanced_accuracy), color="red", size=1.2) +
  ylab("Number of Iterations") +
  xlab("Mean Balanced Accuracy") +
  ggtitle("Mean Balanced Accuracy in AROMA+2P Feature-Based Data\nwith Inverse Probability Sample Weighting") +
  theme(plot.title=element_text(hjust=0.5))

acc_p / bal_acc_p
ggsave("plots/Meta_Null_AROMA_2P_Feature_wise_SMOTE.png", width=7, height=8, units="in", dpi=300)
```

