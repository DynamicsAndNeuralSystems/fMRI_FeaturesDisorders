---
title: "Step 3: ROI-Wise catch22 Feature Analysis"
output: 
  github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
```

### Source functions
```{r}
source("../helper_functions/SVM_functions.R")
rdata_path <- "D:/Virtual_Machines/Shared_Folder/PhD_work/data/scz/UCLA/Rdata/"
set.seed(127)
library(patchwork)
library(knitr)
library(kableExtra)

study <- "D:/Virtual_Machines/Shared_Folder/PhD_work/"
pydata_path <- paste0(study, "data/scz/UCLA/pydata/AROMA_2P/")
ROI_index <- read.csv(paste0(study, "data/scz/UCLA/pydata/ROI_info.csv"))
```


## By individual SPI

Load pyspi data
```{r}
all_pyspi_data <- readRDS(paste0(pydata_path, "UCLA_AROMA_2P_pyspi_res.Rds"))
```


### Focus on pearson correlation

#### Load data
```{r}
corr_data <- subset(all_pyspi_data, SPI == "xcorr_mean_sig-True")  %>%
  mutate(comparison = row_number()) %>%
  mutate(region_pair = ifelse(brain_region_1 < brain_region_2,
                              paste0(brain_region_1, "_", brain_region_2),
                              paste0(brain_region_2, "_", brain_region_1))) %>%
  distinct(region_pair, Subject_ID, .keep_all=T) %>%
  pivot_longer(cols = c(brain_region_1,
                        brain_region_2),
               names_to = "Region_Number",
               values_to = "Index") %>%
  left_join(ROI_index) %>%
  dplyr::select(-Index) %>%
  distinct() %>%
  pivot_wider(id_cols = c("Subject_ID", "group", "SPI", "value", "comparison"),
              names_from = "Region_Number",
              values_from = "ROI") %>%
  dplyr::select(-comparison) %>%
  mutate(region_pair = ifelse(brain_region_1 < brain_region_2,
                              paste0(brain_region_1, "_", brain_region_2),
                              paste0(brain_region_2, "_", brain_region_1)))
```

#### In-sample linear SVM

```{r}
data_for_SVM <- corr_data %>%
  pivot_wider(id_cols = c(Subject_ID, group),
              names_from = region_pair,
              values_from = value) %>% 
  select(-Subject_ID) %>%
  drop_na()
data_for_SVM$group <- factor(data_for_SVM$group, levels = c("CONTROL", "SCHZ"))
  
pearson_corr_in_sample_SVM <- e1071::svm(group ~ ., 
                                         data = data_for_SVM ,
                                         kernel = "linear")

# Generate in-sample predictions based on SVM model
pred <- predict(pearson_corr_in_sample_SVM, data_for_SVM)
data_for_SVM$group <- factor(data_for_SVM$group, levels = levels(pred))

# Calculate accuracy and balanced accuracy
accuracy <- sum(pred == data_for_SVM$group)/length(pred)
balanced_accuracy <- caret::confusionMatrix(data=pred, 
                                            reference=data_for_SVM$group)$byClass[["Balanced Accuracy"]]
balanced_accuracy <- ifelse(is.na(balanced_accuracy), 0.5, balanced_accuracy)

data.frame(accuracy = accuracy,
           balanced_accuracy = balanced_accuracy)
```

#### CV linear SVM
```{r}
set.seed(127)

flds <- createFolds(data_for_SVM$group, k = 10, list = TRUE, returnTrain = FALSE)
      
accuracy_list <- list()
balanced_accuracy_list <- list()


for (i in 1:length(flds)) {
  test_i <- flds[[i]]
  train_i <- setdiff(1:nrow(data_for_SVM), test_i)
  
  train_data <- data_for_SVM[train_i, ]
  test_data <- data_for_SVM[test_i, ]
  
  svmModel <- e1071::svm(factor(group) ~ .,
                         kernel = "linear",
                         cost = 1,
                         data = train_data)
  
  # Generate out-of-sample predictions based on SVM model
  pred <- predict(svmModel, test_data)
  test_data$group <- factor(test_data$group, levels = levels(pred))
  
  # Calculate accuracy and balanced accuracy
  accuracy <- sum(pred == test_data$group)/length(pred)
  balanced_accuracy <- caret::confusionMatrix(reference=test_data$group, 
                                              data=pred)$byClass[["Balanced Accuracy"]]
  
  accuracy_list[[i]] <- accuracy
  balanced_accuracy_list[[i]] <- balanced_accuracy
} 

accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)

data.frame(Accuracy = accuracy_avg,
           AccuracySD = accuracy_sd,
           Balanced_Accuracy = balanced_accuracy_avg,
           Balanced_AccuracySD = balanced_accuracy_sd)
```



#### CV linear SVM inv prob
```{r}
set.seed(127)

sample_props <- corr_data %>%
  dplyr::group_by(Subject_ID, region_pair) %>%
  dplyr::filter(!any(is.na(value))) %>%
  dplyr::ungroup() %>%
  dplyr::distinct(Subject_ID, group) %>%
  dplyr::summarise(control_prop = sum(group=="CONTROL") / n(),
                   schz_prop = sum(group=="SCHZ")/n())

# Convert to sample weights based on inverse of probability
sample_wts <- list("CONTROL" = 1/sample_props$control_prop,
                   "SCHZ" = 1/sample_props$schz_prop)

flds <- createFolds(data_for_SVM$group, k = 10, list = TRUE, returnTrain = FALSE)
      
accuracy_list <- list()
balanced_accuracy_list <- list()


for (i in 1:length(flds)) {
  test_i <- flds[[i]]
  train_i <- setdiff(1:nrow(data_for_SVM), test_i)
  
  train_data <- data_for_SVM[train_i, ]
  test_data <- data_for_SVM[test_i, ]
  
  svmModel <- e1071::svm(factor(group) ~ .,
                         kernel = "linear",
                         cost = 1,
                         data = train_data,
                         class.weights = sample_wts)
  
  # Generate out-of-sample predictions based on SVM model
  pred <- predict(svmModel, test_data)
  test_data$group <- factor(test_data$group, levels = levels(pred))
  
  # Calculate accuracy and balanced accuracy
  accuracy <- sum(pred == test_data$group)/length(pred)
  balanced_accuracy <- caret::confusionMatrix(reference=test_data$group, 
                                              data=pred)$byClass[["Balanced Accuracy"]]
  
  accuracy_list[[i]] <- accuracy
  balanced_accuracy_list[[i]] <- balanced_accuracy
} 

accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)

data.frame(Accuracy = accuracy_avg,
           AccuracySD = accuracy_sd,
           Balanced_Accuracy = balanced_accuracy_avg,
           Balanced_AccuracySD = balanced_accuracy_sd)
```

#### CV linear SVM SMOTE
```{r}
set.seed(127)

flds <- createFolds(data_for_SVM$group, k = 10, list = TRUE, returnTrain = FALSE)
      
accuracy_list <- list()
balanced_accuracy_list <- list()

for (i in 1:length(flds)) {
  test_i <- flds[[i]]
  train_i <- setdiff(1:nrow(data_for_SVM), test_i)
  
  train_data <- data_for_SVM[train_i, ]
  test_data <- data_for_SVM[test_i, ]
  
  train_data <- smotefamily::SMOTE(train_data[,-1], train_data$group, K = 5)$data %>%
            dplyr::rename("group" = "class")
  
  svmModel <- e1071::svm(factor(group) ~ .,
                         kernel = "linear",
                         cost = 1,
                         data = train_data)
  
  # Generate out-of-sample predictions based on SVM model
  pred <- predict(svmModel, test_data)
  test_data$group <- factor(test_data$group, levels = levels(pred))
  
  # Calculate accuracy and balanced accuracy
  accuracy <- sum(pred == test_data$group)/length(pred)
  balanced_accuracy <- caret::confusionMatrix(reference=test_data$group, 
                                              data=pred)$byClass[["Balanced Accuracy"]]
  
  accuracy_list[[i]] <- accuracy
  balanced_accuracy_list[[i]] <- balanced_accuracy
} 

accuracy_avg <- mean(unlist(accuracy_list), na.rm=T)
accuracy_sd <- sd(unlist(accuracy_list), na.rm=T)
balanced_accuracy_avg <- mean(unlist(balanced_accuracy_list), na.rm=T)
balanced_accuracy_sd <- sd(unlist(balanced_accuracy_list), na.rm=T)

data.frame(Accuracy = accuracy_avg,
           AccuracySD = accuracy_sd,
           Balanced_Accuracy = balanced_accuracy_avg,
           Balanced_AccuracySD = balanced_accuracy_sd)
```


### All SPIs

#### In sample

```{r}
df_list <- list()
for (this_SPI in unique(all_pyspi_data$SPI)) {
  SPI_data <- subset(all_pyspi_data, SPI == this_SPI)  %>%
    mutate(comparison = row_number()) %>%
    mutate(region_pair = ifelse(brain_region_1 < brain_region_2,
                                paste0(brain_region_1, "_", brain_region_2),
                                paste0(brain_region_2, "_", brain_region_1))) %>%
    distinct(region_pair, Subject_ID, .keep_all=T) %>%
    pivot_longer(cols = c(brain_region_1,
                          brain_region_2),
                 names_to = "Region_Number",
                 values_to = "Index") %>%
    left_join(ROI_index) %>%
    dplyr::select(-Index) %>%
    distinct() %>%
    pivot_wider(id_cols = c("Subject_ID", "group", "SPI", "value", "comparison"),
                names_from = "Region_Number",
                values_from = "ROI") %>%
    dplyr::select(-comparison) %>%
    mutate(region_pair = ifelse(brain_region_1 < brain_region_2,
                                paste0(brain_region_1, "_", brain_region_2),
                                paste0(brain_region_2, "_", brain_region_1)))
  
  data_for_SVM <- SPI_data %>%
    pivot_wider(id_cols = c(Subject_ID, group),
                names_from = region_pair,
                values_from = value) %>% 
    select(-Subject_ID) %>%
    drop_na()
  data_for_SVM$group <- factor(data_for_SVM$group, levels = c("CONTROL", "SCHZ"))
  
  pearson_corr_in_sample_SVM <- e1071::svm(group ~ ., 
                                           data = data_for_SVM ,
                                           kernel = "linear")
  
  # Generate in-sample predictions based on SVM model
  pred <- predict(pearson_corr_in_sample_SVM, data_for_SVM)
  data_for_SVM$group <- factor(data_for_SVM$group, levels = levels(pred))
  
  # Calculate accuracy and balanced accuracy
  accuracy <- sum(pred == data_for_SVM$group)/length(pred)
  balanced_accuracy <- caret::confusionMatrix(data=pred, 
                                              reference=data_for_SVM$group)$byClass[["Balanced Accuracy"]]
  balanced_accuracy <- ifelse(is.na(balanced_accuracy), 0.5, balanced_accuracy)
  
  res_df <- data.frame(SPI = this_SPI,
                       accuracy = accuracy,
                       balanced_accuracy = balanced_accuracy)
  df_list <- rlist::list.append(df_list, res_df)
}
saveRDS(df_list, "df_list_temp.Rds")
```


## By individual pair of regions

## All SPIs and all pairs of regions



