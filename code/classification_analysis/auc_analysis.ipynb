{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "data_path=\"/Users/abry4213/data/fMRI_classification/\"\n",
    "sys.path.insert(0, './')\n",
    "from core_classification_functions import *\n",
    "from mixed_sigmoid_normalisation import MixedSigmoidScaler\n",
<<<<<<< Updated upstream
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from copy import deepcopy\n",
    "# %load_ext rpy2.ipython"
=======
    "from sklearn.metrics import roc_auc_score\n",
    "%load_ext rpy2.ipython"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "package ‘see’ was built under R version 4.3.3 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# Load tidyverse R package\n",
    "suppressPackageStartupMessages({\n",
    "    library(cowplot)\n",
    "    library(ggpubr)\n",
    "    library(see)\n",
    "    library(tidyverse)\n",
    "    theme_set(theme_cowplot())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "UCLA_CNP_subjects_to_keep = pd.read_feather(f\"{data_path}/time_series_features/UCLA_CNP_filtered_sample_info_catch25_pyspi14.feather\")\n",
    "ABIDE_subjects_to_keep = pd.read_feather(f\"{data_path}/time_series_features/ABIDE_filtered_sample_info_catch25_pyspi14.feather\")\n",
    "\n",
    "# Load metadata\n",
    "UCLA_CNP_metadata = (pd.read_feather(f\"{data_path}/input_data/UCLA_CNP_sample_metadata.feather\")\n",
    "                        .assign(Study = \"UCLA_CNP\")\n",
    "                        .query(\"Sample_ID in @UCLA_CNP_subjects_to_keep.Sample_ID\"))\n",
    "ABIDE_metadata = (pd.read_feather(f\"{data_path}/input_data/ABIDE_sample_metadata.feather\")\n",
    "                        .assign(Study = \"ABIDE\")\n",
    "                        .query(\"Sample_ID in @ABIDE_subjects_to_keep.Sample_ID\"))\n",
    "\n",
    "# Load univariate time-series feature info\n",
    "univariate_feature_info = pd.read_csv(f\"{data_path}/feature_info/univariate_feature_info.csv\")\n",
    "pairwise_feature_info = pd.read_csv(f\"{data_path}/feature_info/pairwise_feature_info.csv\")\n",
    "\n",
    "# Load AUC results\n",
    "AUC_classification_results = pd.read_feather(f\"{data_path}/classification_results/All_AUC_results.feather\")\n",
    "\n",
    "# Find the mean + SD AUC for each disorder, study, analysis_type, and group_var\n",
    "AUC_summary = (AUC_classification_results\n",
    "                .groupby([\"Disorder\", \"Study\", \"Analysis_Type\", \"group_var\"], as_index=False)\n",
    "                .agg({\"AUC\": [\"mean\", \"std\"]})\n",
    "                .reset_index())\n",
    "\n",
<<<<<<< Updated upstream
    "# Load univariate time-series feature data for the two datasets\n",
    "UCLA_CNP_univariate_features = pd.read_feather(f\"{data_path}/time_series_features/UCLA_CNP_catch25_filtered.feather\")\n",
    "# ABIDE_univariate_features = pd.read_feather(f\"{data_path}/time_series_features/ABIDE_catch25_filtered.feather\")\n",
    "\n",
    "# # Load pyspi14 data for UCLA CNP and ABIDE\n",
    "# UCLA_CNP_pyspi14 = pd.read_feather(f\"{data_path}/time_series_features/UCLA_CNP_pyspi14_filtered.feather\")\n",
    "# ABIDE_pyspi14 = pd.read_feather(f\"{data_path}/time_series_features/ABIDE_pyspi14_filtered.feather\")\n"
=======
    "# Flatten the multi-index columns\n",
    "AUC_summary.columns = ['_'.join(col).strip() for col in AUC_summary.columns.values]\n",
    "AUC_summary = (AUC_summary\n",
    "               .rename(columns={\"Study_\": \"Study\", \"Disorder_\": \"Disorder\", \"Analysis_Type_\": \"Analysis_Type\", \"group_var_\": \"group_var\"})\n",
    "               .assign(Analysis_Type = lambda x: np.where(x.Analysis_Type == \"pyspi14_SPI\", \"SPI\", x.Analysis_Type)))\n",
    "\n",
    "# Load balanced accuracy p-values\n",
    "univariate_p_values = pd.read_feather(f\"{data_path}/classification_results/univariate_p_values.feather\")\n",
    "pairwise_p_values = pd.read_feather(f\"{data_path}/classification_results/pairwise_p_values.feather\")\n",
    "combined_univariate_pairwise_p_values = pd.read_feather(f\"{data_path}/classification_results/combined_univariate_pairwise_p_values.feather\")\n",
    "all_balanced_accuracy_res = pd.concat([univariate_p_values, pairwise_p_values, combined_univariate_pairwise_p_values])\n",
    "\n",
    "# Combine balanced accuracy + AUC results\n",
    "merged_classification_metrics = all_balanced_accuracy_res[['Study', 'Disorder', 'Analysis_Type', 'group_var', 'Balanced_Accuracy', 'Balanced_Accuracy_SD']].merge(AUC_summary, on=['Study', 'Disorder', 'Analysis_Type', 'group_var'])\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Disorder</th>\n",
       "      <th>Analysis_Type</th>\n",
       "      <th>group_var</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Balanced_Accuracy_SD</th>\n",
       "      <th>index_</th>\n",
       "      <th>AUC_mean</th>\n",
       "      <th>AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>ASD</td>\n",
       "      <td>Brain_Region</td>\n",
       "      <td>Angular_Gyrus</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>0.047356</td>\n",
       "      <td>136</td>\n",
       "      <td>0.540384</td>\n",
       "      <td>0.055411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>ASD</td>\n",
       "      <td>Brain_Region</td>\n",
       "      <td>Central_Opercular_Cortex</td>\n",
       "      <td>0.516732</td>\n",
       "      <td>0.043970</td>\n",
       "      <td>137</td>\n",
       "      <td>0.489416</td>\n",
       "      <td>0.049915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>ASD</td>\n",
       "      <td>Brain_Region</td>\n",
       "      <td>Cingulate_Gyrus_anterior_division</td>\n",
       "      <td>0.522574</td>\n",
       "      <td>0.047888</td>\n",
       "      <td>138</td>\n",
       "      <td>0.529265</td>\n",
       "      <td>0.055089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>ASD</td>\n",
       "      <td>Brain_Region</td>\n",
       "      <td>Cingulate_Gyrus_posterior_division</td>\n",
       "      <td>0.522027</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>139</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.061353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>ASD</td>\n",
       "      <td>Brain_Region</td>\n",
       "      <td>Cuneal_Cortex</td>\n",
       "      <td>0.519720</td>\n",
       "      <td>0.040899</td>\n",
       "      <td>140</td>\n",
       "      <td>0.516232</td>\n",
       "      <td>0.054066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study Disorder Analysis_Type                           group_var  \\\n",
       "0  ABIDE      ASD  Brain_Region                       Angular_Gyrus   \n",
       "1  ABIDE      ASD  Brain_Region            Central_Opercular_Cortex   \n",
       "2  ABIDE      ASD  Brain_Region   Cingulate_Gyrus_anterior_division   \n",
       "3  ABIDE      ASD  Brain_Region  Cingulate_Gyrus_posterior_division   \n",
       "4  ABIDE      ASD  Brain_Region                       Cuneal_Cortex   \n",
       "\n",
       "   Balanced_Accuracy  Balanced_Accuracy_SD  index_  AUC_mean   AUC_std  \n",
       "0           0.464773              0.047356     136  0.540384  0.055411  \n",
       "1           0.516732              0.043970     137  0.489416  0.049915  \n",
       "2           0.522574              0.047888     138  0.529265  0.055089  \n",
       "3           0.522027              0.043988     139  0.513400  0.061353  \n",
       "4           0.519720              0.040899     140  0.516232  0.054066  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "model = svm.SVC(kernel=\"linear\", C=1, class_weight=\"balanced\", probability=True)\n",
    "pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)),\n",
    "                ('model', model)])\n",
    "classifier_type = \"Linear_SVM_sklearn\"\n",
    "\n",
    "# Define scorers\n",
    "scorers = [make_scorer(roc_auc_score, needs_proba=True), make_scorer(balanced_accuracy_score), make_scorer(accuracy_score)]\n",
    "scoring_names = [\"AUC\", \"Balanced_Accuracy\", \"Accuracy\"]\n",
    "\n",
    "# Classification parameters\n",
    "num_folds = 10\n",
    "num_repeats = 10\n",
    "num_null_iters = 0\n",
    "num_jobs = 1\n",
    "RepeatedStratifiedKFold_splitter = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=127)"
=======
    "merged_classification_metrics.head()"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder = \"ADHD\"\n",
    "dataset_ID = \"UCLA_CNP\"\n",
    "\n",
    "class_labels = np.load(f\"{data_path}/input_data/{dataset_ID}_{disorder}_class_labels.npy\")\n",
    "sample_IDs = np.load(f\"{data_path}/input_data/{dataset_ID}_{disorder}_sample_IDs.npy\")\n",
    "\n",
    "model_name = \"UCLA_CNP_ADHD_catch25_feature_SP_Summaries_welch_rect_area_5_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Running UCLA_CNP_ADHD_catch25_feature_SP_Summaries_welch_rect_area_5_1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running {model_name}\")\n",
    "# Define analysis type\n",
    "if \"ROI\" in model_name:\n",
    "    Analysis_Type = \"Brain_Region\"\n",
    "elif \"combo_catch25_features_all_regions\" in model_name:\n",
    "    Analysis_Type = \"Univariate_Combo\"\n",
    "elif \"combined_univariate_catch25_and_pyspi14\" in model_name:\n",
    "    Analysis_Type = \"SPI_Combo\"\n",
    "elif \"catch25_feature\" in model_name:\n",
    "    Analysis_Type = \"catch25_feature\"\n",
    "else:\n",
    "    Analysis_Type = \"pyspi14_SPI\"\n",
    "\n",
    "# Find grouping_var\n",
    "if Analysis_Type==\"Brain_Region\":\n",
    "    grouping_var = model_name.split(\"_ROI_\")[1]\n",
    "elif Analysis_Type==\"Univariate_Combo\":\n",
    "    grouping_var = \"Combo\"\n",
    "elif Analysis_Type == \"SPI_Combo\":\n",
    "    grouping_var = model_name.split(\"combined_univariate_catch25_and_pyspi14_SPI_\")[1]\n",
    "elif Analysis_Type == \"catch25_feature\":\n",
    "    grouping_var = model_name.split(\"_catch25_feature_\")[1]\n",
    "else:\n",
    "    grouping_var = model_name.split(\"_pyspi14_SPI_\")[1]\n",
    "\n",
    "feature_data = np.load(f\"{data_path}/time_series_features/processed_numpy_files/{model_name}.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find splits\n",
    "splits = list(RepeatedStratifiedKFold_splitter.split(feature_data, class_labels))\n",
    "# Convert splits to a dataframe\n",
    "splits_df = pd.DataFrame(splits, columns = [\"Train\", \"Test\"])\n",
    "\n",
    "# Assign the fold and repeat numbers\n",
    "splits_df[\"Fold\"] = splits_df.index % num_folds\n",
    "splits_df[\"Repeat\"] = splits_df.index // num_repeats\n",
    "\n",
    "fold_res_list = []\n",
    "class_1_col_list = []\n",
    "\n",
    "# Iterate over each row of fold_splits dataframe\n",
    "for i, row in splits_df.iterrows():\n",
    "    fold_num = row[\"Fold\"]\n",
    "    repeat_num = row[\"Repeat\"]\n",
    "    train_indices = row[\"Train\"]\n",
    "    test_indices = row[\"Test\"]\n",
    "\n",
    "    train_data = feature_data[train_indices]\n",
    "    test_data = feature_data[test_indices]\n",
    "\n",
    "    train_data = feature_data[train_indices]\n",
    "    test_data = feature_data[test_indices]\n",
    "\n",
    "    train_labels = class_labels[train_indices]\n",
    "    test_labels = class_labels[test_indices]\n",
    "\n",
    "    # Fit pipe to train_data\n",
    "    loop_pipe = deepcopy(pipe)\n",
    "    loop_pipe.fit(train_data, train_labels)\n",
    "    test_preds = loop_pipe.predict(test_data)\n",
    "    test_preds_prob = loop_pipe.predict_proba(test_data)\n",
    "\n",
    "    # Find out which column corresponds to which class\n",
    "    fitted_model_classes = loop_pipe.classes_\n",
    "    class_1_col = np.where(fitted_model_classes==1)[0][0]\n",
    "    test_preds_prob_data = test_preds_prob[:,class_1_col]\n",
    "    class_1_col_list.append(class_1_col)\n",
    "\n",
    "    # # Figure out which column to keep: \n",
    "    # if len(test_preds[test_preds==0]) == 0:\n",
    "    #     # Find whichever column of test_preds_prob has the lower mean\n",
    "    #     prob_col = np.argmin([np.mean(test_preds_prob[:,0]), np.mean(test_preds_prob[:,1])])\n",
    "    # elif len(test_preds[test_preds==1]) == 0:\n",
    "    #     # Find whichever column of test_preds_prob has the higher mean\n",
    "    #     prob_col = np.argmax([np.mean(test_preds_prob[:,0]), np.mean(test_preds_prob[:,1])])\n",
    "    # elif np.mean(test_preds_prob[test_preds==0]) < 0.5: \n",
    "    #     prob_col = 1\n",
    "    # else: \n",
    "    #     prob_col = 0\n",
    "    # test_preds_prob_data = test_preds_prob[:,prob_col]\n",
    "\n",
    "    # Compute AUC\n",
    "    auc = roc_auc_score(test_labels, test_preds_prob_data)\n",
    "\n",
    "    this_loop_res = pd.DataFrame({\"Fold\": fold_num, \"Repeat\": repeat_num, \"AUC\": auc}, index=[0])\n",
    "    fold_res_list.append(this_loop_res)\n",
    "\n",
    "all_AUC_fold_res = pd.concat(fold_res_list)"
=======
      "`geom_smooth()` using formula = 'y ~ x'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "In geom_segment(aes(x = 50, y = 0.5, xend = Inf, yend = 0.5), linetype = \"dashed\",  :\n",
       "  All aesthetics have length 1, but the data has 410 rows.\n",
       "ℹ Please consider using `annotate()` or provide this layer with data containing\n",
       "  a single row.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i merged_classification_metrics\n",
    "\n",
    "above_50_subset <- merged_classification_metrics %>% \n",
    "    mutate(Disorder = factor(Disorder, levels = c(\"SCZ\", \"BP\", \"ADHD\", \"ASD\"))) %>%\n",
    "    filter(Balanced_Accuracy > 0.5)\n",
    "\n",
    "above_50_subset %>% \n",
    "    mutate(Disorder = factor(Disorder, levels = c(\"SCZ\", \"BP\", \"ADHD\", \"ASD\"))) %>%\n",
    "    ggplot(data=., mapping=aes(x=100*Balanced_Accuracy, y=AUC_mean)) +\n",
    "    geom_point(aes(color=Analysis_Type)) +\n",
    "    facet_grid(Disorder ~ ., scales=\"free\", switch=\"both\") +\n",
    "    geom_vline(xintercept=50, linetype=\"dashed\", color=\"black\") +\n",
    "    # geom_hline(yintercept=0.5, xmin=0.5, linetype=\"dashed\", color=\"black\") +\n",
    "    geom_segment(aes(x = 50, y = 0.5, xend = Inf, yend = 0.5), \n",
    "                     linetype=\"dashed\", color=\"black\", linewidth=0.27) +\n",
    "    # Fit linear model to the data\n",
    "    geom_smooth(data=above_50_subset, method=\"lm\", se=FALSE, color=\"black\") +\n",
    "    stat_cor(method=\"pearson\", label.x = 62.5, label.y = 0.55) +\n",
    "    ylab(\"Mean AUC Across Test Folds\") +\n",
    "    xlab(\"Mean Balanced Accuracy Across Test Folds (%)\") +\n",
    "    theme(strip.placement=\"outside\",\n",
    "          strip.background=element_blank(),\n",
    "          strip.text=element_text(face=\"bold\"),\n",
    "          legend.position=\"bottom\") \n",
    "\n",
    "# ggsave(\"../../plots/robustness_analysis/Balanced_Accuracy_vs_AUC.svg\", width=5, height=8.5, units=\"in\", dpi=300)"
>>>>>>> Stashed changes
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
